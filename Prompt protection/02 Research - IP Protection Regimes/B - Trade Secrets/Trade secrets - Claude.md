# Are AI prompts trade secrets under EU law?

A legal analytics firm discovers that a competitor's credit scoring model produces suspiciously similar outputs to its own – outputs achieved through eighteen months of prompt engineering costing €2.3 million in specialist salaries. The firm maintained NDAs, restricted access, and encrypted its prompt library; however, its engineers submitted prompts to OpenAI's cloud-based GPT-4 API thousands of times daily. A pharmaceutical company develops a specialized prompt sequence that enables Claude to identify promising drug candidates from research literature 60% faster than manual review – but the company's scientists share prompts via consumer ChatGPT accounts, and outputs reveal the prompt's structure to attentive observers. An automotive manufacturer creates proprietary "system prompts" that customize Anthropic's models for supply chain optimization, storing these prompts in encrypted files accessible only to three senior engineers under strict confidentiality agreements – yet the prompts themselves necessarily travel to Anthropic's servers with each API call.

This Article establishes whether AI prompts – the instructions and queries users provide to large language models – qualify as trade secrets under Directive (EU) 2016/943 on the protection of undisclosed know-how and business information. The answer determines whether European businesses can legally prevent competitors from misappropriating valuable prompt engineering work, or whether the fundamental architecture of cloud-based AI services renders such protection untenable. The directive requires information to meet three cumulative elements: secrecy in the sense that it is not generally known or readily accessible; commercial value because it is secret; and reasonable steps under the circumstances to keep it secret. Applied to AI prompts, the first element confronts the problem that cloud-based AI architectures require transmitting prompts to third-party providers, potentially destroying secrecy through disclosure. The second element faces the challenge that prompts may derive value primarily from the underlying AI model rather than possessing independent commercial worth. The third element demands assessing what protective measures are feasible when prompts must be shared with commercial AI providers to function at all – a requirement that may be fundamentally incompatible with trade secret law's confidentiality expectations.

## The three-part test: secrecy, commercial value, and reasonable steps

Directive (EU) 2016/943, adopted on 8 June 2016 with a transposition deadline of 9 June 2018, harmonizes trade secrets protection across EU Member States by establishing minimum standards for civil remedies against unlawful acquisition, use, and disclosure. The directive's legal basis is Article 114 TFEU, which permits harmonization measures for the establishment and functioning of the internal market; this choice of legal basis – rather than Article 118 TFEU, which provides for creating unitary EU intellectual property rights – means the directive harmonizes divergent national laws rather than creating a supranational trade secret right. Article 17(2) of the Charter of Fundamental Rights of the European Union provides that "intellectual property shall be protected," establishing trade secrets protection as a fundamental right matter within the EU legal order. The directive implements the EU's obligations under Article 39 of the TRIPS Agreement, which requires WTO members to protect undisclosed information that is secret, has commercial value because it is secret, and has been subject to reasonable steps to keep it secret.

Article 2(1) of Directive 2016/943 defines "trade secret" as "information which meets all of the following requirements: (a) it is secret in the sense that it is not, as a body or in the precise configuration and assembly of its components, generally known among or readily accessible to persons within the circles that normally deal with the kind of information in question; (b) it has commercial value because it is secret; (c) it has been subject to reasonable steps under the circumstances, by the person lawfully in control of the information, to keep it secret." This three-part definition remained essentially unchanged from the Commission's November 2013 proposal through final adoption in June 2016, demonstrating consensus that the TRIPS Article 39 formulation provides an appropriate international standard. The European Parliament attempted during the ordinary legislative procedure to add requirements that commercial value be "actual or potential significant" and that reasonable steps be "demonstrable" and "verifiable by the relevant competent judicial authorities," but the trilogue negotiations rejected these amendments, preserving the Commission's original formulation.

The directive's structure establishes that all three requirements are cumulative – failure to satisfy any single element defeats trade secret status entirely. Recital 14 explains that "it is important to establish a homogenous definition of a trade secret without restricting the subject matter to be protected" and that the definition "should cover know-how, business information and technological information where there is both a legitimate interest in keeping them confidential and a legitimate expectation that such confidentiality will be preserved." The directive explicitly excludes certain information from protection: Article 1(3) provides that "nothing in this Directive shall be understood to offer any ground for restricting the mobility of employees" and specifically excludes "employees' use of information that does not constitute a trade secret," "employees' use of experience and skills honestly acquired in the normal course of their employment," and additional contractual restrictions beyond those imposed in accordance with Union or national law. Article 3 further establishes that acquisition of a trade secret is lawful when obtained by independent discovery or creation, observation or study of publicly available products, reverse engineering through disassembly or testing of lawfully possessed products, or any other practice conforming to honest commercial practices. As we will see, these exclusions and lawful acquisition provisions become particularly significant for AI prompts, where reverse engineering from outputs and independent discovery through experimentation are both technically feasible and increasingly common.

## Secrecy defeated by disclosure to cloud AI providers

The first element – secrecy in the sense that information is "not, as a body or in the precise configuration and assembly of its components, generally known among or readily accessible to persons within the circles that normally deal with the kind of information in question" – establishes an objective standard based on accessibility within relevant professional circles rather than requiring absolute secrecy. The Commission's Impact Assessment explained that this formulation allows situations where individual components may be publicly known but their specific combination or configuration remains secret; to that extent, a prompt constructed from publicly available techniques might still qualify if the precise assembly creates something not generally known. However, the secrecy requirement fundamentally requires that the information not be "readily accessible" to specialists in the field – and this is where AI prompts confront their most serious obstacle.

Cloud-based AI services – which represent the dominant deployment model for large language models as of October 2025 – require users to transmit prompts to third-party providers with each API call or chat interface interaction. OpenAI's GPT-4, Anthropic's Claude, Google's Gemini, and similar commercial offerings process prompts on the provider's infrastructure; the prompts necessarily travel across networks and reside, at least temporarily, on systems controlled by the AI provider rather than the user. Academic scholarship examining information flows in cloud computing contexts demonstrates that third-party disclosure potentially destroys trade secret status absent express or implied confidentiality agreements establishing duties not to use or disclose the information. Sharon K. Sandeen's analysis of cloud computing and trade secrets emphasizes that without contractual protections, information "known outside" the company by a service provider may lack the secrecy required for trade secret protection, and the information becomes "readily ascertainable" by the provider who possesses it.

The question thus becomes whether contractual confidentiality provisions in AI service agreements sufficiently preserve secrecy despite physical disclosure of prompts to the provider. Enterprise AI service agreements from major providers – such as Microsoft Azure OpenAI Service, Anthropic's enterprise plans, and Google Cloud's Vertex AI – typically include provisions stating that customer prompts and data will not be used to train models or disclosed to third parties. However, consumer-tier services – including the free ChatGPT interface and similar offerings – generally include terms of service permitting the provider to use inputs for model training and service improvement, representing a contractually authorized use that likely defeats trade secret status. German courts applying the Geschäftsgeheimnisgesetz (the German implementation of Directive 2016/943) have emphasized that disclosure to third parties without executed confidential disclosure agreements can result in loss of trade secret protection; the Higher Regional Court of Düsseldorf's 2021 decision established that vetting partners, ensuring minimum necessary disclosure, and maintaining executed NDAs constitute essential reasonable steps. Put differently, disclosure to a third party – even a service provider – without contractual confidentiality protections demonstrates that the information was not maintained as secret and fails both the secrecy element and the reasonable steps element.

National court decisions across Member States demonstrate strict application of the secrecy requirement in contexts involving third-party disclosure. The Dutch District Court Middle Netherlands in August 2018 held that technical drawings marked as confidential but shared with third parties without NDAs failed to qualify as trade secrets – the policy of maintaining secrecy existed, but the practice of unprotected disclosure defeated the claim. The Paris Court of Appeal in 2022 similarly held that sharing technical drawings with third parties without non-disclosure agreements failed the reasonable steps test, which necessarily implies that the information was not maintained as secret. To that extent, the judicial consensus across major tech hub jurisdictions – Germany, France, and the Netherlands – establishes that third-party disclosure without contractual protections defeats trade secret status regardless of other protective measures the holder may have implemented.

Applied to AI prompts, this doctrine creates a bright-line distinction: prompts submitted through enterprise AI services with contractual confidentiality protections potentially maintain secrecy (subject to the reasonable steps analysis discussed below), while prompts submitted through consumer-tier services without such protections fail the secrecy element and cannot qualify as trade secrets under EU law. This conclusion follows ineluctably from the principle that information disclosed to third parties without confidentiality agreements becomes "readily accessible" to those parties within the meaning of Article 2(1)(a), and specialists at AI providers – engineers, researchers, and data scientists who necessarily have at least potential access to user prompts – constitute "persons within the circles that normally deal with the kind of information in question." The secrecy element therefore establishes a threshold barrier: only prompts used exclusively through enterprise AI services with robust contractual confidentiality provisions can even potentially qualify as trade secrets.

## The puzzle of commercial value derived from proprietary models

The second element – that information "has commercial value because it is secret" – requires both that the information possess commercial value and that this value derive causally from the information's secrecy rather than from other characteristics. The Commission's Impact Assessment explained that information has commercial value "whether actual or potential" when "its unauthorized acquisition, use or disclosure is likely to harm the interests of the person lawfully controlling it, or where it undermines his or her scientific and technical potential, business or financial interests, strategic positions or ability to compete." Recital 14 of the directive emphasizes that the definition should cover information where there is "a legitimate interest in keeping them confidential and a legitimate expectation that such confidentiality will be preserved," and such information "should have a commercial value, whether actual or potential." The causal link – "because it is secret" – distinguishes trade secrets from other forms of valuable information; information that would retain its value even if publicly disclosed does not meet this requirement.

AI prompts present a distinctive challenge for the commercial value element because their utility depends fundamentally on the underlying large language model they instruct. A prompt engineered for ChatGPT produces value only when processed by OpenAI's GPT-4 or similar models; the same prompt applied to a different architecture may produce inferior results or fail entirely. This dependency raises the question whether prompts possess independent commercial value or merely derivative value that flows primarily from access to proprietary AI models. German courts have addressed this causal link question in other contexts – the Higher Regional Court of Düsseldorf held in 2021 that even if unauthorized use saves an infringer time or resources, if disclosure doesn't harm the holder's competitive position, the commercial value requirement may not be met. Applied to prompts, this suggests that if a prompt's value derives primarily from the underlying model rather than the prompt itself, and if disclosure of the prompt wouldn't harm the holder's competitive position because competitors lack access to the same model configuration, the commercial value element might fail.

However, three considerations support finding independent commercial value for sufficiently sophisticated prompts. First, the existence of commercial prompt marketplaces – PromptBase, FlowGPT, and similar platforms where users buy and sell prompts – demonstrates market recognition of prompts as valuable assets independent of any particular user's access to AI models. Prompts sold on these platforms derive value from their effectiveness across multiple users, each of whom has independent access to the underlying AI service; the prompt's value thus transcends any single user's model access. Second, specialized prompts that significantly improve output quality or efficiency provide measurable economic benefits – the pharmaceutical company vignette described prompts enabling 60% faster drug candidate identification, representing quantifiable time savings worth potentially millions of euros in accelerated research. Third, "system prompts" embedded in proprietary AI applications – instructions that customize how an AI model behaves within a specific application context – can represent substantial engineering investment and provide differentiation among competing products using the same underlying AI model.

The better view, therefore, distinguishes between simple prompts that any competent user could develop through brief experimentation – which lack the commercial value necessary for trade secret protection – and sophisticated prompts representing substantial investment in prompt engineering, testing, and refinement. The distinction parallels established trade secret doctrine protecting customer lists: publicly available contact information for individuals does not qualify as a trade secret, but a curated compilation of customers derived from substantial effort, investment, and analysis can qualify as a protectable compilation with commercial value deriving from the compilation itself rather than the individual data points. Similarly, individual prompting techniques may be publicly known, but a refined prompt representing months of optimization, A/B testing, and fine-tuning to achieve superior results constitutes a valuable compilation whose "precise configuration and assembly" – to use the language of Article 2(1)(a) – has commercial value because competitors lack this optimized formulation.

German courts applying the Geschäftsgeheimnisgesetz require objective proof that information has economic value, considering factors including value to the company, development costs, type of information, and importance to competitive position. The Higher Regional Court of Düsseldorf's nine-factor test for assessing trade secrets includes "value and development costs" and "importance to company" as distinct considerations, suggesting that even if information could theoretically be independently developed, the investment actually required to develop it contributes to its commercial value. Applied to AI prompts, this framework supports protecting prompts that represent substantial investment – documented development time, A/B testing costs, specialist salaries for prompt engineers – even if the prompts could theoretically be independently discovered, because the commercial value derives from avoiding the need to incur those development costs. To that extent, the commercial value element focuses not on whether information could be discovered independently in theory, but on whether the holder's actual investment in developing the information creates economic value that competitors could misappropriate by copying rather than independently investing.

The causal link – "because it is secret" – requires that disclosure would harm the holder's competitive advantage. For AI prompts, this test distinguishes between prompts whose disclosure would enable competitors to immediately replicate valuable outputs and prompts whose disclosure would provide minimal competitive benefit. Prompts that codify novel applications, combine techniques in non-obvious ways, or represent substantial optimization work satisfy this requirement because their disclosure allows competitors to appropriate the results of the holder's investment without incurring equivalent development costs. However, prompts that merely implement widely known techniques or achieve results that competitors have independently achieved fail this test – the value does not derive from secrecy because disclosure provides no competitive advantage. The commercial value element therefore operates as a filter, excluding trivial or widely known prompts while potentially protecting sophisticated prompts representing substantial investment and providing genuine competitive advantages to their holders.

## Reasonable steps in tension with cloud AI's distributed architecture  

The third element – that information "has been subject to reasonable steps under the circumstances, by the person lawfully in control of the information, to keep it secret" – requires trade secret holders to exercise what Recital 13 characterizes as a "duty of care as regards the preservation of the confidentiality of their valuable trade secrets." The "under the circumstances" qualifier establishes that the requirement is context-specific and proportionate, not absolute; the Commission's legislative history makes clear that measures need not be perfect or provide extreme security, and costs need not exceed the value of the secret. However, all Member State implementations and court decisions emphasize that holders must demonstrate actual protective measures, not merely stated policies – the Dutch court's pithy formulation that "policy without practice fails the reasonable steps test" captures the consensus approach across European jurisdictions.

German courts have developed the most detailed framework for assessing reasonable steps under the Geschäftsgeheimnisgesetz, establishing that protection requires measures at three levels: legal (non-disclosure agreements, employment contract provisions, contractual restrictions on partners), organizational (access restrictions, need-to-know policies, classification systems, employee training, exit procedures), and technical (passwords, encryption, access controls, authentication systems, monitoring). The Higher Regional Court of Düsseldorf's 2021 decision identified nine factors for proportionality assessment: type of trade secret, specific circumstances of use, value and development costs, nature of information, importance to company, size of company, usual confidentiality measures in the company, type of labeling or marking, and contractual provisions with employees and partners. French courts applying the Code de Commerce provisions implementing the directive emphasize that measures must be specific and targeted rather than blanket designations; generic "all information confidential" declarations in employment contracts are insufficient, and holders must specifically identify and mark confidential information, document protection measures taken, and implement both technical restrictions and contractual protections.

Applied to AI prompts, these requirements create significant challenges because the fundamental architecture of cloud AI services requires transmitting prompts across networks to third-party providers. The legal analytics firm in the opening vignette maintained NDAs, restricted internal access, and encrypted its prompt library – satisfying the legal and organizational prongs – but necessarily transmitted prompts to OpenAI's servers thousands of times daily through API calls. The pharmaceutical company's scientists used consumer ChatGPT accounts without confidentiality protections, clearly failing the reasonable steps test by disclosing prompts to a third party without contractual safeguards. The automotive manufacturer stored prompts in encrypted files accessible to only three senior engineers but still transmitted prompts to Anthropic's servers with each API call – potentially satisfying reasonable steps if, and only if, the manufacturer used Anthropic's enterprise service with contractual confidentiality protections.

The decisive question, then, is whether use of enterprise AI services with contractual confidentiality provisions, combined with internal controls on prompt access, constitutes "reasonable steps under the circumstances" or whether the necessity of transmitting prompts to third-party servers fundamentally defeats the secrecy requirement. National court guidance on third-party service providers suggests that contractual confidentiality provisions can suffice – the German courts' emphasis on "executed confidential disclosure agreements" implies that properly documented contractual protections with service providers satisfy reasonable steps even though the service provider necessarily accesses the information. The EUIPO's 2023 Trade Secrets Litigation Trends report notes that "reasonable steps" interpretation has shown significant development across Member States, with courts consistently requiring documented, implemented protection measures proportionate to the information's value.

However, the intersection of AI prompts with cloud computing reveals a structural tension: trade secret law developed in contexts where holders could maintain physical or at least exclusive digital control over secret information – customer lists in locked file cabinets, formulas in restricted laboratory notebooks, source code on access-controlled servers. Cloud AI services invert this model by requiring disclosure to third parties as a condition of using the information at all. The prompt cannot function without transmission to the AI provider's infrastructure; there is no equivalent to maintaining a chemical formula in a secured laboratory while using it in-house for manufacturing. To that extent, AI prompts represent a category of information where "reasonable steps" must necessarily include third-party disclosure, and the question becomes whether contractual protections can substitute for exclusive physical control.

The answer depends on the robustness of the contractual framework and its implementation. Enterprise AI agreements that contractually prohibit the provider from using prompts for any purpose other than processing the specific user's requests, that prohibit disclosure to other parties, that require deletion upon request, and that include audit rights allowing verification of compliance potentially satisfy the reasonable steps requirement – the holder has taken all measures feasible given the technical necessity of third-party processing. German courts' proportionality framework supports this conclusion: the nine-factor test includes "specific circumstances of use" as a factor, suggesting that if the information's use necessarily requires third-party involvement, reasonable steps must be assessed relative to that constraint rather than requiring impossible exclusive control. However, this conclusion requires documented evidence of the contractual protections, evidence that the enterprise service tier was selected rather than consumer services lacking such protections, internal controls limiting which employees can submit prompts and monitoring compliance, prompt sanitization procedures to remove unnecessary sensitive information before submission, and training ensuring employees understand the confidentiality framework.

Put differently, reasonable steps for AI prompts require a comprehensive protection program that acknowledges the necessity of third-party disclosure while minimizing associated risks: use exclusively of enterprise AI services with documented contractual confidentiality protections, internal access controls limiting who can create and submit prompts, technical measures including encryption in transit and at rest, classification systems identifying which prompts contain trade secret information, employee training on proper use of AI services, monitoring and audit procedures detecting unauthorized disclosure, and incident response plans addressing breaches. These measures parallel the protections German courts require for traditional trade secrets but adapted to accommodate the distributed architecture of cloud AI. This is straightforward as a doctrinal matter – reasonable steps must be "under the circumstances," and the circumstances of AI prompt use include technical necessity of third-party processing – but demanding as a practical matter, requiring substantial investment in legal, organizational, and technical infrastructure that many businesses have not yet implemented.

## Counterarguments: why prompts likely fail trade secret protection

Three principal arguments challenge whether AI prompts can or should qualify as trade secrets under Directive 2016/943, each rooted in fundamental characteristics of AI systems and trade secret doctrine. First, prompts may be insufficiently secret because they are too easily reverse-engineered from AI outputs, failing Article 2(1)(a)'s requirement that information be "not readily accessible." Second, prompts may lack the independent commercial value Article 2(1)(b) requires because their value derives primarily from underlying proprietary AI models rather than the prompts themselves. Third, reasonable steps may be structurally impossible for cloud-based AI prompts, defeating Article 2(1)(c), because the fundamental architecture requires disclosure to third parties in ways that existing trade secret doctrine has not accommodated.

The reverse engineering challenge rests on recent technical research demonstrating that effective prompts can be reconstructed from observing only a small number of AI outputs. Academic computer science research published in 2024 describes "reverse prompt engineering" techniques that reconstruct original prompts from as few as five text outputs using black-box, zero-shot methods that leverage the language model itself as an optimizer – the technique achieved prompts 5.8% closer in cosine similarity to originals than previous state-of-the-art methods. Earlier approaches including "logit2prompt" using next-token probability distributions and "output2prompt" requiring 64 outputs have established that prompt inference from outputs is not merely theoretical but practically achievable with commercially available tools. If prompts are reliably reconstructible from publicly available outputs through techniques that Article 3(1)(b) of the directive explicitly recognizes as lawful – "observation, study, disassembly or testing of a product or object that has been made available to the public or that is lawfully in the possession of the acquirer" – then prompts fail the secrecy requirement because they are "readily accessible" through proper means to any competitor willing to invest in reverse engineering.

This argument draws additional strength from Recital 16 of the directive, which provides that "in the interest of innovation and to foster competition, the provisions of this Directive should not create any exclusive right to know-how or information protected as trade secrets" and explicitly states that "reverse engineering of a lawfully acquired product should be considered as a lawful means of acquiring information, except when otherwise contractually agreed." The directive thus establishes a policy preference for permitting reverse engineering, and the ease with which prompts can be inferred from outputs suggests that the directive's drafters would not have intended to grant trade secret protection to information so readily reconstructible. Moreover, the widespread practice within the AI community of sharing and discussing effective prompts – exemplified by prompt marketplaces, online repositories, and technical forums where users freely exchange prompting techniques – demonstrates that prompts are not treated as confidential in industry practice, undermining claims that particular prompts meet the "not generally known among or readily accessible to persons within the circles that normally deal with the kind of information in question" standard.

The independent commercial value challenge contends that prompts function more like instructions for using a tool than like the tool itself, and that trade secret protection should not extend to mere usage instructions that derive their value entirely from proprietary tools owned by others. A prompt for ChatGPT is worthless without access to OpenAI's GPT-4 model; the pharmaceutical company's drug candidate identification prompts provide value only because Claude processes them, and Claude's capabilities derive from Anthropic's billions of dollars in model development investment rather than from the user's prompt engineering work. This dependency distinguishes prompts from paradigmatic trade secrets like chemical formulas or manufacturing processes, which have value independent of any third party's proprietary assets – a formula for a drug compound has value regardless of who manufactures it, and a manufacturing process has value to whoever controls the manufacturing facility. Prompts, by contrast, are entirely dependent on and subordinate to the underlying AI models, suggesting that any commercial value actually derives from model access rather than prompt design.

Furthermore, the high probability of independent discovery undermines commercial value claims for most prompts. Because prompt engineering is a relatively low-barrier skill – requiring no specialized equipment, no substantial capital investment, and no rare expertise – competitors can reasonably be expected to independently discover similar or functionally equivalent prompts through their own experimentation. The directive's Article 3(1)(a) explicitly recognizes "independent discovery or creation" as lawful, and if effective prompts for common tasks can be independently discovered by competent users within weeks or months of experimentation, the information lacks the durability and exclusivity characteristic of traditional trade secrets. Chemical formulas may remain secret for decades; manufacturing processes may resist independent discovery indefinitely; but AI prompts face the constant risk that competitors will independently converge on similar solutions through parallel experimentation, suggesting that the information's commercial value does not truly derive from its secrecy but rather from the prompter's access to the underlying model.

The structural impossibility argument contends that the "reasonable steps" requirement cannot be satisfied for information that must be disclosed to third-party cloud providers as a condition of use, and that extending trade secret protection to such information would distort the doctrine beyond its coherent boundaries. Trade secret law developed to protect information that holders could maintain under their exclusive physical or digital control – the formula kept in a vault, the customer list on a password-protected server, the manufacturing process known only to employees under strict NDAs. Cloud AI inverts this model by requiring disclosure as a precondition of use; the information must leave the holder's control and reside on third-party infrastructure to function at all. Even with contractual confidentiality provisions, the AI provider possesses the information, can technically access it, and represents a potential point of failure through security breaches, employee misconduct, or contractual breach.

This structural characteristic distinguishes AI prompts from other information processed by third-party service providers – payroll data sent to processing companies, tax information shared with accountants, or manufacturing specifications sent to contract manufacturers – because those third parties process the information but do not require the information to provide the service. A payroll processor could calculate employee payments with generic test data; an AI model cannot process a prompt without receiving the actual prompt. To that extent, the information disclosed to AI providers is not incidental to the service but constitutes the core input the service processes, creating a fundamental dependency incompatible with maintaining information as secret. Moreover, the potential for AI providers to inadvertently or deliberately use prompts for model training, to learn from aggregated prompt patterns across users, or to face legal obligations to disclose prompts to regulators or in litigation creates risks that no amount of contractual protection can fully eliminate – the information has entered a domain beyond the holder's exclusive control in ways that trade secret law has not traditionally accommodated.

These three challenges – insufficient secrecy due to reverse engineering, lack of independent commercial value, and structural impossibility of reasonable steps – collectively suggest that AI prompts represent a poor fit for trade secret protection under existing EU law. The directive's three-part test developed to protect information holders can maintain as genuinely confidential; prompts necessarily disclosed to cloud providers fall outside this paradigm. However, these arguments face responsive challenges that reveal the doctrinal question's complexity rather than definitively resolving it.

## Resolution: limited protection for sophisticated prompts under enterprise frameworks

The arguments against trade secret protection for AI prompts carry substantial force, but they prove too much – if accepted fully, they would also eliminate protection for other categories of information that Directive 2016/943 was clearly intended to protect. Software source code can be reverse-engineered from compiled binaries through decompilation and analysis, yet courts routinely recognize source code as protectable trade secrets; customer lists can be independently discovered through market research, yet compilations of customer information qualify as trade secrets when they represent substantial investment; business methods must be disclosed to employees and sometimes partners to be implemented, yet they remain protectable subject to reasonable confidentiality measures. The question is not whether AI prompts present distinctive challenges – they plainly do – but whether these challenges render protection impossible or merely demanding.

The Court of Justice of the European Union's decision in Case C-203/22, Dun \u0026 Bradstreet Austria, decided on 27 February 2025, provides crucial guidance on the intersection between algorithmic information and trade secret protection, though the case addressed GDPR transparency obligations rather than trade secret validity directly. The CJEU held that controllers using automated decision-making systems must provide "meaningful information about the logic involved" but need not disclose the algorithm itself; trade secret protection under Directive 2016/943 can justify withholding detailed algorithmic information from data subjects, though not from supervisory authorities or courts conducting proportionality assessments. The Court established that when a controller claims information contains trade secrets, the controller must provide allegedly protected information to the competent supervisory authority or court, which then balances competing rights and interests on a case-by-case basis – Austrian law creating a blanket exemption for trade secrets was impermissible. The decision thus acknowledges that algorithmic information including the logical instructions that control AI system behavior can qualify as trade secrets while emphasizing that protection is not absolute and must yield to competing fundamental rights and transparency obligations where proportionality requires.

Applied to AI prompts, the Dun \u0026 Bradstreet framework suggests that prompts can in principle qualify as trade secrets but face heightened scrutiny when their protection conflicts with transparency requirements under the GDPR, the AI Act, or other regulatory frameworks. The decision's emphasis on case-by-case balancing rather than categorical rules supports a nuanced approach that distinguishes between simple prompts offering minimal innovation and sophisticated prompts representing substantial investment and genuine competitive advantage. This parallels the Court's treatment of algorithms themselves – not categorically excluded from protection, but subject to disclosure requirements where fundamental rights or regulatory transparency obligations outweigh commercial confidentiality interests.

The resolution must therefore distinguish among prompt categories. First, simple prompts that any competent user could develop through minimal experimentation – basic formatting instructions, common prompting techniques, straightforward queries – do not qualify as trade secrets because they fail all three elements: they are "generally known" within professional circles using AI systems, lack commercial value because competitors can independently discover them trivially, and cannot justify substantial protective measures given their minimal value. These prompts resemble individual entries in a customer list – the format "Dear [Name]" or the technique of asking an AI to "explain in simple terms" is public knowledge, and compiling such techniques provides no more protection than collecting publicly available contact information.

Second, intermediate prompts representing modest optimization or specialization – domain-specific queries, tested formulations that improve reliability, or structured templates that standardize outputs – occupy ambiguous territory. These prompts might satisfy the commercial value element if they represent genuine efficiency improvements, and they might satisfy the secrecy element if not widely shared, but they face challenges under the reasonable steps requirement because the investment required to protect them (comprehensive legal, organizational, and technical measures) may exceed their value, failing proportionality. Moreover, the high probability of independent discovery for intermediate prompts – any competent practitioner working in the same domain will likely develop similar approaches – undermines claims that value derives from secrecy rather than from general domain expertise.

Third, sophisticated prompts representing substantial investment – months of prompt engineering work, extensive A/B testing, quantified performance improvements, integration into proprietary systems, or novel applications of AI capabilities – can potentially qualify as trade secrets if, and only if, used exclusively through enterprise AI services with robust contractual confidentiality provisions and subject to comprehensive internal protection measures. These prompts satisfy the secrecy element because, despite third-party disclosure to the AI provider, contractual prohibitions on use or disclosure render the information "not readily accessible" to competitors – the AI provider is contractually bound not to use prompts for training or disclose them to others, functionally limiting access as effectively as physical security measures. They satisfy the commercial value element because substantial investment in development creates value that competitors could misappropriate by copying rather than independently investing, and because documented performance improvements demonstrate economic worth. They satisfy the reasonable steps element through the comprehensive protection framework outlined above: enterprise service agreements, internal access controls, technical measures including encryption, classification systems, employee training, and monitoring.

This resolution draws support from German courts' proportionality framework under the Geschäftsgeheimnisgesetz, which requires balancing protection measures against information value and considering "specific circumstances of use." If prompts have substantial value (documented through development costs and performance improvements), and if their use necessarily requires third-party processing (inherent in cloud AI architecture), then reasonable steps must be assessed relative to these constraints – demanding exclusive physical control would be impossible, but requiring the maximum feasible protection given technical constraints is both possible and proportionate. The Dutch court's emphasis on actual practice over stated policy requires not merely adopting formal protection programs but implementing and enforcing them – employees who share prompts via consumer AI services in violation of company policy demonstrate that reasonable steps have not been taken in practice, regardless of written policies.

To that extent, the answer to whether AI prompts qualify as trade secrets under EU law depends critically on prompt sophistication and protection rigor: simple prompts categorically fail to qualify; sophisticated prompts representing substantial investment can qualify if subjected to comprehensive protection measures including exclusive use of enterprise AI services with contractual confidentiality provisions, internal access controls, technical protections, and documented enforcement; intermediate prompts face case-by-case assessment where proportionality and independent discovery probability will often defeat protection claims. This framework harmonizes with the directive's policy objectives – encouraging investment in valuable information while permitting reverse engineering, independent discovery, and employee mobility – by protecting genuine innovation while refusing protection to trivial or widely known techniques.

However, the framework faces two unresolved tensions that will require either CJEU clarification or legislative amendment to fully resolve. First, no CJEU decision has directly interpreted Directive 2016/943's three-part test – the directive entered into force in 2016 with a June 2018 transposition deadline, and as of October 2025, no preliminary ruling under Article 267 TFEU has addressed core definitional questions. National courts applying German, French, Dutch, and Irish implementing legislation have developed divergent approaches to "reasonable steps" in particular, with Germany's nine-factor proportionality test, the Netherlands' stringent practice-over-policy requirement, and France's procedural protections representing different doctrinal emphases. Until the CJEU addresses whether third-party disclosure with contractual protections can satisfy the secrecy and reasonable steps requirements, cross-border uncertainty will persist – prompts qualifying as trade secrets in Germany under proportionality analysis might fail in the Netherlands under the stringent practice-focused test.

Second, the intersection between trade secret protection and AI transparency requirements under the AI Act remains incompletely theorized. The AI Act imposes transparency obligations on high-risk AI systems including technical documentation, training data disclosure, and deployment logs – Recital provisions acknowledge that trade secret information "should be safeguarded" but provide no detailed operational guidance on balancing commercial confidentiality against regulatory transparency. Academic scholarship analyzing this tension argues that trade secrets and transparency mandates "directly stand at odds with critical constitutional concepts," and the EUIPO's 2023 Trade Secrets Litigation Trends report notes that developments are needed to clarify the potential role of trade secrets in the data economy. The Dun \u0026 Bradstreet decision provides a framework – case-by-case balancing by authorities or courts – but implementing this framework for AI Act compliance will require either Commission guidance or judicial decisions establishing when transparency obligations override trade secret protection.

Put differently, AI prompts can qualify as trade secrets under current EU law, but only sophisticated prompts subjected to rigorous protection measures, and even then subject to potential displacement by transparency requirements under the GDPR, AI Act, or other regulatory frameworks where fundamental rights or public interest considerations outweigh commercial confidentiality. The legal framework accommodates prompt protection within existing doctrine by treating third-party disclosure with contractual safeguards as consistent with secrecy and reasonable steps, but this accommodation is contestable and has not been tested through CJEU interpretation. Businesses seeking to protect valuable prompt engineering work must implement comprehensive protection programs exceeding the rigor typical for traditional trade secrets, and must prepare for the possibility that courts will require disclosure where transparency obligations so demand – trade secret protection for prompts exists under EU law, but it is conditional, demanding, and ultimately provisional pending authoritative judicial interpretation.