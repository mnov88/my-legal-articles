# Verification of Claims about the "Practice Report" (unpublished draft)

| Claim from the outline (summarising what the draft claims)                                                                                                                                                                                | Evidence that the draft actually makes this claim                                                         | External verification (key sources & citations)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                | Credibility of external sources & notes                                                                                                                                                                                                                                                                                                                                                                      |
| ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | --------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |
| **Student adoption is near‑universal & growing: 86–92% of students use AI.** The outline says the practice report shows surveys (e.g., HEPI, DEC) reporting 92% of UK undergraduates using AI and 86% of students in 16 countries use AI. | The practice report cites survey data (Table 1) summarising multiple surveys.                             | HEPI’s 2025 _Student Generative AI Survey_ reports that **92 %** of UK students used at least one AI tool, up from 66 % the previous year[[1]](https://www.hepi.ac.uk/reports/student-generative-ai-survey-2025/#:~:text=,with%20Kortext). The Digital Education Council’s global survey (16 countries) found **86 %** of students regularly use AI in their studies[[2]](https://www.digitaleducationcouncil.com/post/what-students-want-key-results-from-dec-global-ai-student-survey-2024#:~:text=86,Global%20AI%20Student%20Survey%20found). Another blog citing the same survey notes 24 % daily use and 54 % weekly use[[3]](https://www.ucanwest.ca/blog/education-careers-tips/advantages-and-disadvantages-of-ai-in-education#:~:text=traditional%20teaching%20jobs). | HEPI is an independent UK policy institute and the survey was conducted with polling firm YouthSight; DEC’s survey covered 3,800 students in 16 countries; both are credible. The daily/weekly usage numbers come from DEC and a university blog quoting it[[3]](https://www.ucanwest.ca/blog/education-careers-tips/advantages-and-disadvantages-of-ai-in-education#:~:text=traditional%20teaching%20jobs). |
| **Students use AI mainly to “save time” (51 %) and “improve quality” (50 %).**                                                                                                                                                            | Report Table 1 summarises HEPI survey results.                                                            | HEPI’s report notes that the main reasons students use AI are **saving time (51 %)** and **improving work quality (50 %)**[[4]](https://www.hepi.ac.uk/reports/student-generative-ai-survey-2025/#:~:text=,50).                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                | The HEPI survey is primary research; numbers are directly reported and therefore credible.                                                                                                                                                                                                                                                                                                                   |
| **Students feel unprepared: 58 % say they lack AI skills and 48 % do not feel ready for an AI‑enabled workforce.**                                                                                                                        | Draft cites DEC survey.                                                                                   | The DEC Global AI Student Survey reports that **58 %** of students felt they lacked sufficient AI knowledge and skills and **48 %** felt inadequately prepared for an AI‑enabled workplace[[5]](https://www.digitaleducationcouncil.com/post/what-students-want-key-results-from-dec-global-ai-student-survey-2024#:~:text=86,Global%20AI%20Student%20Survey%20found).                                                                                                                                                                                                                                                                                                                                                                                                         | DEC’s survey covered 3,800 students across 16 countries and is public. Credible, though details are not peer‑reviewed.                                                                                                                                                                                                                                                                                       |
| **80 % of students believe their university’s AI integration does not meet expectations.**                                                                                                                                                | Draft cites DEC survey.                                                                                   | The DEC article notes that 80 % of students said AI in universities “are not fully meeting expectations”[[6]](https://www.digitaleducationcouncil.com/post/what-students-want-key-results-from-dec-global-ai-student-survey-2024#:~:text=in%20their%20universities%2C%20but%20are,are%20not%20fully%20meeting%20expectations).                                                                                                                                                                                                                                                                                                                                                                                                                                                 | Same DEC survey. Reliable for perception data but not peer‑reviewed.                                                                                                                                                                                                                                                                                                                                         |
| **Students’ AI use for assessments jumped from 53 % to 88 % in one year.**                                                                                                                                                                | Report highlights this as evidence of rapid adoption.                                                     | HEPI key findings show that the proportion of students using generative AI for assessments rose from **53 %** in 2024 to **88 %** in 2025[[7]](https://www.hepi.ac.uk/reports/student-generative-ai-survey-2025/#:~:text=Key%20findings%3A).                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   | HEPI survey credible; indicates rapid year‑over‑year increase.                                                                                                                                                                                                                                                                                                                                               |
| **Faculty adoption is much lower: 61 % of faculty have used AI but 88 % of those do so “minimally”.**                                                                                                                                     | Draft cites the 2025 Global AI Faculty Survey.                                                            | The Campbell University meta‑summary of recent surveys notes that the DEC 2025 Global AI Faculty Survey found **61 %** of faculty had used AI in teaching, but **88 %** of those reported minimal use[[8]](https://sites.campbell.edu/academictechnology/2025/03/06/ai-in-higher-education-a-summary-of-recent-surveys-of-students-and-faculty/#:~:text=is%20increasing%2C%20but%20still%20lags,applications%20of%20AI%20in%20education).                                                                                                                                                                                                                                                                                                                                      | Campbell University summary aggregates multiple surveys; DEC survey covers 1,681 faculty from 28 countries. Credible but not peer‑reviewed.                                                                                                                                                                                                                                                                  |
| **Only 17 % of faculty rate their AI literacy as advanced or expert; 40 % say they are just beginning.**                                                                                                                                  | Draft cites the same survey.                                                                              | The Campbell University summary reports that **40 %** of faculty felt they were just beginning their AI literacy journey and only **17 %** were at an advanced or expert level[[9]](https://sites.campbell.edu/academictechnology/2025/03/06/ai-in-higher-education-a-summary-of-recent-surveys-of-students-and-faculty/#:~:text=The%20Digital%20Education%20Council%E2%80%99s%20faculty,AI%20usage%20and%20low%20AI).                                                                                                                                                                                                                                                                                                                                                         | The DEC survey is credible for perceptions, but methodology details are not fully available.                                                                                                                                                                                                                                                                                                                 |
| **59 % of higher‑education leaders think recent graduates are unprepared for workplaces using AI.**                                                                                                                                       | Draft cites AAC&U/Elon University survey.                                                                 | Campbell’s summary notes that in an AAC&U and Elon University survey, **59 %** of leaders believed that last spring’s graduates were not prepared for work in companies where AI tools are important[[10]](https://sites.campbell.edu/academictechnology/2025/03/06/ai-in-higher-education-a-summary-of-recent-surveys-of-students-and-faculty/#:~:text=sufficient%20AI%20knowledge%20and%20skills%2C,9).                                                                                                                                                                                                                                                                                                                                                                      | AAC&U and Elon survey details are not provided in full; however, this aligns with widely reported concerns.                                                                                                                                                                                                                                                                                                  |
| **39 % of institutions have AI‑use policies (up from 23 %), indicating slow institutional response.**                                                                                                                                     | Draft cites an EDUCAUSE statistic.                                                                        | The Anara “AI in Higher Education Statistics” report cites EDUCAUSE data: **39 %** of institutions had AI‑related acceptable‑use policies in 2025, up from **23 %** the previous year[[11]](https://anara.com/blog/ai-in-education-statistics#:~:text=%2A%2057,7%20Cengage).                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   | EDUCAUSE is a trusted higher‑education IT association; the figure is credible, though context (sample, methodology) is not detailed.                                                                                                                                                                                                                                                                         |
| **AI‑generated lesson plans are moderate‑to‑low quality and rarely promote higher‑order thinking.**                                                                                                                                       | Draft summarises Table 2, Use Case 1.                                                                     | A peer‑reviewed study in _CITE Journal_ evaluated 310 AI‑generated lesson plans for eighth‑grade civics. Nearly **half** of all learning activities were coded at the “remember” level, and the majority of plans were **moderate to low quality**, with few opportunities for analysis or creation[[12]](https://citejournal.org/volume-25/issue-3-25/social-studies/civic-education-in-the-age-of-ai-should-we-trust-ai-generated-lesson-plans/#:~:text=First%2C%20across%20all%20AI,2023%2C%20Polikoff%20%26%20Dean).                                                                                                                                                                                                                                                       | This is a scholarly article; credible evidence that AI lesson plans often fail to engage higher‑order thinking.                                                                                                                                                                                                                                                                                              |
| **AI‑generated assessments lack empirical validation.**                                                                                                                                                                                   | Draft claims current research has not evaluated the quality/fairness of AI‑generated quizzes and rubrics. | Emerging research contradicts a blanket statement that there is “no evidence.” A 2025 study in _BMC Medical Education_ generated 220 single‑best‑answer (SBA) questions with GPT‑4 and found that **69 %** were fit for inclusion after expert review and that AI‑generated questions performed comparably to human‑authored items[[13]](https://bmcmededuc.biomedcentral.com/articles/10.1186/s12909-025-06881-w#:~:text=The%20screening%20process%20revealed%20that,of%20facility%20and%20discrimination%20index). Another study (field trial) reported that AI‑generated exam questions performed comparably to expert‑created questions after screening[[14]](https://bmcmededuc.biomedcentral.com/articles/10.1186/s12909-025-06881-w#:~:text=Summary%20of%20results).    | These studies show that AI‑generated assessments can be valid if quality‑controlled, so the draft’s claim is overstated. However, the body of evidence is still small; more validation is needed.                                                                                                                                                                                                            |
| **AI tutoring / chatbots deliver very large learning gains (Hedges g ≈ 1.02).**                                                                                                                                                           | Draft cites Use Case 6.                                                                                   | A 2025 meta‑analysis on AI in education reported a significant overall effect size (**g = 0.86**) and found that chatbots and generative AI produced the **largest effect (g = 1.02, 95 % CI 0.45–1.59)**[[15]](https://files.eric.ed.gov/fulltext/EJ1465704.pdf#:~:text=a%20significant%20positive%20effect%20size,most%20substantial%20positive%20impact%20on).                                                                                                                                                                                                                                                                                                                                                                                                              | The meta‑analysis follows PRISMA guidelines and synthesizes multiple studies; effect sizes are credible.                                                                                                                                                                                                                                                                                                     |
| **Students trust AI feedback less when they know it’s AI‑generated (“credibility crisis”).**                                                                                                                                              | Draft references a study by Lee & Moore (2024).                                                           | An arXiv study comparing human, AI and co‑produced feedback found that students preferred AI feedback when the source was blinded but showed a **strong bias against AI** when the source was disclosed; only AI feedback suffered a decline in perceived genuineness[[16]](https://arxiv.org/pdf/2504.10961#:~:text=Findings%20revealed%20that%20when%20the,produced%20feedback).                                                                                                                                                                                                                                                                                                                                                                                             | This is a preprint (not yet peer‑reviewed) but provides experimental evidence of bias. It cautions that students’ perceptions may reduce the impact of AI feedback.                                                                                                                                                                                                                                          |
| **AI can both enhance and harm critical thinking; frequency of use is unrelated to critical thinking skills, but using AI for reflective thinking improves critical‑thinking development.**                                               | Draft summarises Part III.1.                                                                              | A systematic review of 19 studies concluded that ChatGPT can enhance students’ critical thinking but **over‑reliance** can reduce motivation for self‑reflection and critical evaluation[[17]](https://files.eric.ed.gov/fulltext/EJ1459623.pdf#:~:text=Results%3A%20Findings%20reveal%20that%20ChatGPT,generated%20content). An MDPI study (Xu et al., 2025) found that **usage frequency of AI was unrelated to critical‑thinking disposition**, but **using AI for reflective thinking** was positively associated with critical‑thinking skills[[18]](https://www.mdpi.com/2227-7102/15/8/977#:~:text=motivation%20are%20more%20inclined%20to,that%20Hypothesis%203%20is%20valid).                                                                                         | The systematic review is peer‑reviewed and synthesizes multiple studies; the MDPI article is a peer‑reviewed empirical study. Both are credible.                                                                                                                                                                                                                                                             |
| **Students using large language models (LLMs) for research focus on a narrower set of ideas than those using traditional search; analyses become more biased and superficial.**                                                           | Draft cites this to explain cognitive harm.                                                               | Duke University’s AI ethics toolkit summarizes research noting that in one study students using LLMs focused on a **narrower set of ideas** and produced more biased, superficial analyses compared with those using traditional search[[19]](https://lile.duke.edu/ai-ethics-learning-toolkit/does-ai-harm-critical-thinking/#:~:text=compared%20to%20those%20students%20using,do%20not%20outsource%20their%20judgment).                                                                                                                                                                                                                                                                                                                                                      | This is a blog summarizing research; it does not cite the original study by name. It is not a peer‑reviewed source, but Duke Learning Innovation is a reputable academic center. Without the primary study, this evidence is suggestive rather than definitive.                                                                                                                                              |
| **AI systems can serve as metacognitive scaffolds: students use AI to plan, monitor and evaluate their learning; structured reflection requirements in AI‑enhanced practice exams improve self‑regulated learning.**                      | Draft cites Part III.2 and Part III.2.                                                                    | A Scientific Reports study analysed 834 reflective journals and found that students used AI as a **metacognitive scaffold**, externalizing planning and monitoring strategies[[20]](https://pmc.ncbi.nlm.nih.gov/articles/PMC12508024/#:~:text=quasi,31%29%2C%20which%20are%20large%20effect). An AI‑enhanced practice exam system required students to **explain their reasoning and rate confidence** before receiving feedback; this design increased textbook engagement, confidence and recall, suggesting structured reflection may be more impactful than sophisticated AI feedback[[21]](https://arxiv.org/html/2505.13381v1#:~:text=40,impactful%20than%20sophisticated%20feedback%20mechanisms).                                                                     | The journal article and conference paper are peer‑reviewed. They provide credible evidence that AI can support metacognition when tasks explicitly require reflection.                                                                                                                                                                                                                                       |
| **AI‑enhanced social‑emotional learning (SEL) frameworks boost engagement and emotional well‑being; students view AI as a non‑judgmental safety net.**                                                                                    | Draft cites Part III.3.                                                                                   | A 2025 study in the _European Journal of Education_ surveyed 816 Chinese EFL students; it found that an AI‑enhanced SEL framework **significantly boosted student engagement and emotional well‑being**, improving emotional regulation and focus[[22]](https://www.researchgate.net/publication/387956529_How_AI_-Enhanced_Social-Emotional_Learning_Framework_Transforms_EFL_Students'_Engagement_and_Emotional_Well-Being#:~:text=This%20study%20explores%20the%20transformative,creates%20a%20more%20emotionally%20supportive). Qualitative reports also note that students describe AI tutors as a **“safety net”** that reduces anxiety[[20]](https://pmc.ncbi.nlm.nih.gov/articles/PMC12508024/#:~:text=quasi,31%29%2C%20which%20are%20large%20effect).                 | The SEL study is peer‑reviewed; qualitative insights are from a separate study. Both support the claim.                                                                                                                                                                                                                                                                                                      |
| **There is a proposed “personalisation without isolation” model: AI handles individual practice so class time can focus on social learning; however, this model lacks empirical validation.**                                             | Draft identifies this as an unmet research need (Gap 1).                                                  | A Times of India article describes the **“personalisation without isolation”** approach, where AI adjusts practice and teachers orchestrate discussion[[23]](https://timesofindia.indiatimes.com/education/news/ai-in-classrooms-friend-or-foe-benefits-boundaries-and-why-learning-is-still-a-human-act/articleshow/124956167.cms#:~:text=Personalisation%20without%20isolation,defend%20their%20solutions%2C%20not%20just). The article is journalistic and does not present empirical evaluation. No peer‑reviewed studies implementing this model were found.                                                                                                                                                                                                              | The lack of empirical studies supports the draft’s claim that this social‑learning model remains unvalidated.                                                                                                                                                                                                                                                                                                |
| **The sensory dimension of AI‑generated content (e.g., multisensory materials) is under‑researched in higher education.**                                                                                                                 | Draft notes this as Gap 4.                                                                                | Searches reveal few empirical studies on AI generating multisensory educational content for higher education. Existing works focus on K‑12 tools (e.g., AI sensory activities generators) or theoretical proposals; no peer‑reviewed studies specifically evaluating sensory‑rich AI‑generated materials in higher education were found.                                                                                                                                                                                                                                                                                                                                                                                                                                       | Absence of evidence in scholarly databases supports the claim that this dimension is a research gap.                                                                                                                                                                                                                                                                                                         |
| **Research gaps include (1) validation of social‑learning models, (2) quality/fairness of AI‑generated assessments, (3) longitudinal effects of AI use, (4) sensory dimension, and (5) equity and algorithmic bias.**                     | Draft summarises Part IV.                                                                                 | Evidence gathered supports these gaps: there are few empirical studies on social models, AI‑generated assessment quality is only beginning to be tested[[13]](https://bmcmededuc.biomedcentral.com/articles/10.1186/s12909-025-06881-w#:~:text=The%20screening%20process%20revealed%20that,of%20facility%20and%20discrimination%20index), most studies are short‑term, the sensory dimension is under‑researched, and equity/bias concerns are noted in several surveys.                                                                                                                                                                                                                                                                                                       | This synthesis is reasonable; it aligns with our literature scan.                                                                                                                                                                                                                                                                                                                                            |
| **MIT preprint “Your Brain on ChatGPT” suggests ChatGPT leads to cognitive harm: LLM users show the weakest neural connectivity, produce homogeneous writing and struggle to recall their own AI‑assisted prose.**                        | Draft cites Part I as evidence of cognitive harm.                                                         | The MIT Media Lab preprint _Your Brain on ChatGPT_ reports that participants using LLM assistance exhibited the **weakest neural coupling** compared with search‑engine and brain‑only groups; their essays were more homogeneous (fewer unique ideas) and participants struggled to recall text they had just written[[24]](https://www.media.mit.edu/projects/your-brain-on-chatgpt/overview/#:~:text=strategies,they%20wrote%20just%20minutes%20prior). The preprint authors caution that the results are preliminary and not yet peer‑reviewed[[25]](https://www.media.mit.edu/projects/your-brain-on-chatgpt/overview/#:~:text=uploaded%20to%20Arxiv%2C%20the%20preprint,with%20caution%20and%20as%20preliminary).                                                        | The study is a preprint, so its findings should be treated cautiously. It provides suggestive evidence but has not undergone peer review; sample size (54 participants) is limited.                                                                                                                                                                                                                          |
| **Short‑term gains, long‑term gaps: GenAI and search tools improve immediate performance on lower‑order tasks but not retention, and do not enhance higher‑order tasks.**                                                                 | Draft cites Part I for long‑term retention concerns.                                                      | A quasi‑experimental study (_Short‑Term Gains, Long‑Term Gaps_) compared ChatGPT, Google search and e‑textbook groups. ChatGPT and Google groups outperformed the control on immediate lower‑order tasks but **their advantage disappeared over time**; retention scores converged and control participants had the highest retention[[26]](https://scale.stanford.edu/ai/repository/short-term-gains-long-term-gaps-impact-genai-and-search-technologies-retention#:~:text=Taxonomy,The%20study). For higher‑order tasks, no significant differences were observed[[27]](https://scale.stanford.edu/ai/repository/short-term-gains-long-term-gaps-impact-genai-and-search-technologies-retention#:~:text=outperformed%20the%20control%20group%20in,driven).                   | This study is published via Stanford’s SCALE Initiative repository and on arXiv; it provides experimental evidence but may still be under review. Credible for suggesting short‑term vs. long‑term differences.                                                                                                                                                                                              |
| **AI‑generated assessment items lack quality/fairness research.**                                                                                                                                                                         | Draft states there is little validation.                                                                  | As noted above, recent studies show AI‑generated exam questions can be valid after quality control[[13]](https://bmcmededuc.biomedcentral.com/articles/10.1186/s12909-025-06881-w#:~:text=The%20screening%20process%20revealed%20that,of%20facility%20and%20discrimination%20index). Another 2024 field study found AI‑generated questions performed comparably to expert‑written ones (not shown above, but reported in practice report).                                                                                                                                                                                                                                                                                                                                     | Evidence now exists, so the draft’s blanket claim is outdated; however, the body of evidence is still small and limited to specific domains (e.g., medicine).                                                                                                                                                                                                                                                |

---

[[1]](https://www.hepi.ac.uk/reports/student-generative-ai-survey-2025/#:~:text=,with%20Kortext) [[4]](https://www.hepi.ac.uk/reports/student-generative-ai-survey-2025/#:~:text=,50) [[7]](https://www.hepi.ac.uk/reports/student-generative-ai-survey-2025/#:~:text=Key%20findings%3A) Student Generative AI Survey 2025 - HEPI

[https://www.hepi.ac.uk/reports/student-generative-ai-survey-2025/](https://www.hepi.ac.uk/reports/student-generative-ai-survey-2025/)

[[2]](https://www.digitaleducationcouncil.com/post/what-students-want-key-results-from-dec-global-ai-student-survey-2024#:~:text=86,Global%20AI%20Student%20Survey%20found) [[5]](https://www.digitaleducationcouncil.com/post/what-students-want-key-results-from-dec-global-ai-student-survey-2024#:~:text=86,Global%20AI%20Student%20Survey%20found) [[6]](https://www.digitaleducationcouncil.com/post/what-students-want-key-results-from-dec-global-ai-student-survey-2024#:~:text=in%20their%20universities%2C%20but%20are,are%20not%20fully%20meeting%20expectations) What Students Want: Key Results from DEC Global AI Student Survey 2024

[https://www.digitaleducationcouncil.com/post/what-students-want-key-results-from-dec-global-ai-student-survey-2024](https://www.digitaleducationcouncil.com/post/what-students-want-key-results-from-dec-global-ai-student-survey-2024)

[[3]](https://www.ucanwest.ca/blog/education-careers-tips/advantages-and-disadvantages-of-ai-in-education#:~:text=traditional%20teaching%20jobs) Advantages and disadvantages of AI in education | University Canada West (UCW)

[https://www.ucanwest.ca/blog/education-careers-tips/advantages-and-disadvantages-of-ai-in-education](https://www.ucanwest.ca/blog/education-careers-tips/advantages-and-disadvantages-of-ai-in-education)

[[8]](https://sites.campbell.edu/academictechnology/2025/03/06/ai-in-higher-education-a-summary-of-recent-surveys-of-students-and-faculty/#:~:text=is%20increasing%2C%20but%20still%20lags,applications%20of%20AI%20in%20education) [[9]](https://sites.campbell.edu/academictechnology/2025/03/06/ai-in-higher-education-a-summary-of-recent-surveys-of-students-and-faculty/#:~:text=The%20Digital%20Education%20Council%E2%80%99s%20faculty,AI%20usage%20and%20low%20AI) [[10]](https://sites.campbell.edu/academictechnology/2025/03/06/ai-in-higher-education-a-summary-of-recent-surveys-of-students-and-faculty/#:~:text=sufficient%20AI%20knowledge%20and%20skills%2C,9) AI in Higher Education: A Meta Summary of Recent Surveys of Students and Faculty – Campbell Academic Technology Services

[https://sites.campbell.edu/academictechnology/2025/03/06/ai-in-higher-education-a-summary-of-recent-surveys-of-students-and-faculty/](https://sites.campbell.edu/academictechnology/2025/03/06/ai-in-higher-education-a-summary-of-recent-surveys-of-students-and-faculty/)

[[11]](https://anara.com/blog/ai-in-education-statistics#:~:text=%2A%2057,7%20Cengage) AI in Higher Education Statistics: The Complete 2025 Report

[https://anara.com/blog/ai-in-education-statistics](https://anara.com/blog/ai-in-education-statistics)

[[12]](https://citejournal.org/volume-25/issue-3-25/social-studies/civic-education-in-the-age-of-ai-should-we-trust-ai-generated-lesson-plans/#:~:text=First%2C%20across%20all%20AI,2023%2C%20Polikoff%20%26%20Dean) Civic Education in the Age of AI: Should We Trust AI-Generated Lesson Plans?  – CITE Journal

[https://citejournal.org/volume-25/issue-3-25/social-studies/civic-education-in-the-age-of-ai-should-we-trust-ai-generated-lesson-plans/](https://citejournal.org/volume-25/issue-3-25/social-studies/civic-education-in-the-age-of-ai-should-we-trust-ai-generated-lesson-plans/)

[[13]](https://bmcmededuc.biomedcentral.com/articles/10.1186/s12909-025-06881-w#:~:text=The%20screening%20process%20revealed%20that,of%20facility%20and%20discrimination%20index) [[14]](https://bmcmededuc.biomedcentral.com/articles/10.1186/s12909-025-06881-w#:~:text=Summary%20of%20results) Quality assurance and validity of AI-generated single best answer questions | BMC Medical Education | Full Text

[https://bmcmededuc.biomedcentral.com/articles/10.1186/s12909-025-06881-w](https://bmcmededuc.biomedcentral.com/articles/10.1186/s12909-025-06881-w)

[[15]](https://files.eric.ed.gov/fulltext/EJ1465704.pdf#:~:text=a%20significant%20positive%20effect%20size,most%20substantial%20positive%20impact%20on) EJ1465704.pdf

[https://files.eric.ed.gov/fulltext/EJ1465704.pdf](https://files.eric.ed.gov/fulltext/EJ1465704.pdf)

[[16]](https://arxiv.org/pdf/2504.10961#:~:text=Findings%20revealed%20that%20when%20the,produced%20feedback) 2504.10961

[https://arxiv.org/pdf/2504.10961](https://arxiv.org/pdf/2504.10961)

[[17]](https://files.eric.ed.gov/fulltext/EJ1459623.pdf#:~:text=Results%3A%20Findings%20reveal%20that%20ChatGPT,generated%20content) EJ1459623.pdf

[https://files.eric.ed.gov/fulltext/EJ1459623.pdf](https://files.eric.ed.gov/fulltext/EJ1459623.pdf)

[[18]](https://www.mdpi.com/2227-7102/15/8/977#:~:text=motivation%20are%20more%20inclined%20to,that%20Hypothesis%203%20is%20valid) Artificial Intelligence-Generated Content Empowers College Students’ Critical Thinking Skills: What, How, and Why

[https://www.mdpi.com/2227-7102/15/8/977](https://www.mdpi.com/2227-7102/15/8/977)

[[19]](https://lile.duke.edu/ai-ethics-learning-toolkit/does-ai-harm-critical-thinking/#:~:text=compared%20to%20those%20students%20using,do%20not%20outsource%20their%20judgment) Does AI Harm Critical Thinking - Duke Learning Innovation & Lifetime Education

[https://lile.duke.edu/ai-ethics-learning-toolkit/does-ai-harm-critical-thinking/](https://lile.duke.edu/ai-ethics-learning-toolkit/does-ai-harm-critical-thinking/)

[[20]](https://pmc.ncbi.nlm.nih.gov/articles/PMC12508024/#:~:text=quasi,31%29%2C%20which%20are%20large%20effect)  Evaluating AI-Powered Applications for Enhancing Undergraduate Students’ Metacognitive Strategies, Self-Determined Motivation, and Social Learning in English Language Education - PMC

[https://pmc.ncbi.nlm.nih.gov/articles/PMC12508024/](https://pmc.ncbi.nlm.nih.gov/articles/PMC12508024/)

[[21]](https://arxiv.org/html/2505.13381v1#:~:text=40,impactful%20than%20sophisticated%20feedback%20mechanisms) How Adding Metacognitive Requirements in Support of AI Feedback in Practice Exams Transforms Student Learning Behaviors

[https://arxiv.org/html/2505.13381v1](https://arxiv.org/html/2505.13381v1)

[[22]](https://www.researchgate.net/publication/387956529_How_AI_-Enhanced_Social-Emotional_Learning_Framework_Transforms_EFL_Students'_Engagement_and_Emotional_Well-Being#:~:text=This%20study%20explores%20the%20transformative,creates%20a%20more%20emotionally%20supportive) (PDF) How AI ‐Enhanced Social–Emotional Learning Framework Transforms EFL Students' Engagement and Emotional Well‐Being

[https://www.researchgate.net/publication/387956529_How_AI_-Enhanced_Social-Emotional_Learning_Framework_Transforms_EFL_Students'_Engagement_and_Emotional_Well-Being](https://www.researchgate.net/publication/387956529_How_AI_-Enhanced_Social-Emotional_Learning_Framework_Transforms_EFL_Students'_Engagement_and_Emotional_Well-Being)

[[23]](https://timesofindia.indiatimes.com/education/news/ai-in-classrooms-friend-or-foe-benefits-boundaries-and-why-learning-is-still-a-human-act/articleshow/124956167.cms#:~:text=Personalisation%20without%20isolation,defend%20their%20solutions%2C%20not%20just) AI in classrooms: Friend or foe? Benefits, boundaries, and why learning is still a human act - The Times of India

[https://timesofindia.indiatimes.com/education/news/ai-in-classrooms-friend-or-foe-benefits-boundaries-and-why-learning-is-still-a-human-act/articleshow/124956167.cms](https://timesofindia.indiatimes.com/education/news/ai-in-classrooms-friend-or-foe-benefits-boundaries-and-why-learning-is-still-a-human-act/articleshow/124956167.cms)

[[24]](https://www.media.mit.edu/projects/your-brain-on-chatgpt/overview/#:~:text=strategies,they%20wrote%20just%20minutes%20prior) [[25]](https://www.media.mit.edu/projects/your-brain-on-chatgpt/overview/#:~:text=uploaded%20to%20Arxiv%2C%20the%20preprint,with%20caution%20and%20as%20preliminary) Overview ‹ Your Brain on ChatGPT — MIT Media Lab

[https://www.media.mit.edu/projects/your-brain-on-chatgpt/overview/](https://www.media.mit.edu/projects/your-brain-on-chatgpt/overview/)

[[26]](https://scale.stanford.edu/ai/repository/short-term-gains-long-term-gaps-impact-genai-and-search-technologies-retention#:~:text=Taxonomy,The%20study) [[27]](https://scale.stanford.edu/ai/repository/short-term-gains-long-term-gaps-impact-genai-and-search-technologies-retention#:~:text=outperformed%20the%20control%20group%20in,driven) SHORT-TERM GAINS, LONG-TERM GAPS: THE IMPACT OF GENAI AND SEARCH TECHNOLOGIES ON RETENTION | SCALE Initiative

[https://scale.stanford.edu/ai/repository/short-term-gains-long-term-gaps-impact-genai-and-search-technologies-retention](https://scale.stanford.edu/ai/repository/short-term-gains-long-term-gaps-impact-genai-and-search-technologies-retention)