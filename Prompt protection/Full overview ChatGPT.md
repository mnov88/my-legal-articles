# Intellectual property protection for AI prompts

## Introduction

A startup founder pays six figures to hire a **“prompt engineer”** – an expert in crafting input instructions that make generative AI reliably produce valuable outputs. A marketplace called **PromptBase** sells text prompts for a few euros each, advertising them as proprietary creations of their authors[[1]](https://news.artnet.com/art-world/ai-prompt-engineer-2288620#:~:text=Illustration%20promptbase,%E2%80%9D). Meanwhile, a health AI company accuses a rival of **“prompt injection”** hacking to steal the secret inputs underlying its medical chatbot. These vignettes illustrate a new reality: the **natural-language prompts** given to AI systems have economic value and are increasingly treated as **assets** worth protecting. This article asks whether and how **European intellectual property law** can protect such prompts.

**Prompts** – sequences of text (or other data) that users provide to AI models to generate a desired result – now function as key **input assets** in generative AI. They range from simple queries (“Translate this sentence”) to elaborate scripts containing **specific syntax, parameters, or creative language**. The central legal question is whether these prompts can be **owned or protected** like other intellectual creations. Could a prompt qualify as a **copyrightable work**, or even as a **computer program** under EU law? Might especially innovative prompts be eligible for **patent protection**? Or are prompts better shielded as **trade secrets** and confidential know-how? Each theory presents unique doctrinal hurdles.

This Article systematically evaluates four possible regimes – **copyright**, including the special framework for **software**; **patents**; and **trade secrets** – to determine which, if any, can secure exclusive rights over AI prompts. Part I establishes why prompts have quantifiable economic value, drawing on the nascent **market for prompts** and evidence of competitive advantage. Part II examines whether prompts meet the EU copyright criteria as original works of authorship, addressing the threshold of **originality** and the idea–expression dichotomy. Part III considers an alternative approach: treating prompts as **computer programs** protected by the Software Directive, and whether the functional nature of prompts aligns with that framework. Part IV analyzes the strict requirements of **patentability** – **technical character**, novelty, and non-obviousness – applied to prompts, and asks if a prompt could ever be claimed as a patentable invention. Part V turns to **trade secret law**, which protects valuable information kept confidential, to see if this pragmatic route better fits prompts. Finally, Part VI weighs the **trade-offs** between these approaches and offers an outlook on the optimal strategy and potential legal developments.

The analysis unfolds against the backdrop of EU law’s core principles and case law. It breaks down each legal test into elements – for example, **originality** requiring the author’s own intellectual creation, or a patent requiring a **technical contribution** – and applies them to prompts with careful attention to CJEU jurisprudence and doctrinal nuances. Conflicting perspectives are quarantined in counter-argument sections (e.g. the view that a prompt is a mere unprotectable idea, vs. the view that a complex prompt is creative text). By process of elimination, inadequate theories are rejected before concluding which (if any) IP protection is **viable for prompts**. As we will see, each doctrine has gaps when applied to this unusual subject matter – a subject matter that blurs the line between **creative expression** and **functional instruction**. The question this Article asks is straightforward: under existing European intellectual property law, **can the creator of an AI prompt prevent others from copying or reusing it?** The answer lies in navigating unsettled law – and, to that extent, in identifying which legal interpretations are most convincing.

## 1. The economic value of AI prompts

European law strives to protect intellectual creations in part to **incentivize investment** and reward creativity. To justify any IP protection for AI prompts, one must first show that prompts have real **economic value** worth protecting. Empirically, there is growing evidence that **skilled prompt-crafting** can confer significant commercial advantage. Although the practice of “prompt engineering” barely existed a few years ago, it has rapidly become a **marketable skill** commanding high salaries and spurring a small marketplace for prompt “products.” This Part marshals the evidence – from marketplaces to lawsuits – demonstrating that prompts can be **valuable business assets**.

### 1.1 An emerging market for prompts

The rise of public generative AI models (like ChatGPT for text or Midjourney for images) has given birth to a niche market where **prompts are bought and sold as commodities**. On platforms such as **PromptBase**, users trade text prompts that yield particularly useful or creative outputs[[1]](https://news.artnet.com/art-world/ai-prompt-engineer-2288620#:~:text=Illustration%20promptbase,%E2%80%9D). For a modest price (often under €5), one can purchase, for example, a prompt to generate “fairytale animal book illustrations” or “high-quality tiny animal images,” rather than painstakingly developing such prompts oneself. The very existence of prompt marketplaces signals that prompts are **perceived as valuable know-how** – much like mini-software scripts – that save others time and effort. PromptBase’s own terms of service pointedly declare that “*All prompts available on our marketplace are the intellectual property of their respective creators*”[[1]](https://news.artnet.com/art-world/ai-prompt-engineer-2288620#:~:text=Illustration%20promptbase,%E2%80%9D). Simply put, the platform asserts that a prompt’s author **owns** it and may sell usage rights, akin to an artist selling a design. While this contractual language has no force beyond the platform, it underscores a commercial reality: prompts are being **treated as proprietary products** by their creators and consumers.

Beyond direct sales, prompts have become a source of competitive advantage in content creation and business processes. **Entrepreneurs market compilations of prompts** (e.g. an “AI Prompt Bible” offering 1,000 expert-crafted prompts) with the promise that a buyer can “*become an artist without being an artist*” simply by using these inputs. Although commentators have questioned the long-term value of such easily copyable prompt “skills”, the short-term willingness of users to pay for effective prompts confirms that they hold **practical economic value**. If a particular phrasing reliably produces a high-quality image or insightful analysis that generic prompts cannot, that phrasing has utility – and thus **market value** – independent of the underlying AI model.

This emerging prompt economy, however, also highlights the **fragility** of the value of prompts absent legal protection. The prompt marketplace is plagued by immediate imitation: as soon as any prompt proves popular, **rivals can clone it** or share it freely, undercutting the original seller. An investigative account of PromptBase noted that nothing stops a buyer from reposting or reselling a purchased prompt, or even using new AI tools to “reverse-engineer” the effect of the prompt without ever paying the original author. The **ease of duplication** (a single text string can be copied at zero cost) and the lack of inherent secrecy (prompts must be disclosed to be sold or used) mean that any **economic lead** gained by a clever prompt is **tenuous**. This dynamic suggests that, unless some legal regime can step in, prompt creators may struggle to **monetize or secure returns** on their inventive inputs – a classic market failure rationale for IP protection.

### 1.2 A valuable skill commanding high compensation

Another measure of prompts’ value is what employers and industries are willing to pay those who can craft them. In the tech industry, **“prompt engineer”** roles have quickly become **highly paid positions**. Reports indicate that top AI firms have offered compensation packages upwards of \$300,000 for prompt engineering experts. Even in Europe, where salaries tend to be lower than Silicon Valley, experienced prompt designers can command six-figure (€) salaries. These figures rival or exceed salaries for traditional software engineers, reflecting the **scarcity and perceived importance** of advanced prompting skillsets. One prominent example widely cited in early 2023 was the AI startup **Anthropic** advertising a prompt engineer position with a salary up to \$335,000. Such high valuations implicitly recognize that a well-crafted prompt can significantly improve an AI system’s output – for instance, by making it more accurate, efficient, or tailored to business needs – and thus confer a **competitive edge** to the enterprise. In other words, the know-how to write superior prompts functions as a form of **intellectual capital**.

It is telling that businesses are not only *buying prompts* but also investing in **in-house prompt development**. Some companies treat effective prompts as **trade secrets**, integral to their products. For example, OpenAI reportedly embedded hidden “system” prompts to instruct ChatGPT on how to behave; when outsiders discovered and shared those hidden prompts, it raised concerns about the leakage of proprietary configurations. In a more concrete demonstration, the *OpenEvidence v. Pathway* lawsuit (USA, 2025) revolves around alleged theft of prompt-based know-how: the plaintiff claims its competitor **hacked into its AI system via prompt injections to extract the secret prompts and instructions** that powered its medical AI, then copied the system using that information. The suit explicitly frames those prompts and settings as **valuable trade secrets** misappropriated by dishonest means. While just an allegation, it exemplifies that companies see well-tuned prompts not merely as generic text but as **protected business assets** – much like source code or confidential formulas – that rivals might covet.

### 1.3 The value-add of prompts: functional and creative dimensions

Why do prompts command value? Their value stems from both **functional efficacy** and **creative uniqueness**. Functionally, a prompt can be the key to unlocking a specific **capability of an AI model** – for instance, a carefully structured prompt that gets a large language model to output a useful spreadsheet formula, or that guides a text-to-image model to produce a consistent art style. In effect, the prompt serves as a **quasi-algorithmic instruction**, directing the model’s computational process towards a valuable result. In economic terms, it reduces the cost (time, compute, trial-and-error) needed to achieve that result. Creatively, a prompt can incorporate an **original combination of ideas, phrases, and constraints** that yields an output no one else would easily generate. A vivid prompt for an image model might describe an imaginative scene in nuanced detail; the person who conceived that description has contributed creative value analogous to an art director guiding an image. To the extent the prompt itself is expressive (even if the final goal is functional), it may reflect **individual creative choices** that differentiate it from banal inputs.

However, the very qualities that give prompts value also complicate their legal status. A prompt that is highly *functional* (structured with logic and parameters to steer an AI) starts to resemble a **software command or utilitarian method**. Conversely, a prompt that is highly *creative* (rich in imaginative language) may be seen as mere **preparatory input** whose creative value manifests in the output rather than in the prompt’s text per se. European intellectual property doctrines historically draw lines between **functional information and creative expression**, and between **ideas and their expression**. Prompts straddle these lines. The next sections will examine how those doctrines – copyright, patent, trade secret – apply when we assert that prompts deserve protection commensurate with their demonstrated value. The evidence of a prompt’s economic value does not automatically guarantee it legal protection, but it sets the stage: **prompts are not trifles**; they are assets for which innovators seek protection, and the law must consider whether it can accommodate that need. As explained above, the “prompt economy” is real and growing. This Article now turns to the doctrinal analysis of protecting that economy’s principal asset: the prompts themselves.

## 2. Copyright protection under EU law

**Can an AI prompt be protected by copyright as a literary or artistic work under EU law?** Copyright is an attractive starting point: it automatically protects original expressions without formalities, providing potentially long-term and wide-ranging protection against copying. In the EU, any “**work**” meeting the originality standard – the author’s own intellectual creation – is entitled to copyright protection (InfoSoc Directive 2001/29, Art 2; Berne Convention as incorporated). Prima facie, a prompt is a string of text, and text can certainly be a literary work. This section explores whether prompts can satisfy the **originality** threshold and avoid exclusion as mere ideas or functional instructions.

The analysis proceeds in three steps. Section 2.1 explains the EU originality test and asks whether a prompt’s text can qualify as an **original expression** of the prompt writer. Section 2.2 addresses the **idea–expression dichotomy**: even if some creativity is present, is a prompt too much like a method or idea (unprotectable) rather than an expression (protectable)? Finally, section 2.3 considers practical issues: assuming a prompt is copyrightable, what rights and limits would that entail, and have any courts or commentators already opined on prompts in copyright (yes – notably a Czech court’s obiter remarks)? Through this, we will find that **simple prompts likely fail to qualify** as works, whereas **complex, elaborate prompts might** – but even then, enforcement of copyright in prompts faces conceptual challenges.

### 2.1 Originality of prompts: the “author’s own intellectual creation” test

Under EU law, the touchstone of copyright protectability is **originality**, meaning the work is the **author’s own intellectual creation**. This standard, established by the CJEU in *Infopaq* and subsequent cases, requires that the author made **free and creative choices** in producing the work so that it bears the author’s personal stamp (see *Eva-Maria Painer*, C-145/10, para 89). It’s a relatively low threshold – no artistic merit is needed, only a minimal degree of **creative freedom** in the expression. Even an excerpt of 11 words can satisfy it if those words are the result of creative selection or arrangement. On the other hand, expressions dictated by technical function or banal choices do not meet the standard.

Applying this to AI prompts: does writing a prompt involve creative choices comparable to writing a sentence in an article or a line of poetry? **Sometimes, yes.** Consider a user who crafts a rich narrative prompt for an image generator: *“At dusk, a lone violinist plays on a rooftop under swirling clouds, in the style of Monet, with neon city lights below.”* The user has chosen specific visual elements, a mood, and an art style – arguably an original combination. If another person, working independently, would almost certainly phrase it differently, that indicates the prompt’s phrasing is not inevitable or purely functional. Such a prompt could be seen as the **expression of a mental creation**: the author imagined a scene and expressed it in a unique text description. Likewise, a carefully phrased instruction for a chatbot that injects a certain humor or perspective (e.g. role-playing a character in the prompt) might reflect the author’s personal creative input. The *Kluwer Copyright Blog* suggests that “the more complex prompts” – those with elaborate content or structure – “would probably be protectable as a normal literary text”. In other words, a sufficiently detailed prompt can cross the line into being an **authored text** like any other, with original selection and arrangement of words.

However, not all prompts enjoy that creative leeway. Many prompts are **highly constrained or trivial**. A prompt might simply be a question (*“What is the capital of Myanmar?”*) or a two-word command (*“translate French”*). Such minimal or routine inputs lack any modicum of originality – they are generic or dictated by function. The CJEU has repeatedly held that where expression is **dictated by a technical function or by rules**, there is no room for originality: the expression and the idea merge. For instance, in the *BSA* case (C-393/09), the Court denied protection to elements of software user interfaces that were strictly determined by technical considerations, noting that if the expression is **indispensable for achieving a certain result, it cannot be original**. Similarly, if a prompt is formulated in the only or one of very few effective ways to achieve a known output from the AI, one could argue any creativity is absent or severely limited. A prompt like *“/imagine prompt: cat drinking cocktail –-ar 16:9 –-v 5”* (a string with parameters for Midjourney) is mostly functional keywords and flags that anyone trying to get that result would have to use. In such cases, as the Court said, the “idea and expression become indissociable” and the criterion of originality is not met. Thus **many short or format-driven prompts will fall on the unprotectable side**, either for lack of any originality or because whatever minimal differences exist are not the result of creative choice but of necessity or convention.

The **length** of a prompt is not decisive per se, but often length correlates with creative opportunity. Longer prompts with narrative elements, specific adjectives, or unusual combinations likely involve more individual choice. Very short prompts or purely functional sequences (e.g. code-like prompts with tokens) likely do not. The *Infopaq* principle allows even a short excerpt to qualify if it reflects original expression, so a short prompt *could* be protected if, say, it coined a clever original phrase (imagine a whimsical two-word poem used as a prompt). But as a practical matter, **most trivial prompts lack the “personal touch”** that EU originality demands.

Another angle is **human vs. AI contribution**. Some prompts are themselves generated or heavily suggested by AI (for instance, using one AI to generate a prompt for another). If an AI suggested the wording and the human merely copied it, can the human claim authorship? Under EU law, authorship requires a natural person’s creative effort (*Computer Programs Directive* 2009/24, Art 2(1); Berne Conv. principle). If a prompt’s text is entirely machine-generated or so constrained by the machine’s requirements that the human added no creativity, it wouldn’t qualify as a human “work.” That scenario is less common for prompts (prompts are usually human-written), but worth noting: the user must actually exercise **creative choices** in devising the prompt. If the prompt is largely borrowed or auto-completed by the AI, the human’s contribution might be deemed insufficient (analogous to how AI-generated outputs currently are denied copyright for lack of human authorship).

In summary, a prompt **can** meet the originality threshold *if and only if* the prompt’s formulation is the result of the author’s free and creative choices – not constrained by functionality or triviality. Some AI prompts, especially those resembling creative prose or unique instructions, likely clear that bar. Many others – generic, factual, or constrained prompts – do not. Copyright law would thus protect the **cream of the crop** of prompts (the truly authored ones) but not the many garden-variety inputs. Yet even for those “authored” prompts, a deeper issue lurks: Are we protecting only the prompt’s text itself, or something about the prompt’s *function*? This leads to the idea–expression dichotomy, examined next.

### 2.2 Prompts as idea or expression: the recipe analogy

Copyright does not protect ideas, procedures, methods, or concepts – only the **expressive form** in which they are embodied (Berne Article 2, TRIPS Art 9(2); reflected in EU law by doctrine and e.g. Software Directive Art 1(2)). One intuitive argument is that an AI prompt is more like a **set of instructions or an idea for a work**, rather than a work itself. Indeed, in a recent case in the Czech Republic – one of the first European cases on AI-generated content – the court opined *obiter* that an AI prompt “could only be regarded as a **theme or idea** for a work” and thus **incapable of copyright protection**, since ideas are explicitly excluded under Czech law. The court drew an analogy: a prompt is like the *recipe* for a cake, and the AI’s output is the cake itself. Copying someone’s cake (output) doesn’t copy their recipe (prompt) in the copyright sense, because the recipe was never protected expression to begin with – it was a set of instructions (the *subject* of the work, not the work).

This reasoning resonates with a long-standing principle: copyright should not extend to **methods of creation**. Just as the idea of painting in cubist style or the method of taking a photo with certain camera settings can’t be monopolized, one might contend that the method of producing a certain AI-generated result (i.e. the prompt) is an unprotectable idea or process. The **UK courts** have similarly held that recipes, patterns, or systems generally are not protected, except possibly their exact wording if original. A prompt can be seen as analogous to a **computer command** or **search query**, which are generally factual or functional inputs not meant to be “authored works” (the CJEU in *Innoweb* recognized that a search engine query itself isn’t a protected work, though a collection of queries might form a protected database – not relevant here).

However, this is not the end of the matter. The **line between idea and expression** can be fine. A prompt is indeed an instruction to achieve a result, but it is also literally a **text authored by someone**. We can separate two aspects of the prompt: (a) the *literal text* the user wrote, and (b) the *function or effect* that text has on the AI system. Copyright can only ever protect (a) – the specific combination of words – and not (b) – the underlying idea of getting the AI to do X. Thus, if Alice devises a brilliant prompt to generate a Van Gogh-style moonlit forest image, copyright might protect the exact wording Alice used (if original), but it cannot stop others from generating similar images by other means or with paraphrased prompts that capture the same idea. In copyright terms, others are free to use the **idea** of Alice’s prompt; they just cannot **verbatim copy** her expression beyond a de minimis extent.

So, is a prompt’s value mainly in its *idea* or in its *expression*? If the secret sauce is that you realized asking for “a moonlit forest in the style of Van Gogh” yields great outputs, the value lies in the concept (Van Gogh style applied to forests at night) – which is an unprotectable idea or genre. Anyone is free to have the same idea and express it in their own words. If, on the other hand, the value lies in *very precise wording* you crafted (“a shadowy cobalt-blue forest under swirling stars reminiscent of Starry Night – style of Van Gogh, high detail”) and that exact wording is crucial, then copyright could theoretically protect that wording from wholesale copying. But even here, the law might view the prompt as akin to the **instructions for producing a work** rather than the work itself.

Notably, the Czech court’s recipe analogy suggests a fear of **indirect monopoly**: If one could copyright a prompt, could one then claim that any output from that prompt is a derivative work of the prompt? Normally copying an output would not infringe copyright in the input instructions (just as eating a cake doesn’t infringe the recipe). But some might argue that a prompt and output are linked in a way that copying the output effectively reproduces the creativity of the prompt. This was posed as a question by scholars: could the author of a copyright-protected prompt claim that an AI-generated image directly **embodies the intellectual creation of the prompt’s text**, such that using the same output is an infringement of the prompt? That seems a stretch under current doctrine – it would be treating the prompt like a **preparatory design** that permeates the output. The prevailing view is likely negative: a prompt is more like a **tool or method** (thus idea) rather than expression manifested in the output. The output may be completely different in form (image vs. text prompt), and copyright does not recognize a general protection for “sweat of the brow” or investment in making something indirectly.

In EU law, this idea-expression division is explicit for software: *“Ideas and principles which underlie any element of a computer program… are not protected by copyright”* (Directive 2009/24, Art 1(2)). If prompts were seen as comparable to software (we examine that in the next Part), their **functional aspects** would clearly be unprotected. But even as literary works, the general idea-expression principle would exclude any attempt to protect **functional results or concepts** via prompt copyright.

Thus, while a prompt’s **text** might be original expression, one must accept that copyright would only prohibit **copying that text (or a substantial part thereof)**. It would not give a monopoly on the *task achieved* by the prompt. Competitors could write different prompts achieving similar outputs; they just cannot plagiarize the specific wording if it qualifies as original expression. In practice, this limits the usefulness of copyright for prompts: a competitor could easily avoid infringement by rephrasing the prompt (unless the prompt is so unique that any rephrasing fails to achieve the effect – but then maybe that uniqueness is itself the protectable part?).

To illustrate: suppose a prompt for a chatbot is: *“Act as a polite butler with a dry wit; answer questions with a brief, humorous retort followed by a helpful explanation.”* If that is protectable text, another developer could achieve the same style by saying *“You are a witty, polite assistant. Always give a short wry joke first, then a detailed answer.”* – capturing the idea but not the exact expression. This would not infringe the first prompt’s copyright since the wording differs. The **idea (a witty butler persona)** is free for all; only verbatim or closely paraphrased copying of the specific phrasing is restricted. Copyright therefore offers at best a **narrow shield**: it prevents verbatim cloning of a prompt, but not competitive use of the underlying prompt concept.

One more point on idea vs expression: The *format* of prompts might be considered an idea in itself. Many prompts use formulaic structures (especially for image models: lists of descriptors, then style tags, then resolution). Those standard formats are not protectable – they are analogous to grammar or syntax. Only the **creative embellishments** within that structure could count. This again hews to the idea that what is functional or necessary (the format, common terms) is not protectable, what is freely chosen (unusual combination or phrasing) might be.

In sum, a prompt that contains sufficient **creative expression** can in theory be a copyright-protected work (most likely a literary work). But enforcing that right means catching someone copying the prompt **text**. Given how easily a prompt’s function can be replicated with alternative wording or minor tweaks, copyright protection might be more symbolic than practically effective. Nonetheless, it could deter *blatant* copying (like someone simply redistributing your prompt text on a forum or marketplace), which is not nothing.

### 2.3 European perspectives: case law and commentary

It is instructive to survey how European legal sources have begun to treat prompts in copyright discourse:

– **CJEU case law:** The Court of Justice has not yet ruled on prompts directly. However, its case law on software and AI outputs frames the discussion. The *Infopaq* line of cases (author’s own intellectual creation) as discussed above suggests some prompts can be works. Meanwhile, the Court’s stance on **AI-generated outputs** (no human authorship, thus no protection) indirectly affects prompts: if AI outputs aren’t protected because the human prompt is not considered sufficient creative control for authorship, that implies the law views prompting as something less than traditional creation. In the famous *Naruto* (monkey selfie) and *Thaler* (AI as inventor) contexts (though one is authorship, one patent inventorship), the consistent theme is requiring human creative acts. A prompt is a human act, but the outputs have been deemed mostly machine. As the European Parliament’s recent study put it: “**No Copyright for Prompts Alone**: Merely providing a prompt to an AI model does not amount to authorship. Human contributions must shape the expressive aspects of the output”. This doesn’t directly answer whether the prompt itself is protected, but suggests that by itself a prompt isn’t enough to claim the output.

– **National case law:** The **Czech Municipal Court in Prague (2023)** decision, briefly noted earlier, is the only known EU judicial pronouncement on prompts. There, the court’s central holding was that an AI-generated image had no human author (hence no copyright). In passing, the court commented that the **prompt is just a theme/idea** and not protectable. This aligns with Czech law’s explicit exclusion of themes and ideas from protection. It’s *obiter dictum* (non-binding commentary), but it signals skepticism towards treating prompts as works. The Czech judges essentially regarded the prompt as part of the *process of creation*, not the created work itself – reinforcing the recipe analogy discussed. It is conceivable that other national courts, if faced with similar disputes, would take cues from this reasoning, at least until the CJEU provides guidance.

– **Commentary:** Academic and professional commentary in Europe is just beginning to grapple with prompt protection. A notable commentary by Eden Howard (University of Cambridge) in 2025 contends that this issue merits greater attention. She identifies challenges such as the **connection between prompt and output** – e.g. could a prompt’s copyright indirectly control output copying – and notes the Czech case’s stance that prompts are ideas not works. The consensus in commentary appears to be that **simple prompts are not protectable**, but **complex prompts might be** under existing law, albeit raising novel questions (like indirect infringement). Another perspective (Nuno Sousa e Silva, 2024) acknowledges that complex prompts “mirror the logic and organization” of code and could be considered a form of literary expression, even as they also serve an instructional role. There is thus a live debate: should we classify prompts as protectable expression (with some sui generis considerations) or lump them with unprotectable processes?

– **US developments for comparison:** The U.S. Copyright Office’s 2025 AI report, while not binding in Europe, took the view that prompts are generally “**uncopyrightable instructions**,” though it left room that an especially creative prompt text might have some protectable elements[[2]](https://www.lexology.com/library/detail.aspx?g=af1f00b2-10f7-412e-96ba-27c4451c4322#:~:text=The%20report%20also%20addresses%20whether,to%20the%20outputs%20they%20generate)[[3]](https://www.lexology.com/library/detail.aspx?g=af1f00b2-10f7-412e-96ba-27c4451c4322#:~:text=The%20report%20also%20addresses%20whether,to%20the%20outputs%20they%20generate). This mirrors the EU idea/expression analysis and suggests transatlantic agreement that we can’t protect the act of prompting itself, only the expressive text if it qualifies. The U.S. position also underscores that regardless of complexity, the user of a prompt is not considered the author of the AI output[[4]](https://www.lexology.com/library/detail.aspx?g=af1f00b2-10f7-412e-96ba-27c4451c4322#:~:text=copyright%2C%20as%20outlined%20in%20the,protected%20under%20current%20copyright%20law)[[5]](https://www.lexology.com/library/detail.aspx?g=af1f00b2-10f7-412e-96ba-27c4451c4322#:~:text=The%20Office%E2%80%99s%20report%20states%20that,than%20the%20user%E2%80%99s%20original%20authorship) – consistent with EU national cases so far.

Finally, one must note **duration and scope**: If a prompt text is protected, it gets the full term of life plus 70 years copyright. This is a very long protection for what might be a small creation. Some might find that disproportionate, raising a policy question whether prompts (especially short ones) ought to be excluded as a matter of de minimis. EU law typically doesn’t have a formal “short phrases” exclusion, but in practice truly short or banal phrases are not original (Infopaq implied even 11 words could be, but less might not). In any event, the **mismatch in scale** might be a reason courts would be reluctant to extend copyright to something as utilitarian and short-lived as many prompts. The *sweat of the brow* invested in fine-tuning a prompt is not directly relevant to copyright – only the outcome in terms of original expression counts.

**Conclusion on copyright:** Under current EU law, **some AI prompts can qualify as copyrightable works** – specifically those that constitute original expression of a human author’s intellect. A complex, creative prompt that reflects personal choice in its formulation could be seen as a literary work (or possibly, in rare cases, as a written artistic work like poetry). However, many prompts will fail to meet originality due to functional constraints or lack of creativity. Moreover, even when copyright subsists, it **only protects the prompt’s expression** (the exact text or a close paraphrase), not the underlying idea or the output generated. The idea that a prompt is just an unprotectable method has found purchase in at least one court, indicating judicial caution. Therefore, while copyright **in principle** offers some protection for prompts, in practice it may be **limited and brittle**. The next section explores whether classifying prompts as **software** (computer programs) could bolster their protection or change the analysis – an intriguing alternative given the quasi-code-like nature of many prompts.

## 3. Prompts as “computer programs” under EU law

Prompts tell a computer (an AI model) what to do – could they therefore be considered a type of **computer program**, protected under the EU Software Directive (Directive 2009/24/EC)? This idea has surfaced in commentary as generative AI blurs the lines between code and natural language. If prompts qualified as programs, they would be shielded by a specialized copyright regime: software is protected as a literary work, but with particular rules on ownership, exceptions, and scope tailored to functional works. This Part examines whether that classification is legally tenable and what it would imply.

The analysis is structured as follows. Section 3.1 outlines the definition (or lack thereof) of “computer program” in EU law and asks whether a natural-language prompt could fit that concept. Section 3.2 considers **advantages** of software classification (e.g. automatic employer ownership, narrow exceptions for decompilation, etc.) that might make it attractive to prompt creators, as well as **challenges** (e.g. the functional constraint doctrine and interoperability rules that might limit protection). Section 3.3 reviews relevant case law (like *SAS v. WPL* and *BSA*) on the scope of software copyright, as well as policy arguments about equating prompts to code.

### 3.1 Definition of a computer program: could a prompt qualify?

EU directives deliberately do **not strictly define** “computer program.” Recital 7 of Directive 91/250 (carried into the codified Directive 2009/24) states that the term *“shall include programs in any form, including those which are incorporated into hardware,”* and further *“includes preparatory design work leading to the development of a computer program provided that… a computer program can result from it”*. This broad formulation was meant to “futureproof” the law, ensuring that new types of software or coding formats aren’t excluded just because they look different from 1990s source code. Notably, EU law gives no explicit definition beyond that – but **U.S. law does** (and EU often considers such definitions): under 17 USC §101 a computer program is *“a set of statements or instructions to be used directly or indirectly in a computer in order to bring about a certain result.”*. The essence is clear: a program is a set of **instructions for a computer** to achieve a result.

At first glance, **AI prompts satisfy that description**. When you enter a prompt into a model, you are effectively providing a set of instructions (“generate text about X in style Y” or “create an image with attributes A, B, C”) that the computer (the AI) uses to produce a result. A prompt **causes a computational process to occur** – it directs software to generate an output. As one engineer analogized, *“we conjure the spirits of the computer with our spells”*, and prompts do resemble such “spells.” In functional terms, an **advanced prompt** with structured syntax (including variables or tags like `--v 5` for versioning or `<style:impressionist>` etc.) starts to look like a little piece of code. It has input parameters and expected outputs; it may even include logical operators or control sequences (“if output too long, summarize” in some multi-step prompt). Indeed, *some prompts include pseudo-code or JSON structures* to guide models – blurring into actual programming.

Proponents of this view argue there is **no principled obstacle** to treating a prompt language as a programming language. Humans historically have programmed computers in all sorts of languages – machine code, assembly, high-level languages, visual block languages – so why not natural language if the machine can parse it? The key element is instructing the machine to achieve a result. If the user’s words serve that role, they might be considered a **program “in any form”**. The *Kluwer* commentary explicitly poses: *“is there any obstacle to considering these prompts as a programming language?”* and notes that the EU’s choice not to define “program” leaves room to include unconventional forms of code, possibly even natural language control of a computer. In effect, the AI model’s interpretive engine (say, the large language model) acts as a compiler/interpreter of the prompt, much as it would for code.

However, the counter-argument is that **natural language prompts are qualitatively different** from traditional programs. Classic code is written in formal syntax with deterministic effects. Prompts are written in natural (albeit stylized) language and yield *probabilistic, variable outputs* – the same prompt to the same model might not give identical output each time. Detractors might say a prompt is more like a query or user input than a program: akin to typing search terms into Google rather than writing the Google algorithm itself. The Software Directive was conceived in the era of source code and compiled object code; whether the legislators imagined natural language commands as “programs” is doubtful. Yet Recital 7’s breadth and the dynamic nature of programming languages (consider that early programmers in the 1950s might find modern Python or even visual programming languages unrecognizable as “code”) suggests we focus on function: **does it instruct a computer?** If yes, form shouldn’t matter. A prompt indeed instructs a complex software (the AI model) to carry out a task. It arguably *is* part of the programming of that AI for that particular task.

The question, then, might turn on whether a prompt is seen as part of the **user’s creative expression (literary work)** or part of the **machine’s functional apparatus (software)**. We could analogize: A game like *The Sims* allows players to give commands to characters in plain language (e.g., “go to the kitchen”). Those commands cause in-game actions but we wouldn’t normally call them programs; they are user inputs, with the software (game code) doing the heavy lifting. Perhaps prompts are more akin to such user inputs – transient, specific to an instance, not themselves generalizable routines. A **computer program**, by contrast, usually denotes a set of instructions with some structure and completeness that can run on its own or be reused systematically.

Yet, we can conceive of cases where prompts blur into programs. For instance, users can chain multiple prompts and instructions to effectively create a *script* for the AI (sometimes called prompt chaining or using tools like LangChain). If someone writes a long prompt or series of prompts that performs calculations or iterative logic via the AI, that starts to look like a *programmatic routine* crafted in natural language. The dividing line is not obvious.

**EU law’s silence** on a precise definition means a court could, in theory, interpret “program” broadly to include a prompt that the machine “executes” to generate a result. Absent CJEU guidance, national courts could diverge. We have no known EU case yet on this exact point. The safe stance is that current practice does *not* treat prompts as software, but some authors have suggested it as a future possibility.

It is noteworthy that Recital 7 also says preparatory design material leading to a program is protected as part of the program. Could a prompt be seen as **preparatory design** for a program? Likely not: that concept was meant for things like flowcharts or pseudo-code written in preparation for coding. One might argue an advanced prompt (structured pseudo-code given to an AI that then writes actual code) could be that – if the prompt is effectively pseudo-code expecting the AI to produce working code, the prompt might be preparatory material for the code. But that’s a stretch, since the AI’s output code might not be protected (if seen as mostly machine-generated). The *Dutch Supreme Court (2018)* held that preparatory design work versus a normal literary work depends on whether further programming work is needed – if yes, then it’s preparatory to software, if not, then it’s just a literary work. A prompt usually directly causes the result without further human coding, so perhaps it’s *not* mere preparatory material but either a software in itself or just a literary piece.

In conclusion on definition: **It is at least arguable** that a complex prompt constitutes a “set of instructions… to bring about a certain result” – satisfying the essence of a program. The lack of formal syntax requirement in EU law means the door is ajar for such interpretation. But it remains an unsettled, novel claim. We will assume arguendo that prompts *could* be classified as programs and explore what that would mean.

### 3.2 Implications of treating prompts as software

If prompts were deemed computer programs under the directive, the following implications arise:

-   **Authorship and ownership:** Software directive Article 2(3) provides that when a program is created by an employee in the execution of duties, the employer *“exclusively shall be entitled to exercise all economic rights”* in the program, absent contract to the contrary. This is a significant difference from general copyright (where member state laws vary on work made for hire). For companies investing in prompt engineering, having prompts be “software” would **ensure employer ownership by default** of employees’ prompts. That clarity and automatic vesting could be beneficial in a workplace where prompt creation is routine – no need for separate agreements for each prompt; it’s statutorily the company’s. It could reduce disputes if, say, a prompt engineer left the firm; the firm could assert rights in the prompts as they would in code.

-   **Protection scope:** Software copyright protects the expression of code (source or object) but **not ideas, algorithms, or programming languages** (Art 1(2)). That is similar to general copyright’s idea-expression rule, but applied specifically. For prompts, this would mean the specific prompt text is protected, but any **underlying method or functional result** (the idea of using that prompt) is not – which is the same outcome we had under normal copyright, frankly. However, one nuance: in software cases like *SAS Institute v. WPL* (C-406/10), the CJEU held that the **functional behavior** of a program (its functionality, programming language, data file formats) is not protected expression. If prompts were programs, a court might analogize that the *functionality of the prompt – i.e., producing a certain effect in the AI – is not protectable*, only the prompt’s literal text. That is again analogous to what we found under literary copyright (can’t monopolize the output or idea). So in terms of idea-expression, software treatment doesn’t extend protection to the “functional effect” either.

-   **Originality threshold:** The originality bar for software is explicitly the same “own intellectual creation” standard (Art 1(3)), and the CJEU said no other criteria (like effort or novelty) apply. So classifying as software doesn’t lower or raise the bar; it remains the author’s free choices in code. If anything, software case law like *BSA* adds that when expression is dictated by technical function (only one or few ways to write something), it’s not original. That could apply to prompts: if you have only limited ways to phrase a prompt to get a desired function, then under *BSA* it lacks originality (idea-expression merge). So software doctrine would similarly refuse protection to highly constrained prompts. No difference there.

-   **Exceptions and reverse engineering:** A notable aspect of software copyright is the narrower set of exceptions. For instance, **decompilation** (reverse-engineering code to achieve interoperability) is allowed under certain conditions (Directive 2009/24, Art 6). Also, observing or testing a program’s functioning to learn ideas is explicitly allowed (Art 5(3)). If prompts are software, could someone lawfully “observe, study or test” a prompt by seeing how it works in order to learn the underlying ideas or interface? Potentially yes – which ironically might legalize some forms of prompt *reverse-engineering*. For example, if a competitor can lawfully access your prompt (say by buying it on a marketplace or being authorized as a user), under Art 5(3) they could test it to understand how it achieves its results without infringing, as long as they don’t copy the code (prompt text) itself beyond what’s needed to test. Similarly, if they needed to interoperate with your system, they might decompile or analyze prompts as allowed by Art 6. These provisions are designed to prevent software copyright from locking up functional interfaces. A prompt could be seen as part of an interface with the AI model. A competitor might argue they can find out how your prompt works to develop a compatible prompt or system. In short, software classification brings not only protection but also **user freedoms** to dissect and learn from the “code.”

-   **Scope of rights – adaptations:** Software owners have the exclusive right to control reproduction, adaptation, distribution etc. (Art 4). For prompts, this means copying the prompt text or creating an adaptation (modified prompt) would be infringement if done without authorization (subject to exceptions). That is similar to normal copyright, though software law emphasizes that *loading, running, transmitting* a program is an act of reproduction requiring permission (unless for intended use by lawful acquirer). If a prompt is a program, then arguably **each inputting of the prompt into the AI** is an act of reproduction (loading it into computer memory). Normally, a licensed user of software has an implied right to load it for use. If we analogize, when you sell someone a prompt, do they have an implied license to use (enter) it? Probably yes, or else the product is useless. But this highlights an oddity: if prompts were software, an end-user who lawfully obtained the prompt could rely on Art 5(1) exception that *necessary acts of reproduction for use of the program by lawful acquirer* do not require further authorization. That would cover actually using the prompt in the AI. However, if someone came across the prompt who wasn’t authorized (e.g. scraped it from a leaked source), using it could infringe the reproduction right. This is analogous to using pirated software. In practice, it’s unlikely that scenario would play out; more likely disputes are about wholesale copying and reselling prompts, which straightforward copyright already covers.

-   **Term and formalities:** The term for software is the same life+70 (natural author) or 70 from publication (if a legal person is author in some regimes) – no difference. Software classification wouldn’t shorten protection term. It does, however, emphasize that **no additional originality or threshold is needed** (some national laws historically had “sweat of brow” for software but EU settled on own intellectual creation only).

-   **Possible enhanced protection?** Some might think treating prompts as software could magically protect the *functional result* or allow going after those who independently create similar prompts. That is not the case. The *SAS* ruling explicitly held one cannot stop a competitor from writing their own code that has the same functionality as yours, as long as they don’t copy the code expression. By extension, one could not stop someone from writing a different prompt that achieves the same output as your prompt. Software copyright would not give a patent-like coverage of functionality. It remains copyright, just in a specialized domain.

-   **Different rules on transfer and licensing:** Software often is licensed, not sold, with shrink-wrap terms, etc. That’s contract, not copyright, but note that the Software Directive Art 4(2) introduces **exhaustion** for first sale of a program copy (except rental). If a prompt is considered software, perhaps selling a copy of it exhausts distribution right, meaning the buyer can resell it. But if it’s licensed, exhaustion might not apply straightforwardly (CJEU’s UsedSoft case said even downloaded software can be exhausted if license permits permanent use). This is an interesting wrinkle: prompt marketplaces often license use but forbid resale. If prompts are software, a court might say after the sale, the buyer can resell (subject to making their copy unusable) by analogy to *UsedSoft*. For prompt creators, that’s not great; they’d prefer to restrict redistribution. Under ordinary copyright of literary works, exhaustion would also normally apply to distribution of copies, but since prompts are digital, one might argue distribution right exhaustion doesn’t clearly cover online transfers (it did in *UsedSoft* for software by special interpretation). It’s a deep cut issue, but worth noting: Software law introduced some user rights (resale, etc.) that might give less flexibility to prompt sellers than a pure contract regime.

-   **Criminal penalties or anti-circumvention:** Some jurisdictions treat software piracy stringently. But more relevant, Software Directive Art 7 requires remedies against acts like dealing in infringing software copies and devices to remove copy protection. If prompts were software, distributing infringing copies could similarly face stiff remedies. Also, if someone made a tool to auto-extract or circumvent protections on prompt libraries, it could be analogous to a circumvention device (if the prompt is protected by a technical measure). This is speculation; far-fetched perhaps, but software classification could engage those often-overlooked provisions.

In summary, classifying prompts as computer programs **would not dramatically expand the basic availability of copyright** – prompts already can be protected if original. But it would import a different set of rules and default assumptions that, in some ways, could better suit industrial use (like employer ownership) but in others could weaken protection (due to things like reverse engineering allowances). It also conceptually foregrounds the *functional* nature of prompts – which might ironically cause judges to scrutinize originality even more strictly under the *BSA* doctrine (if prompt expression is largely dictated by achieving a function, then no protection).

### 3.3 Challenges and objections: determinism, originality, and outputs

Commentators have raised several **objections** to treating prompts as code – some legal, some pragmatic:

**(a) Determinism vs. randomness:** Traditional programs yield the same output given the same input (absent random functions). AI prompts do not guarantee identical output each time. One might argue this disqualifies them as “programs.” However, as the Kluwer piece notes, **absolute determinism is not required for copyright** – even in software, random or non-linear processes are possible. And a program can be nondeterministic (like an AI itself is a nondeterministic algorithm). So this is not a decisive legal point, just a conceptual difference. The main upshot is, unlike copying code which produces identical behavior, copying a prompt doesn’t guarantee copying the *output*. But copying a prompt is still copying of text, which is what copyright cares about. Thus the nondeterministic nature doesn’t really affect protectability of the prompt’s expression; it’s more relevant to whether the output can be considered just a “translation” or compilation of the prompt (it’s not).

**(b) The output as compiled code?** A provocative idea is whether the AI’s output could be seen as a **compiled version of the prompt** (like machine code of source code). If that were so, then by protecting the prompt as software, would the output automatically be protected as part of that program? The Kluwer author raised this and answered that one could consider the prompt as the program but *“reject the classification of the output as a compiled program.”* Under Recital 7, preparatory design material is protected if a computer program can result at a later stage, but here the output is not really a software program (it could be an image or text). And indeed, he notes, the model’s generation is “more than a change of format of the prompt”. So treating output as just the binary form of the prompt is not convincing. The output has its own creative elements (from the AI or from training data) that are not traceable one-to-one to the prompt’s text. Therefore, even if prompt = program, the output is not simply that program’s reproduction. So one cannot indirectly claim the output is protected by the prompt’s software copyright – that would be a form of **monopoly spillover** that likely fails (and the author correctly insists prompts as software “does not necessarily imply that the output is even protected”).

**(c) Normal copyright vs. software rules differences:** Why does it matter, one might ask, whether we label it software or just a literary text? One big difference is in **ownership and transfer rules** (as discussed, e.g. employer ownership by default). Another is that **moral rights** for software in some countries are limited due to its functional nature. In an EU context, most countries give authors moral rights even for software (except maybe ability to object to modification may be curtailed if it conflicts with normal software use). If a prompt engineer has moral rights (like paternity or integrity) in a prompt they wrote, that could be awkward in a commercial setting – employers might want to avoid that by classifying it as software (some jurisdictions either disallow moral rights for software or make them waivable, since software often gets modified by others). This is a subtle but real aspect: A prompt modified by someone else – could the original author claim a moral right violation? Possibly if it’s a literary work and the change is prejudicial. Under software rules, modifications by lawful users are expected (Art 5(1) and exceptions). So again, for a company, treating them as software could circumvent potential moral rights claims by employees.

**(d) Enforcement differences:** Enforcing rights in prompts might differ if it’s software – one could use anti-piracy laws, or certain evidentiary presumptions (some jurisdictions have presumptions for software authorship). But likely one would still just use copyright infringement framework.

**(e) Policy**: On a higher level, is it **desirable** to treat prompts as software? The Kluwer piece points out a challenge: EU law has *different sets of rules for software vs other copyright*. If prompts become very important and are classified one way or the other, it has downstream effects on licensing, exceptions, etc. There may be inconsistency if, say, a short creative prompt is “literary work” and a long functional prompt is “software” – two regimes for similar things. Perhaps the law would need to clarify via legislation or jurisprudence. Right now, it’s an open question that academics are raising preemptively, anticipating that as natural language becomes a standard interface (the “natural language computer” concept), the legal definition of software might be interpreted to extend to such interfaces. We are in a transitional moment – reminiscent of when software itself was new and courts had to decide to treat it as literary work. A U.S. court in the 1980s famously said applying copyright to programs is like “assembling a jigsaw puzzle whose pieces do not quite fit”. Similarly, applying the software puzzle to prompts may not perfectly fit, but it might be the least bad option.

**Conclusion on prompts as programs:** It is **legally plausible but untested** to argue that a sufficiently complex AI prompt is a “computer program in any form.” Doing so would bring the prompt under the Software Directive’s wing, giving clearer ownership to employers and aligning it with how we protect other functional code. It would not protect the prompt’s functional ideas or outputs (those remain free or require patents), but it would secure the textual instructions similar to code. The main drawback is that prompts differ from code in predictability and format, and treating them as software could allow certain *fair use* (like reverse-engineering) that prompt creators might not anticipate. Moreover, a prompt that requires further creative programming to be effective might be seen as *not yet a program* (just preparatory work) if the human prompt isn’t the final set of instructions but the AI’s internal weights produce the final “program” for output. The Dutch Supreme Court’s logic suggests if creative programming is still needed after the prompt, then the prompt was not a complete program but just preparatory text. In AI, once the prompt is given, the model runs by itself – no further human programming – so arguably the prompt was the final input.

Ultimately, whether prompts “can be considered computer programs” is unsettled. If a court were persuaded, the **practical differences** would be moderate – the core issue of originality remains, but the legal treatment would shift in nuanced ways. As prompts become more integral to software operations, the classification question may become ripe for judicial decision or even legislative clarification. For now, prompt authors might invoke both theories in the alternative: “My prompt is an original literary work, or alternatively, protected as a program.” The next Part steps away from copyright and asks if a prompt could ever be protected by **patent law** – a very different type of IP right, focused on functionality and innovation rather than expression.

## 4. Patent protection for prompts

**Can AI prompts be patented?** Patent law protects novel, non-obvious **technical inventions** – products or processes that provide a new technical solution. At first blush, an AI prompt is just information (a text string) and might not seem like the kind of tangible invention patents cover. However, inventors and commentators have speculated about patenting prompts, especially as they can act as blueprints to produce useful outcomes. This section analyzes whether an AI prompt could meet the criteria for patentability under the European Patent Convention (EPC) and related EU patent law principles.

We proceed by examining: (1) the **subject-matter eligibility** of prompts – do they fall into excluded categories like “presentation of information” or “computer program as such”? (2) assuming a prompt is not categorically excluded, could it satisfy the requirements of **novelty, inventive step, and industrial application**? and (3) practical considerations and precedent (are there any patent applications on prompts, how EPO might treat them).

### 4.1 Patentable subject matter: is a prompt an “invention” or just information?

The EPC Article 52 defines what can be an invention and lists exclusions. In particular, **“schemes, rules and methods for performing mental acts… and presentations of information”** are not regarded as inventions *“as such”* (Art 52(2) & (3)). A bare prompt – essentially a piece of text instructing a model – might be characterized as either a “scheme for performing a mental act” (if we analogize AI to a brain) or more directly as a “presentation of information.” Indeed, a prompt is literally a presentation of information (words) to a machine. Typically, things like designs of user interfaces or communication content fall under “presentation of information” and are not patentable unless they produce a further technical effect. For example, the EPO might refuse a patent on just the content of a message or an advertisement slogan, considering it a non-technical information presentation.

However, EPC exclusions only apply to the subject-matter “as such.” If the prompt is part of a larger **technical process**, it might escape the exclusion. European practice uses the **COMVIK approach**: we identify the invention’s features, split into those contributing to technical character and those that don’t, and only the technical ones count for inventive step. A *prompt by itself* likely has no inherent technical character – it’s just text. But if one frames the invention as a **method involving using a prompt in a generative AI system to achieve a technical outcome**, it could have technical character by virtue of that context. For instance, “a method of operating a neural network to manufacture a new chemical compound, comprising inputting a prompt with specific parameters” might be argued as a technical process (if indeed it yields a chemical structure with a technical effect). The prompt is part of a method that solves a technical problem (finding a compound).

So one pathway to patentability is **embedding the prompt in a larger invention**. The prompt alone (“text X”) is not an apparatus or process; but “using text X in machine Y to achieve result Z” could be a process. The question becomes: does that process solve a **technical problem**? EPO case law demands AI or algorithm inventions either have a specific technical application or contribute to the technical functioning of a computer to be patentable. If the prompt’s purpose is purely to create artistic or literary content (e.g. “generate a fantasy novel plot”), that is arguably *not a technical purpose* – it’s creative, non-technical. But if the prompt is used in, say, a medical AI system to generate treatment recommendations, there’s a stronger case for a technical purpose (healthcare).

Even then, the **inventive step** must lie in something technical. A novel prompt could be novel information, but the EPO tends to disregard innovations that lie solely in the content of information rather than a new technical means. For example, inventing a new mathematical formula or a new presentation format is not patentable unless it solves a technical issue. A prompt might be seen like a new formula for getting a result out of an AI – but since the AI itself is doing the heavy lifting, the prompt’s content might be considered a non-technical contribution. The EPO might say: “The idea of phrasing the input in this way is a linguistic or cognitive contribution, not a technical one.” Unless the phrasing achieves a technical effect (like reducing computational load or bias in the model – something measurable in technical terms), it’s likely to be dismissed as non-technical.

The **“presentation of information”** exclusion is particularly apt: EPO Guidelines (G-II, 3.7) state that the mere content of information (what is conveyed) is not technical, though the manner of presenting (if it has cognitive/physiological effect) can be. A prompt is basically content conveyed to a machine. One could argue the prompt is optimized to have a particular effect on the machine’s state (like reducing token usage or focusing attention – which is a technical effect if framed as improved computational efficiency). But if the effect is just “better output” in a qualitative sense, EPO might call it non-technical improvement (just improving quality of text or image is not per se technical unless tied to e.g. reduced noise, improved resolution – which might be considered technical in image processing perhaps).

Given these hurdles, a *naked prompt* (as a standalone text) is probably not patentable subject matter. The more promising scenario is where someone has devised a **specific category of prompts that achieve a technical result** not achievable before. For instance, consider a prompt that instructs an AI to configure a manufacturing machine’s parameters – essentially using the AI to indirectly control hardware. If that prompt is structured in a novel way to achieve a better control signal, one might try to claim the overall method as an invention. But then the prompt is just part of the method.

Some commentators (like an IPWatchdog article in early 2024) have speculated about patenting prompts by treating them analogous to broad claims. One suggestion was to write patent claims that basically say: *“A product having characteristic X, wherein the product is described by the output of an AI when given prompt P.”*. This is an unusual claim format, likely not permissible under EPC clarity rules, but it shows creative thinking: patent the *result* but reference the prompt in the claim. Another idea was to treat a detailed prompt as like a pseudocode for an algorithm – if the underlying algorithm is patentable (say a new encryption method), then a prompt that causes an AI to generate that algorithm’s code might be encompassed. However, this is more about patenting the underlying algorithm via any means, not the prompt per se.

In short, to pass the **eligibility** filter, a prompt must be tied to a **technical solution**. A generic creative prompt (like for art or text) is likely *deemed non-technical*. A prompt geared to solving a technical problem (like generating optimized engineering designs or controlling a technical system) stands a better chance, but even then the novelty would have to reside in the prompt’s innovative content, which the EPO might see as an abstract idea (if it's just a description).

### 4.2 Novelty and inventive step: assuming technical nature

Suppose one surmounts the initial hurdle and frames a patent claim involving a prompt in a way that has technical character (e.g., “Method of operating [technical system] using an AI prompt comprising [specific features] to achieve [technical outcome]”). The next inquiries are **novelty** and **inventive step**.

-   **Novelty:** The prompt (as part of the claim) must not be fully disclosed in the prior art. Given the explosion of prompts shared online, novelty could be a factual challenge. But let’s say this is a genuinely new prompt format that no one published. Novelty could be fine if the combination of features in the prompt hasn’t been described. However, if the prompt is something obvious like “ask the AI to do X,” it might have been suggested somewhere. Patent novelty for a piece of text is unusual – you’d have to search literature to see if that text or approach was ever documented. If it’s truly new, novelty can be satisfied by absence of identical prior disclosure.

-   **Inventive step:** The real crux. The invention must not be obvious to a skilled person in light of prior art. If the only inventive aspect is the **content of the prompt** (a phrase or idea to combine certain instructions), an examiner will question whether that is an obvious thing to try. For example, suppose the prompt is to generate a new drug molecule by telling the AI “Design a molecule with these properties.” If previously people tried similar prompts, it may be obvious. On the other hand, if someone discovered a very clever trick in phrasing that yields a surprising technical effect (like reducing hallucinations or achieving an outcome no one thought possible), one could argue there’s an inventive insight. But an examiner could retort: “This is just a non-technical idea (maybe obvious to try different phrasings) with no deeper technical contribution.” To overcome that, one needs to pinpoint a technical problem and show the prompt’s design overcame it in a non-obvious way. Perhaps something like: the AI used to fail at a task due to certain biases, and the inventor found that by including a specific calibration prompt segment, it eliminates the bias – thereby solving a technical problem (improving reliability of AI system). If evidence showed this prompt trick was non-obvious and effective, there’s a case for inventive step.

One difficulty: **who is the “skilled person”** here? Possibly an AI developer or prompt engineer with knowledge of AI systems. That hypothetical person might have a repertoire of prompt techniques. If the invention is basically “include a random seed token in the prompt to reduce overfitting” (just as an example), is that something the skilled AI practitioner would think of? Possibly, if such practices are known. If not, maybe it’s inventive. It’s highly case-by-case. But the general caution is that **inventive concepts in information content are rarely recognized** unless tightly linked to a technical effect.

The IPWatchdog piece suggests broad prompts describing classes of inventions could be patented if the class is novel. For instance, a prompt that describes a completely new kind of hammer not seen before, and thus effectively claims that hammer. That is akin to writing a patent claim for the hammer itself; the prompt angle doesn’t add much except as a drafting gimmick. In EPC practice, one would simply patent the hammer if it’s novel and non-obvious as a product, no need to mention the prompt. Claiming “a hammer described by output of an AI given prompt P” is an unusual, perhaps unclear claim. It might be rejected for indefiniteness – patent claims usually must define the product’s features, not refer to an AI’s output description.

-   **Industrial application:** A prompt itself, being just text, doesn’t directly have a physical result unless we consider the output. But if we frame as a method, likely industrial applicability is met if it can be used in industry (which generative processes can, e.g. designing something). That’s usually a low bar unless it’s something abstract like a purely aesthetic creation method – but even that can be said to have use in creative industries.

**Precedent:** There is no known EPO case specifically on patenting a user input or prompt text. However, relevant analogies: - **Software patents**: The EPO does allow patents on computer-implemented inventions (including those involving software or algorithms) if they have technical effect. A prompt could be seen as part of a software system (input data). But data by itself is generally not patentable unless processed in a new way. Patents have been granted on things like specific query generation methods for search engines that improve search performance – that could be analogous if the prompt creation method improves the AI’s technical performance (say reducing compute or memory). - **User interface inventions**: Sometimes UI improvements (like a particular GUI layout that improves user performance) have been patented, considered technical if they solve a human-machine interaction issue (like reducing cognitive load). A carefully crafted prompt might be seen as solving a “machine understanding” problem – enabling better parsing by the AI (like a kind of improved interface between human and model). If one could quantify that as a technical improvement (e.g. faster convergence or less memory use because prompt structured data better), that might be a hook. - The GJE article notes many AI-related applications fail for lack of clear technical purpose. A prompt whose primary effect is user preference (e.g. nicer image) is not technical. They specifically mention generative outputs often “lack a clearly defined technical objective”, being driven by user preferences. That suggests the EPO would likely view generative art or text prompts as failing the technical purpose requirement. They recommend keeping AI inventions anchored in a technical field (audio, image processing with objective features, etc.). - There is also the conceptual issue: if someone tried to patent a prompt per se, could it be considered just an attempt to monopolize a **communication to an AI**? That might raise concerns akin to patenting a scientific theory or mathematical method (excluded under Art 52 as well) if the prompt is effectively an algorithmic step. - Not to mention, disclosing the prompt in a patent makes it public – so if the patent is not granted or after it expires, everyone can use it. Many might prefer to keep a highly effective prompt as a trade secret rather than patent it, given the uncertainty of patenting and the long publication.

### 4.3 Tradeoffs and current thinking on patenting prompts

Given the above, it appears that **patent protection for prompts is largely theoretical at present**. We have not seen high-profile attempts to patent a standalone prompt. It’s telling that companies concerned about prompt theft (like the OpenEvidence case) went to trade secret law, not patent. Patents require revealing the invention and enduring a lengthy examination (3-5 years at EPO) – by which time the AI models or prompts may have evolved significantly, reducing business value. Also, the prompt has to be specific enough in the claim to be meaningful. A claim like “a text prompt comprising features A, B, C that causes a neural network to produce desired output” would likely face clarity and sufficiency issues: one must show that just any network with that prompt will do it, or specify the model environment.

However, there are scenarios where an **inventive prompt** could merit a patent: - If someone pioneers a class of prompts that enable AI to perform a *new technical function*, such as controlling machinery or achieving a scientific result that AIs couldn’t previously do. For example, suppose a prompt sequence that reliably causes a trained model to simulate quantum physics experiments (thus solving a technical problem). If that idea was non-obvious and provides a concrete technical result (like better simulation accuracy), it might be patent-worthy as part of a method. - If the prompt is tied to a **physical outcome** (like 3D printing instructions generated by AI from a prompt), one could try to claim the process from prompt to printed object. The novelty might lie in how the prompt yields the design. But again, likely one would patent the printed object if it’s new, not the prompt.

The overarching theme in EU is that **patents are reserved for technical innovations**, and the bar is high to show an AI prompt innovation is technical and non-obvious. By contrast, the U.S. tends to allow more abstract patents if phrased in certain ways (though even there, abstract idea doctrine under Alice could be a hurdle for pure info).

Practically, also consider **enforcement**: if you had a patent on a prompt, how to detect infringement? You’d have to catch someone using the same or equivalent prompt. If it’s in secret or behind an interface, not easy. Unlike a device you can inspect, prompts are ephemeral. This is similar to software patents – enforcement can be tricky if code is not disclosed, but at least products might show evidence. With prompts, unless outputs have telltale signs or someone copies text exactly, detection is hard. So patent might be a weak remedy compared to something like trade secret where you sue if an insider or hacker steals it.

**Conclusion on patents:** In principle, **nothing in law outright forbids patenting a prompt** – as long as it’s framed as part of a technical invention. But in practice, it faces formidable obstacles: - It likely falls under excluded subject matter if taken alone. - It may not satisfy inventive step if the only novelty is in informational content without technical effect. - It’s likely easier to protect valuable prompts as secrets or via copyright (for literal copying) than to convince a patent office to grant a 20-year monopoly on using a particular AI input. - Patent law’s disclosure requirement is at odds with how prompt value is often ephemeral or context-dependent (what’s great for GPT-4 now may be moot for GPT-5, etc., long before patent issuance).

To date, we have not seen EU patents granted purely on prompt content. Unless and until someone demonstrates a prompt that yields a distinctly technical solution to a recognized technical problem (and writes a skilled patent application around it), **patent protection for prompts remains largely speculative**. The next Part turns to a more straightforward form of protection that has already seen real-world invocation: **trade secret law**, which may provide de facto protection without the hurdles of formality or subject-matter limitations.

## 5. Trade secret protection for prompts

Unlike copyright or patents, **trade secret law** does not confer exclusive rights erga omnes, but it protects valuable information from being wrongfully acquired or disclosed. Under EU Directive (EU) 2016/943 (the Trade Secrets Directive), a “trade secret” is defined as information that **(a)** is secret (not generally known or readily accessible), **(b)** has commercial value because it is secret, and **(c)** has been subject to reasonable steps by its holder to keep it secret. This framework squarely applies to things like formulas, business methods, algorithms – and indeed can apply to **AI prompts** that meet those criteria.

This Part examines whether prompts can be protected as trade secrets, and what that entails. It is in many ways the most straightforward path: if a prompt is **valuable and you keep it confidential**, the law can help prevent or remedy its theft or unauthorized disclosure. Unlike IP rights, no originality or technical character is required – even a very utilitarian prompt could qualify if kept secret and valuable. However, trade secrets only protect against **misappropriation**, not independent discovery or reverse engineering by fair means.

### 5.1 When is a prompt a protectable trade secret?

Under the definition quoted above, to qualify as a trade secret, a prompt must:

-   **Not be generally known or readily accessible** to experts or users in the field. So, if a prompt has been posted on a public forum or widely shared, it loses secrecy and cannot be claimed as a trade secret. But if a company develops unique prompts internally and does not disclose them, that condition can be met. Even if outsiders can guess similar prompts, what matters is that the specific information (the prompt text or method) isn’t common knowledge. For example, a particular prompt engineering technique that only your team knows could be secret.

-   **Have commercial value because of its secrecy.** This means the prompt gives you some competitive advantage or economic benefit as long as others don’t have it. Many prompts likely qualify: a prompt that significantly improves an AI’s output could give a company a head start (e.g. generating better marketing copy or more efficient code). The value is directly tied to others not having it – if everyone had it, it’s no longer special. So if a prompt is trivial or easily devised by anyone, it might not have much “commercial value *because* it is secret.” But if it took lots of trial and error to find and yields superior results, that effort and result is valuable, and being the only one (or one of few) who know it confers advantage. Cases in other domains (like secret recipes or manufacturing processes) set the precedent: even if something could *in theory* be independently discovered, its secrecy still grants an edge and hence value.

-   **Subject to reasonable steps to keep secret.** This is crucial: the company or individual must actively protect the prompt’s confidentiality – e.g. through NDAs, access controls, encryption, marking it confidential, etc. If you just have employees who use the prompt openly and it leaks without any contractual or security measures, a court might find you failed to take reasonable steps. In context, an AI company might restrict prompt knowledge to need-to-know employees, embed it in code (not visible to users), or if sharing with business partners, do so under confidentiality agreements. The diligence here can determine protection: the Trade Secrets Directive specifically requires proof of such steps. In the AI context, one measure could be building the prompt into the system where users can’t directly extract it.

If these are met, the prompt qualifies as a trade secret. What protection does that give? If someone **unlawfully acquires, uses, or discloses** the prompt, the holder can take legal action for misappropriation. Unlawful acquisition includes theft, industrial espionage, breach of confidence, or any other conduct contrary to honest commercial practices. In the prompt scenario, hacking into a system to get the prompt or an ex-employee taking it to a rival would be classic unlawful acquisition. The Directive specifically says acquisition is unlawful whenever done without consent by unauthorized access or copying of files containing the secret – which covers e.g. someone who finds a way to extract the prompt from the AI system.

Notably, the Directive (and national laws following it) permits **lawful acquisition** via independent discovery or reverse engineering of a lawfully acquired product. So if a competitor independently figures out an equally good prompt, that’s not illegal – there’s no exclusivity like patent gives. Or if they legitimately had access to outputs or limited use of the AI and from that deduced the prompt (which might be possible in some cases via “prompt injection” or other testing, unless such testing itself is considered contrary to honest practices), that might be allowed. The Directive allows reverse engineering of a product someone obtained lawfully unless restricted by agreement. If a company offers an AI service and users can query it, arguably those users could try prompt injection to uncover its hidden prompts unless bound by contract not to.

Case in point: the **OpenEvidence v. Pathway** scenario. OpenEvidence had an AI platform with proprietary prompt-based configurations. Pathway lied about their identity to become a user (impersonating a doctor to get access) and then executed dozens of cleverly crafted inputs to get the AI to reveal its internal prompts and instructions. This is basically reverse engineering via violation of terms (since presumably the user agreement forbade such manipulation). OpenEvidence alleges this was misappropriation of trade secrets. Indeed, if proven, it fits: the prompt designs were secret, valuable in giving their AI a unique edge, and Pathway acquired them by dishonest means (breaching access rules, using “prompt injection” as a hacking technique). That case, cited earlier, confirms that at least some companies view prompts as trade secrets and are using trade secret law to protect them. (It was filed in a US court, but given similar trade secret principles in EU, a European firm could do likewise under the Directive and national implementations.)

So any prompt that a company does not want competitors to have, they should treat as a potential trade secret: e.g., not include it in any published material, guard it behind authentication, and contractually bind employees or partners who might see it. The formalities are less strict than patent (no registration needed), but the onus is on the holder to maintain secrecy.

A nuance: can multiple pieces of information collectively be a secret? Yes – even if bits are known, the combination can be secret if not readily assembled. So a whole **prompt engineering strategy or library** could be a protected secret. Each prompt in an internal library might not individually be mind-blowing, but the set or the fact that they are tuned to certain tasks might be proprietary.

Trade secret law does not excuse one from lawful investigation though: if someone legally got access and “observed, studied, or tested” a product (here, maybe the AI’s outputs) to deduce the secret, that’s lawful, as long as not contractually prohibited. Many AI systems now have terms forbidding reverse engineering. If a user violates those terms to find the prompt, that likely counts as “contrary to honest practices” under the Directive, thus unlawful acquisition. So contract law and TS law work in tandem: the contract makes it dishonest to do that, and TS law then kicks in when they do it anyway.

### 5.2 Enforcement and remedies under trade secret law

If someone misappropriates a prompt secret, what can the trade secret holder do? The EU Trade Secrets Directive provides for various remedies: - **Injunctive relief:** courts can stop the use or disclosure of the secret, prevent production of goods that would exploit it, etc. So a court might order the misappropriating competitor to cease using the stolen prompt and not disclose it further. If that competitor integrated the prompt into a competing AI, the court could even bar them from offering that product (or require removing the secret elements). - **Seizure of infringing goods:** If the secret is embodied in products (in prompts case, maybe not directly relevant unless a product encodes that prompt), those goods can be seized. - **Damages:** The holder can get damages for losses or unjust enrichment due to the misappropriation. For example, if the competitor made profits by using the stolen prompt to improve their service, the original firm could claim those profits or at least a royalty. - **Confidentiality in litigation:** The Directive also ensures the secret isn’t unnecessarily exposed in court – proceedings can limit access to the info to certain persons (though the details of how each country implements that vary).

Crucially, trade secret law does **not** make it illegal for others to create or use similar prompts if they came up with them independently or got them legitimately. So it’s a weaker exclusivity than a patent. It’s more a remedy against unfair behavior. But in practice, if your main risk is employees leaving or hackers, trade secret is powerful: it gives you a cause of action where otherwise, without patent, you’d have none (since copyright might not protect a short functional prompt, and patent you likely don’t have).

Trade secret protection can **last indefinitely** (until the secret is out). So as long as a prompt retains value and secrecy, you can keep it secret for as many years as you like – better than patent’s 20-year max, if the prompt is something that remains relevant (which in AI context, the longevity might not be decades, but still, indefinite potential).

However, this regime has downsides: - If someone publicly discloses the prompt (say an ex-employee posts it online), the secret status may be lost. You can sue that ex-employee for damages, but the cat’s out of the bag; you can’t make the information secret again. Some measures like getting an injunction to take down info might help if done quickly, but the internet seldom forgets. So leakage can destroy the value beyond legal recourse. - If multiple independent developers all come up with similar prompts, none can stop the others via trade secret – each’s knowledge is their own secret. It’s only misappropriation that’s actionable, not mere use of similar knowledge. So if it’s an area where multiple people have the expertise, secrets might leak through no illicit action (convergent evolution of prompts). - **Ex-employees**: A tricky aspect is when employees move to new jobs, they carry knowledge in their head. Trade secret law in EU tries to avoid unduly hindering mobility; it doesn’t allow restraining someone from using their general skills and experience (which might include knowledge of how to prompt). But taking a specific confidential prompt text may cross the line. The new employer could be liable if they encourage or knowingly use the former employer’s secrets. Courts might assess if the info is truly specific and secret or just part of normal skillset now. This is a classic area of dispute in trade secrets (espionage vs. unprotected know-how). - **Public interest exceptions:** The Directive provides exceptions where acquiring/disclosing a secret is lawful, e.g. whistleblowing to reveal wrongdoing, or for journalistic freedom, or a workers’ representative sharing it for legitimate purposes. Unlikely to apply to prompts except in odd cases (maybe if a prompt had some dangerous hidden behavior and an employee exposed it for public interest).

In the known example, Pathway (allegedly) impersonated a user and tricked the AI to reveal secrets. That’s clearly outside normal use – they basically hacked via prompts. So that’s actionable. If they had instead legitimately hired one of OpenEvidence’s engineers who remembered some of the prompts and recreated them, that’s a murkier scenario: OpenEvidence could still sue that employee for breach of confidentiality, and the new company if it was a direct transfer of specific secret info. If the engineer just used general knowledge like “we found adding a temperature parameter at end helps outputs” (which might be considered more general technique), it might be hard to claim that’s a protected secret if it’s borderline common practice or too abstract.

All considered, **trade secret is currently the strongest, most realistic form of IP-like protection for prompts**. It’s already being invoked in disputes, indicating the legal community sees it as the proper tool in absence of formal IP rights. It is flexible: any prompt of any nature qualifies if it meets secrecy and value conditions – no need to prove creativity or technical effect. The trade-off is you must maintain secrecy and accept that independent discovery by others is allowed. For fast-moving fields like AI, where innovations often come from many sources, that’s a significant caveat – your advantage might be short-lived as others find similar solutions.

## 6. Comparative evaluation and the path ahead

Having canvassed four approaches – **copyright**, **software (computer program) copyright**, **patents**, and **trade secrets** – we now step back to assess which mechanism (or combination) is most effective for protecting AI prompts, and what broader implications arise. Each approach has distinct **strengths and limitations**:

-   **Copyright (literary works):** Easiest to obtain (automatic), potentially covers creative prompts, but offers narrow protection (only verbatim or closely similar copying) and may not apply to highly functional or short prompts. It does not protect the idea or outcome of the prompt, only its textual form. Enforcement is relatively straightforward if someone blatantly copies a prompt and publishes it (e.g., ripping prompts from PromptBase and reselling them verbatim – that would infringe if the prompts are original). But if someone paraphrases or independently devises a similar prompt, copyright provides no remedy. Also, the threshold question (is the prompt a work?) injects uncertainty – some courts may deem prompts unprotectable ideas, as in the Czech obiter.

-   **Copyright (software approach):** In theory, classifying prompts as computer programs could grant the same copyright protection but with different legal rules benefiting prompt owners (like default employer ownership and restricted exceptions). However, this approach is novel and untested. It might slightly strengthen a prompt owner’s position in an employment context, but it doesn’t solve the core issue of functional overlap – it still only guards against copying the prompt text. Moreover, it's unclear if courts would accept that classification; in the meantime, treating prompts as “normal” literary works is the safer route in litigation (since the end result – protection against copying text – is similar either way). The main difference, the “different rules” (exceptions, interoperability allowances), could in some cases actually weaken control (by permitting some reverse engineering). Thus, while conceptually intriguing, the software route is not a panacea and introduces complexity.

-   **Patents:** Provide broad protection (preventing independent use of the same invention) but are largely ill-suited to prompts. Very few prompts could meet the stringent patent criteria of technical contribution and non-obviousness. The time and cost to get a patent, and the requirement of publishing the prompt in a patent application (destroying secrecy), make it an unattractive path for something that might be superseded by new models or prompts in a couple of years. If a prompt is truly part of a larger technical invention (e.g. using AI prompts in a new manufacturing process), it might be patentable as part of that process – but then one is patenting the process, not securing the prompt in isolation. **As a direct mechanism for prompt protection, patents are currently the weakest candidate**: not only is success unlikely, but the strategic trade-off (disclosure vs. 20-year right) seldom makes sense given the pace of AI progress. Indeed, a prompt valuable today might be obsolete by the time a patent is granted (5+ years later). The IPWatchdog’s imaginative speculation about patenting prompts has not yet translated into real-world practice at the EPO or national offices. Until we see a test case, patents remain a theoretical long-shot for prompt protection.

-   **Trade secrets:** By far the most **pragmatically effective** for firms today. If a company has a secret prompt that gives it an edge, keeping it confidential and leveraging trade secret law’s deterrents and remedies is a sound strategy. The advantage is immediate and does not depend on satisfying an originality or inventiveness test. It covers even highly functional, short prompts – as long as they’re not generally known and are guarded, they qualify. The downside is one only has recourse against improper acts (theft, breach of confidence, etc.), not against someone who comes up with the same prompt independently or uses it after an accidental disclosure. For many companies, that’s a reasonable tradeoff: their main fear is direct theft (like a competitor scraping or an insider leaking), which TS law addresses well. Indeed, as generative AI becomes a competitive field, we can expect companies to double-down on secrecy for their prompt tuning techniques, similar to how algorithms or source code are guarded. Trade secret law in the EU, especially after the 2016 Directive harmonization, offers robust tools including rapid injunctive relief and preservation of confidentiality during litigation, which encourages victims to pursue misappropriators without the entire secret going public in the process.

To illustrate the **trade-offs**, consider an enterprise with a portfolio of specialized prompts: - If they tried copyright: they could register them (optional but sometimes done for evidence), but then the prompt’s text becomes a matter of record. They could send cease-and-desist letters if someone copies them verbatim. But proving copying may be hard if the infringer claims independent creation. And copyright wouldn’t stop the infringer from using a slight rewording to achieve the same result, as that’s not copying expression but idea. - If they tried patent: they’d have to publicly disclose the best mode of the prompt in a patent application. If the patent is denied or even if granted, others can read the prompt in the file. Given low grant probability, they risk giving away the secret for nothing. Even if granted, enforcement would be tricky and maybe too late to matter. Also, patents are jurisdiction-limited; prompts can be used globally, and policing worldwide would be nearly impossible. - With trade secrets: They disclose nothing publicly, can act swiftly if an ex-employee tries to use the prompt at a rival (seek an injunction for breach of confidence), and deter casual attempts to steal with the specter of legal action. But they must invest in cybersecurity and training to maintain secrecy, which is a manageable cost relative to others.

**Which works best?** For the immediate future, **trade secrets emerge as the most effective approach for industry**, while **copyright is a second-line protection** primarily against outright copying on open platforms. The two are not mutually exclusive: a prompt can be both a trade secret and copyrighted. Indeed, if a secret prompt is leaked on the internet, the trade secret status might be lost (no longer secret), but the company could still use copyright to takedown the posted content (assuming the prompt is original enough to claim copyright). That interplay means companies should leverage both: maintain secrecy to maximize protection, and have copyright as a fallback if secrecy is breached and the prompt is disseminated (though once public, copyright stops further copying but cannot undo the knowledge dissemination – anyone who saw it can use the idea).

**Software classification** is more a doctrinal debate than a practical measure companies can “choose.” A firm could simply treat its prompts like software in contracts (assigning them as works made for hire, etc.), which is wise. But whether the law views it that way in disputes remains to be seen. It might matter if an employee in a country without strong work-for-hire rules left – if the prompt is considered a computer program, then by Directive 2009/24 the employer automatically owns it, whereas if it’s a general literary work, one looks to national law (which often, but not always, gives employers certain rights). In the EU, many countries by default give employers rights to employees’ works created in course of employment even outside software, but if there’s doubt, companies can explicitly secure prompt rights via contract.

**Implications for the future:** The analysis reveals a gap: none of the formal IP regimes (copyright/patent) perfectly fits AI prompts. Copyright struggles with the merger of idea and expression in short functional texts; patent demands technical invention where often there is mostly creative or linguistic ingenuity; designs and trademarks are irrelevant here. Trade secrets fill the gap but at the cost of losing protection if information goes public – not a true exclusivity, just a deterrent to misappropriation.

One could ask, is there a need for a **sui generis right for AI prompts**? Historically, when a valuable category of information didn’t fit existing IP, legislators sometimes created bespoke protections (e.g., semiconductor mask rights in the 1980s, database sui generis right in the EU in 1996). Could there be a “prompt right”? It seems unlikely and arguably unnecessary: - The economy around prompts is still nascent and arguably well-served by trade secret and contracts. If anything, extending IP too far could impede the free flow of ideas. Many in the AI community share prompt techniques openly; a strong IP right could hamper that collaborative progress. - Overprotection risk: If one could patent or lock down prompts broadly, it might stifle follow-on innovation. Prompts often incorporate references to styles or third-party works (like “in the style of [artist]”), raising issues (the Artnet piece pointed out many prompts lean on other creators’ names). Overly broad protection might run into conflicts with those underlying rights or speech freedoms.

Instead of new rights, the path ahead may involve **clarifying existing law’s application**. Perhaps: - Courts will refine the originality test for prompts: e.g., confirm that *some* prompts can be original works (setting a precedent that, say, a sufficiently elaborate prompt meets the Infopaq standard). - Infringement theories might be tested: e.g., if someone copies an AI-generated output that was produced by a protected prompt, could that be indirect infringement of the prompt’s copyright? (The Oxford talk hypothesized that, but likely courts would reject that – copying the image is not copying the text of prompt). - Software notion: Perhaps an authoritative voice (like a CJEU decision or a legislative recital in future AI-related law) might clarify if prompts are covered under software copyright or not. If the AI Act (currently in EU legislative process) doesn’t cover IP, maybe future Commission guidelines on AI and IP could address prompts specifically. - **Contract and TOS enforcement**: We might see more reliance on contract law: e.g., PromptBase’s terms claim IP but also likely restrict buyers from sharing purchased prompts. Enforcing those terms (as contracts) could be another route – not IP law per se, but important. If a buyer resells a prompt from PromptBase, the seller could sue for breach of contract even if copyright is uncertain. However, contract only binds parties to it, not third parties.

Finally, consider **ethical and policy dimensions**: If AI prompts were strongly protected, would that encourage innovation (by rewarding prompt engineers) or hinder it (by fragmenting knowledge)? There’s a parallel to software in early days – some argued for sui generis protection but ultimately copyright (with adaptations) sufficed. Prompts might similarly just be subsumed under existing doctrines (with some test cases to shape how).

**Conclusion**: Today, for a prompt creator or company, **the prudent strategy** is: - Keep truly valuable prompts confidential and treat them as trade secrets (NDAs, limited access, etc.). - Use technical measures to prevent easy extraction (the Bloomberg case shows how prompt injection can be a threat; developers might design models to resist revealing their instructions). - Leverage copyright registrations or claims as needed if someone outright copies your prompt in a publicly traceable way. - Do not rely on patents (unless your prompt is part of a bigger patented process). - Ensure employment and partnership contracts clearly assign prompt-related rights and impose confidentiality. In other words, lean on **the protections that already exist and are immediately applicable (contract, trade secret, and copyright for literal copying)**, rather than hope for some future legal reform.

The various approaches each have a role, but none is a silver bullet: - **Trade secrets** work best to *prevent theft and provide remedies against dishonest competition*. - **Copyright** works to *deter plagiarism in open forums and give a basis to remove unauthorized postings (via DMCA or EU equivalents)*, albeit limited by the originality of the prompt. - **Patents** are largely *irrelevant for now in prompt protection*, given the mismatch with patent criteria. - **“Computer program” theory** is intellectually interesting and may in time influence jurisprudence, but it doesn't drastically change how one protects prompts day-to-day; it mostly matters for how law conceptualizes prompts in the long term.

In a broader sense, this discussion exemplifies how IP law adapts to new creative paradigms. Just as we saw debates on whether AI outputs can be copyrighted (most say no without human creativity, per CJEU stance requiring human author), now we focus on the human inputs. The **human creativity in prompts** is indeed something the law can reward, but it must fit within existing frameworks. As of 2025, the balance struck seems to be: - Encourage human-crafted prompts by allowing them protection as long as they are sufficiently creative (copyright) or kept secret (trade secret). - But do not create entirely new monopolies that could chill the widespread experimentation with prompts (which has a strong open-source and community-driven element – many prompt techniques are shared freely in AI forums).

**To that extent**, trade secret law appears to be the approach that “works best” in practice for those seeking strong protection, supplemented by targeted use of copyright. Prompt creators who publish their prompts (for sale or in research) sacrifice trade secret protection, relying then on whatever copyright can do – which as we saw, is limited. Those who truly want exclusivity will keep their “secret sauce” prompts under wraps, effectively opting out of the public domain but preserving their edge.

Looking ahead, if prompts become even more central (imagine professional prompt libraries driving critical industries), we might see more formalization – maybe industry standards for prompt licensing, maybe litigation that sets precedents (like a case deciding a prompt had copyright and was infringed, or confirming an AI prompt as a protected software work). The *path ahead* likely involves such **case-by-case development** rather than sweeping legislative intervention. IP law has proven somewhat flexible: courts can adapt principles of originality or technical effect to new contexts like prompts.

In conclusion, among the evaluated approaches: - **Trade secret protection currently works best for securing prompt value**, given it directly targets the main risk (unwanted disclosure/use by others) and imposes duties on those who would obtain the prompt improperly. - **Copyright offers auxiliary protection** against literal copying and may bolster confidence that original prompts are recognized as creative outputs of the prompt engineer – but it fails to protect the functional aspects or prevent independent usage. - **Patents are ill-fitted** to this largely creative/linguistic innovation and introduce more problems than solutions for prompt owners. - **No single approach is perfect**, but a combination – secret-keeping for core competitive prompts, copyright against blatant copiers, and internal policies treating prompts akin to code – provides a workable path.

To that extent, the prudent path for prompt creators is clear: leverage secrecy and contract to maximize control, use copyright where applicable, and do not pin hopes on patents or untested theories. The law, as it stands, can accommodate protection of prompts, albeit indirectly and with important limits rooted in fundamental IP principles (like idea/expression and the need for human creativity). Those limits mean that not every prompt will be protectable – trivial or obvious ones won’t – and that is arguably a good thing: it prevents over-monopolization of basic querying techniques. The **implication** is a balanced outcome: truly innovative, hard-to-discover prompts can be safeguarded (via secrecy or as creative works), while everyday prompting methods remain free for all to use and improve.

As generative AI evolves, so too will the legal understanding. But for now, prompt creators have an arsenal of legal tools – if used wisely – to shield their valuable inputs, without need of new IP rights. The path ahead likely involves refining these existing tools’ application rather than forging new ones, ensuring that the law continues to reward the human ingenuity behind effective AI prompts without stifling the collaborative progress in this field.

**Simply put**, the current legal framework – imperfect as it is – provides multiple overlapping avenues to protect prompts, and the “best” approach will often be a layered one: keep it secret, label it confidential, assert copyright if leaked, and avoid the uncertainty of patent. The diverse nature of prompts (some like mini-programs, some like short poems) means multiple doctrines will remain relevant. The challenge for practitioners and courts will be to apply each doctrine’s tests carefully to this new subject matter, maintaining doctrinal consistency while recognizing the economic realities of prompt engineering. The analysis above demonstrates that when done systematically, EU law *can* accommodate IP protection for AI inputs in a nuanced, fact-specific way – no drastic overhaul needed, just careful interpretation and strategic use of existing principles.

[\^1]: Directive (EU) 2016/943, Art 2(1): “*‘trade secret’ means information which meets all of the following requirements: (a) it is secret in the sense that it is not… generally known among or readily accessible to… circles that normally deal with the kind of information in question; (b) it has commercial value because it is secret; (c) it has been subject to reasonable steps… to keep it secret*.”

[\^2]: *OpenEvidence Inc. v. Pathway Medical Inc.* (D. Mass. complaint filed Feb. 2025). Alleging defendant “*executed dozens of ‘prompt injection’ attacks by crafting inputs to get the AI to reveal proprietary information about how it operates*,” constituting trade secret misappropriation.

[\^3]: *Infopaq International A/S v. Danske Dagblades Forening*, C‑5/08, EU:C:2009:465, para 48. The CJEU held that even an 11-word extract can be protected if it constitutes the “expression of the intellectual creation of the author”.

[\^4]: *Bezpečnostní softwarová asociace* (BSA) v. SVAP, C‑393/09, EU:C:2010:816, para 49. The CJEU ruled that for software, “*where the expression of those components is dictated by their technical function, the criterion of originality is not met, since… the idea and the expression become indissociable*.”

[\^5]: Nuno Sousa e Silva, “Prompts as code?”, *Kluwer Copyright Blog* (5 Nov 2024). Argues that complex prompts mirror the logic of programming languages and queries whether prompts could fall under the definition of computer programs, noting Recital 7 of the Software Directive and broad US definitions.

[\^6]: Bird & Bird (V. Chloupek & M. Taimr), “Czech Court denies copyright protection of AI-generated work” (29 May 2024). Summarizing the Prague Court decision: “*The Court also considered that the prompt itself could only be regarded as a theme or idea for a work, neither of which can be protected by copyright*”.

[\^7]: *SAS Institute Inc. v. World Programming Ltd.*, C‑406/10, EU:C:2012:259, paras 38–40. The CJEU confirmed that source code and object code of a program are protected expressions, but *“neither the functionality of a computer program nor the programming language and the format of data files used in a computer program… constitute a form of expression….”*.

[\^8]: Kate Voller, “Generative AI – not so great at generating European patents” (GJE, 13 May 2024). Notes that many AI patent applications fail at the EPO because the outputs lack a distinct technical purpose, and emphasizes that to be patentable, AI inventions must serve a “specific technical purpose” or involve a “specific technical implementation”.

[\^9]: US Copyright Office, *Copyright and AI* (Jan 2025 report). Clarified that purely AI-generated outputs (from text prompts alone) are not protectable, and likened prompts to instructions conveying ideas, outside copyright – though acknowledging a very creative prompt might contain expressive elements[[4]](https://www.lexology.com/library/detail.aspx?g=af1f00b2-10f7-412e-96ba-27c4451c4322#:~:text=copyright%2C%20as%20outlined%20in%20the,protected%20under%20current%20copyright%20law)[[2]](https://www.lexology.com/library/detail.aspx?g=af1f00b2-10f7-412e-96ba-27c4451c4322#:~:text=The%20report%20also%20addresses%20whether,to%20the%20outputs%20they%20generate).

[\^10]: Artnet News (B. Davis), “Is crafting ‘super prompts’ the art of the future? Probably not” (20 Apr 2023). Observes that PromptBase’s terms claim all prompts are the IP of their creators[[1]](https://news.artnet.com/art-world/ai-prompt-engineer-2288620#:~:text=Illustration%20promptbase,%E2%80%9D), but many prompts reference living artists’ styles – implying legal and ethical tensions in claiming ownership of prompts built on others’ IP or persona.

[1] Is Crafting ‘Super Prompts’ for A.I. Generators the Art of the Future? Probably Not

<https://news.artnet.com/art-world/ai-prompt-engineer-2288620>

[[2]](https://www.lexology.com/library/detail.aspx?g=af1f00b2-10f7-412e-96ba-27c4451c4322#:~:text=The%20report%20also%20addresses%20whether,to%20the%20outputs%20they%20generate) [[3]](https://www.lexology.com/library/detail.aspx?g=af1f00b2-10f7-412e-96ba-27c4451c4322#:~:text=The%20report%20also%20addresses%20whether,to%20the%20outputs%20they%20generate) [[4]](https://www.lexology.com/library/detail.aspx?g=af1f00b2-10f7-412e-96ba-27c4451c4322#:~:text=copyright%2C%20as%20outlined%20in%20the,protected%20under%20current%20copyright%20law) [[5]](https://www.lexology.com/library/detail.aspx?g=af1f00b2-10f7-412e-96ba-27c4451c4322#:~:text=The%20Office%E2%80%99s%20report%20states%20that,than%20the%20user%E2%80%99s%20original%20authorship) Copyright Office Says AI-Generated Works Based on Text Prompts Are Not Protected - Lexology

<https://www.lexology.com/library/detail.aspx?g=af1f00b2-10f7-412e-96ba-27c4451c4322>

