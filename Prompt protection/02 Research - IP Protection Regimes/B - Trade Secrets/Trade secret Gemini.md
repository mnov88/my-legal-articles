# The Ghost in the Machine: Trade Secret Protection for AI Prompts in the European Union

## Introduction

A design firm meticulously develops a multi-layered prompt, a complex tapestry of architectural jargon, stylistic commands, and negative constraints, to coax a generative AI into producing a novel and commercially valuable building aesthetic. A financial analyst, seeking an edge in a volatile market, crafts an intricate query combining economic indicators, historical data patterns, and specific modelling parameters to predict asset price movements with greater accuracy. A pharmaceutical researcher, in the quest for a new therapeutic, engineers a highly precise prompt to guide an AI model in predicting the folding structure of a complex protein. These are not mere questions posed to a machine; they are valuable, engineered informational assets, the product of significant expertise, iteration, and investment. In the burgeoning economy of generative artificial intelligence, the inputs—the prompts—are rapidly becoming as valuable, if not more so, than the outputs they generate. To that extent, the question of their legal protection is not an academic curiosity but a matter of profound commercial and strategic importance for innovative undertakings across the Union.

The central problem this Article addresses is whether, and under what conditions, these informational inputs to generative AI systems can be protected as 'trade secrets' within the legal framework established by Directive (EU) 2016/943 on the protection of undisclosed know-how and business information (the ‘Trade Secrets Directive’ or ‘the Directive’).1 As prompts evolve from simple textual queries into sophisticated, proprietary tools that confer a significant competitive advantage, their alignment with traditional categories of intellectual property becomes increasingly strained.3 Copyright may offer thin protection, limited to the literal expression of the prompt, while patent law is largely inapplicable. Trade secret law, with its flexible, conduct-based approach to protecting commercially valuable confidential information, thus presents itself as the most plausible, and perhaps only, viable legal shield.

This Article will establish that while the doctrinal architecture of the Trade Secrets Directive is sufficiently flexible to accommodate AI prompts, their protection is far from automatic. It is contingent upon a rigorous and demonstrable satisfaction of the Directive’s three-part legal test—a test that, as we will see, presents substantial barriers. The requirements of 'secrecy' and, most critically, 'reasonable steps to keep it secret' create a high evidentiary threshold for what are often intangible, digital assets. Furthermore, the very medium through which these assets are exploited—the AI platforms themselves—is governed by a web of contractual terms of service that may, by design or by default, eviscerate the confidentiality upon which trade secret protection depends. The analysis will proceed in four parts. Part I will deconstruct the doctrinal framework of the Directive, tracing its legislative origins and dissecting the tripartite definition of a 'trade secret'. Part II will apply this legal framework directly to AI prompts, systematically examining whether they can satisfy each of the three cumulative requirements for protection. Part III will then explore the scope of the rights conferred by such protection, assuming it can be established, and the remedies available for their infringement. Finally, Part IV will address the formidable legal and practical limitations that challenge this protection—from doctrinal public interest exceptions to systemic conflicts with other regulatory regimes and, most acutely, the contractual environment of AI platforms. Ultimately, this Article concludes that trade secret law offers a potential but precarious shield for the valuable know-how embedded in AI prompts.

## The Doctrinal Framework for Trade Secret Protection in the European Union

To assess the protectability of AI prompts, one must first comprehend the legal architecture designed to protect undisclosed know-how and business information within the Union. The adoption of Directive (EU) 2016/943 marked a pivotal moment, moving from a fragmented landscape of national laws to a harmonised minimum standard of protection. This legislative intervention was not arbitrary; it was a direct response to identified deficiencies in the internal market and an attempt to align Union law with established international standards. The result is a precise, tripartite legal definition of a 'trade secret' that forms the bedrock of the entire protective regime. Understanding the Directive's genesis and its core definition is therefore indispensable to the analysis that follows.

The legislative history of the Directive reveals a clear and consistent objective: to remedy the legal fragmentation that was seen to inhibit cross-border innovation and investment within the internal market.2 Prior to 2016, the legal protection afforded to trade secrets varied dramatically across Member States, with some relying on unfair competition law, others on general tort principles, and still others on specific provisions within criminal or labour codes.6 The European Commission, in its 2013 proposal for the Directive, identified these disparities as a significant deterrent to businesses—particularly SMEs—engaging in cross-border research cooperation, outsourcing, and other innovation-related activities that depend on the sharing of confidential information.7 The explicit aim, therefore, was to establish a "sufficient and consistent level of civil redress" across the Union in the event of unlawful acquisition, use, or disclosure of a trade secret, thereby fostering a more trustworthy environment for R&D and knowledge exchange.10 This harmonisation effort was consciously anchored in existing international norms, specifically Article 39 of the Agreement on Trade-Related Aspects of Intellectual Property Rights (the TRIPS Agreement), which sets out common international standards for the protection of undisclosed information.2

The centrepiece of this harmonised framework is the definition of a 'trade secret' provided in Article 2(1) of the Directive. This provision establishes a cumulative, three-part test. For information to qualify as a trade secret, it must satisfy all of the following requirements:

$$(a)$$

it is secret in the sense that it is not, as a body or in the precise configuration and assembly of its components, generally known among or readily accessible to persons within the circles that normally deal with the kind of information in question;

$$(b)$$it has commercial value because it is secret;$$(c)$$

it has been subject to reasonable steps under the circumstances, by the person lawfully in control of the information, to keep it secret.13

This definition represents a significant doctrinal shift for several Member States. The preparatory works and the final text of the Directive signal a deliberate move away from the subjective standards that previously existed in some national legal orders—such as the pre-Directive German law, which placed emphasis on the holder's subjective 'will to keep secret' as inferred from the circumstances—towards a more objective, evidence-based standard.14 The introduction of the explicit requirement in Article 2(1)(c) to demonstrate "reasonable steps" was a cornerstone of the harmonisation project, intended to create a more predictable and uniform legal standard across the Union.10 The implication of this shift is profound; mere intent to maintain confidentiality is no longer sufficient. A claimant must now be able to produce concrete evidence of proactive measures taken to protect the information in question. This transforms the management of trade secrets from a passive state of mind into an active, auditable, and continuous process of governance.12 To that extent, the Directive places a considerable evidentiary burden squarely on the party claiming protection—a burden that, as the analysis in Part II will demonstrate, is particularly challenging in the context of intangible digital assets like AI prompts.

## The Application of the Article 2(1) Test to AI Prompts

Having established the doctrinal framework of the Directive, the analysis now turns to its application to the specific subject matter of this inquiry: AI prompts. The question is whether a prompt—a string of digital text designed to elicit a specific response from a generative AI model—can satisfy the cumulative tripartite test laid down in Article 2(1). This requires a granular examination of each of the three prongs: secrecy, commercial value, and the implementation of reasonable protective steps. While the 'commercial value' of a well-engineered prompt is often intuitive, the requirements of 'secrecy' and 'reasonable steps' present significant and complex analytical hurdles, particularly given the digital nature of the asset and the environment in which it is used.

The first condition, secrecy, requires that the information is not "generally known among or readily accessible to persons within the circles that normally deal with the kind of information in question".13 A sophisticated AI prompt, when properly conceptualised as a digital asset, can satisfy this requirement, though the argument is not without nuance. The critical interpretative leverage is found in the Directive’s own language, which extends secrecy not just to the information "as a body" but also to "the precise configuration and assembly of its components".16 This phrasing is crucial. A functional analogy can be drawn to a chemical formula or a complex recipe; the individual components—words, punctuation, coding syntax, parameters like 'temperature' or 'top_p'—are, in isolation, public knowledge.17 However, their specific selection, combination, ordering, weighting, and iterative refinement constitute a "precise configuration" that is neither generally known nor readily accessible. A simple prompt such as "write a poem about a cat" would plainly fail this test. However, a highly engineered prompt—perhaps hundreds of words long, incorporating detailed stylistic instructions, negative constraints, few-shot examples, and specific output formatting—is the product of skill, investment, and experimentation. Its unique assembly is not in the public domain. The digital nature of prompts, while facilitating easy copying, does not in itself defeat secrecy.19 The legal test is not whether the information _can_be copied, but whether it _is_ in fact known or accessible.19 As with any digital object, its secrecy is a function of the technical and organisational access controls placed upon it. While there is as of yet no direct jurisprudence from the Court of Justice of the European Union (CJEU) on the interpretation of "precise configuration" for digital assets like prompts, national courts have, in analogous contexts, recognised that compilations of publicly available data can qualify for trade secret protection where the compilation itself is the product of substantial effort and is not, as a whole, publicly available.20

The second condition—that the information has "commercial value because it is secret"—is more straightforward to establish for an engineered prompt.13 The value of a prompt is not intrinsic to the text itself but is derived from its function: the capacity to elicit a superior, more efficient, or unique output from an AI model. Recital (14) of the Directive provides helpful guidance, clarifying that information possesses commercial value—whether actual or potential—where its unlawful acquisition, use, or disclosure "is likely to harm the interest of the person lawfully controlling it, in that it undermines his or her scientific and technical potential, business or financial interests, strategic positions or ability to compete".11 A secret, well-crafted prompt provides its holder with precisely such a competitive advantage. It may enable the holder to generate higher-quality marketing copy, more accurate source code, novel industrial designs, or more insightful data analysis, and to do so more consistently, more quickly, or at a lower cost than competitors who lack access to that specific prompt.23 The commercial harm that would flow from the prompt's disclosure is the direct erosion of this competitive differentiation. To that extent, the prompt possesses a clear commercial value that is inextricably linked to its secrecy.

The third condition, requiring that the information has been "subject to reasonable steps under the circumstances... to keep it secret," presents the most significant practical and evidentiary gauntlet for a would-be prompt holder.13 As established in Part I, this is an objective test requiring demonstrable, proactive measures. A court will expect to see evidence of a multi-faceted protection strategy encompassing a hierarchy of technical, contractual, and organisational measures.14 Technical measures for a prompt library would include, for instance, storing prompts in an encrypted database, implementing strict access controls on a need-to-know basis, using secure networks for transmitting prompts to an AI API, and maintaining logs to monitor access.14 Contractual measures are equally vital, primarily through robust confidentiality clauses in employment agreements and non-disclosure agreements (NDAs) with any contractors or partners who may have access to the prompts.14 Finally, organisational measures—such as maintaining an internal register of trade secrets, implementing clear policies on the handling of proprietary prompts, and conducting regular employee training on these policies—serve to demonstrate a consistent and deliberate corporate intention to maintain secrecy.14

The jurisprudence of national courts provides a valuable guide to what constitutes "reasonable steps." The decision of the Paris Court of Appeal in a case involving Total Raffinage France (No. 22/06168) is particularly instructive. There, the court found the reasonable steps requirement to be satisfied by a combination of measures including the company's bylaws, a binding confidentiality agreement, internal regulations restricting physical access to the site, and specific obligations of discretion and non-disclosure embedded in employment contracts.28 Conversely, a recent decision by the German Federal Labour Court (8 AZR 172/23) serves as a cautionary tale; it held that an overly broad, "catch-all" confidentiality clause in an employment contract was invalid for placing an unreasonable disadvantage on the employee, thereby leaving the employer without an enforceable contractual basis for its claim.31 This highlights the need for precision. The Directive’s own text—requiring "reasonable steps _under the circumstances_"—signals that the standard is contextual and proportionate, not a demand for absolute, impregnable security.14 A court will weigh factors such as the value of the prompt, the size and resources of the holder, and industry norms.14 While this flexibility is pragmatic, it introduces a degree of legal uncertainty. It is not enough for a prompt holder to implement protective measures; it must also be prepared to articulate and defend in court why the chosen measures were reasonable for its specific circumstances. The first interpretation—that any disclosure defeats secrecy—must therefore be rejected.

## The Scope of Protection and its Practical Enforcement

Assuming a prompt or a collection of prompts successfully navigates the tripartite test of Article 2(1) and qualifies as a trade secret, the analysis must then turn to the practical scope of the rights conferred by the Directive. Protection is not an abstract status; it manifests as a set of entitlements to prevent, and obtain redress for, specific forms of conduct defined as unlawful. The Directive delineates a clear boundary between unlawful misappropriation and lawful forms of acquisition, such as independent discovery and reverse engineering. Understanding this boundary is critical to appreciating both the power and the inherent limits of trade secret protection in the context of AI.

The core of the protection is found in Article 4, which defines the categories of conduct deemed unlawful. First, the acquisition of a trade secret without the holder's consent is unlawful whenever it is carried out by "unauthorised access to, appropriation of, or copying of any documents, objects, materials, substances or electronic files" or by "any other conduct which, under the circumstances, is considered contrary to honest commercial practices".32 In the context of AI prompts, this would straightforwardly cover acts such as hacking into a company's server to steal a prompt library, an employee exfiltrating prompt files to a personal device, or industrial espionage aimed at obtaining a competitor's proprietary prompt engineering methodologies.

Second, and more centrally, the use or disclosure of a trade secret is unlawful if carried out by a person who acquired it unlawfully, is in breach of a confidentiality agreement or other duty of non-disclosure, or is in breach of a contractual duty to limit its use.32 This is the primary right that protects the holder against exploitation by insiders (e.g., employees, contractors) or external bad actors. Crucially, Article 4(4) extends liability to secondary infringers. It renders the acquisition, use, or disclosure of a trade secret unlawful whenever a person, at the time of the act, "knew or ought, under the circumstances, to have known that the trade secret had been obtained directly or indirectly from another person who was using or disclosing the trade secret unlawfully." This provision creates a chain of liability that can reach downstream actors who traffic in misappropriated information.

Furthermore, Article 4(5) introduces the concept of "infringing goods," defining their production, marketing, or importation as an unlawful use of a trade secret where the actor knew or ought to have known of the underlying misappropriation.32 The Directive defines 'infringing goods' as those "the design, characteristics, functioning, production process or marketing of which significantly benefits from trade secrets unlawfully acquired, used or disclosed".13 This provision has powerful implications for AI prompts. An AI-generated output—be it a unique industrial design, a block of source code, a piece of marketing copy, or a detailed financial analysis—created using a stolen prompt could plausibly be classified as an "infringing good" on the basis that its characteristics "significantly benefit" from the misappropriated prompt.33 This would empower the trade secret holder to seek remedies not only against the person who stole the prompt, but also against a third party who knowingly markets the resulting AI-generated content. The available remedies under Chapter III of the Directive are robust, including provisional measures to halt infringement pending trial (Article 10), final injunctions prohibiting further use or disclosure (Article 12), orders for the recall or destruction of infringing goods (Article 12), and the award of damages (Article 14).1

However, these rights are circumscribed by the lawful acts defined in Article 3. Trade secret protection does not confer a monopoly right akin to a patent. Article 3(1)(a) explicitly states that the acquisition of a trade secret is lawful when obtained by "independent discovery or creation".10 If a competitor, through its own skill and effort, independently develops a prompt that is identical or functionally equivalent to another's secret prompt, that competitor has acted lawfully and is free to use it. More problematically for prompt holders, Article 3(1)(b) legitimises reverse engineering, defined as the "observation, study, disassembly or testing of a product or object that has been made available to the public".32 This provision raises a difficult and unresolved question: if an AI-generated _output_ is made public, does the act of analysing that output to deduce the likely _input_ prompt constitute a form of lawful reverse engineering? A strong argument can be made that it does.16 If a competitor can successfully reverse-engineer a proprietary prompt by studying its publicly available outputs, that acquisition would be lawful under the Directive, representing a significant practical limitation on the durability of a prompt's secrecy. To that extent, the protection afforded by the Directive is a shield against misappropriation, not a barrier to legitimate competition and innovation.

## Legal and Practical Limitations on Trade Secret Protection for Prompts

Even where a prompt qualifies as a trade secret and an act of misappropriation has occurred, the holder's ability to seek redress is not absolute. The protective regime established by the Directive is subject to a series of formidable limitations, both doctrinal and practical. The Directive itself contains mandatory public interest exceptions that can override a trade secret claim. Beyond the text of the Directive, a burgeoning body of CJEU case law is establishing a clear principle that trade secret protection must be balanced against other fundamental rights and regulatory obligations, creating a systemic constraint. Perhaps most decisively, the practical reality of using third-party AI platforms introduces a contractual dimension that may preemptively nullify any claim to secrecy. These limitations, individually and collectively, render the protection of AI prompts a highly precarious endeavour.

First, the Directive itself carves out a set of mandatory exceptions in Article 5. A national court must dismiss an application for measures, procedures, and remedies where the alleged acquisition, use, or disclosure of the trade secret was carried out for one of several enumerated purposes.32 These include: exercising the right to freedom of expression and information, which explicitly includes respect for the freedom and pluralism of the media (Article 5(a)); revealing misconduct, wrongdoing, or illegal activity, provided the respondent acted to protect the general public interest—the so-called whistleblower exception (Article 5(b)); disclosure by workers to their representatives as part of the legitimate exercise of their functions (Article 5(c)); and for the purpose of protecting a legitimate interest recognised by Union or national law (Article 5(d)). These exceptions were the subject of intense negotiation during the legislative process, reflecting a conscious effort by the co-legislators to balance the protection of commercial interests against fundamental rights and public accountability.8 Their effect is to create a public interest override. For instance, if an employee or a journalist were to disclose a set of proprietary prompts that were engineered to systematically generate biased, discriminatory, or illegal content, such a disclosure would almost certainly be shielded from liability under Article 5.

Second, a more systemic limitation arises from the interplay between the Trade Secrets Directive and the expanding universe of EU digital regulation. A foundational principle for resolving these conflicts is now emerging from the jurisprudence of the CJEU. The recent judgment in Case C-203/22 _Dun & Bradstreet Austria_ is of paramount importance in this regard.37 In that case, a credit agency refused to provide a data subject with "meaningful information" about the logic of its automated credit-scoring algorithm, as required by the General Data Protection Regulation (GDPR), on the grounds that the algorithm constituted a trade secret.40 The CJEU unequivocally rejected the notion that trade secrecy could serve as a blanket exemption from GDPR obligations. While acknowledging that the right of access under the GDPR is not absolute and must be balanced against the rights of others—including the protection of trade secrets as a form of intellectual property—the Court established a crucial procedural and substantive framework for this balancing act.37 It ruled that the controller cannot be the sole arbiter of this balance. Instead, where a conflict arises, the controller must disclose the allegedly secret information to the competent court or supervisory authority, which is then tasked with conducting a case-by-case assessment to determine the appropriate extent of disclosure to the data subject.37 This judgment establishes a universal principle: trade secrecy is not an absolute shield but rather a factor to be weighed in a judicial or quasi-judicial balancing exercise against competing legal rights and public interests. This principle will undoubtedly be applied by analogy to resolve conflicts with other legislative instruments, such as the transparency obligations for high-risk systems under the AI Act or the data access rights under the Data Act. Indeed, Article 78 of the AI Act already gestures towards such a balance, providing that confidentiality obligations must not hinder effective enforcement, although it has been criticised for lacking a clear procedural mechanism.43 The _Dun & Bradstreet_ ruling effectively supplies that missing mechanism.

Third, and most acutely, a formidable practical impediment arises from the contractual terms governing the use of AI platforms. The very act of submitting a prompt to a third-party service is a disclosure, the legal consequences of which are determined by the provider's terms of service. An analysis of these terms reveals a critical divergence. Consumer-facing services, such as the public version of ChatGPT, have historically included terms that reserve the provider's right to use user inputs for model training and service improvement.45 Agreeing to such terms is fundamentally incompatible with the secrecy requirement of the Directive. In contrast, enterprise-grade API services from providers like OpenAI and Google now typically offer much stronger confidentiality commitments. Their business terms often explicitly state that customer data submitted via the API will not be used to train their models, and that the customer retains ownership of their inputs.46 However, even these enterprise agreements often contain clauses permitting the provider to retain and review data for purposes such as abuse monitoring.47

This contractual environment directly implicates the "reasonable steps" requirement of Article 2(1)(c). A court could very well conclude that a user who submits a proprietary prompt to a service under terms that grant the provider any rights to use, review, or retain that data—even for limited purposes—has failed to take reasonable steps to keep it secret. The voluntary disclosure to a third party without a strict, unequivocal obligation of confidentiality could be interpreted as a contractual waiver of trade secret status.45 This is not a mere theoretical possibility; it is a direct and likely consequence of the legal test. The viability of any trade secret claim for an AI prompt is therefore critically—and perhaps fatally—dependent on the precise contractual language of the AI service agreement. This creates a practical bifurcation where protection may only be plausible for users of premium, enterprise-level services that offer explicit zero-retention and no-training guarantees, while users of more common consumer-grade tools may have, in effect, contractually surrendered their claim to secrecy from the outset. This practical limitation must therefore be seen as the most immediate and significant barrier to the protection of prompts as trade secrets.

## Conclusion

The doctrinal architecture of Directive 2016/943 is, in principle, sufficiently capacious and technologically neutral to accommodate the protection of highly engineered AI prompts as trade secrets. The legal framework does not foreclose the possibility; rather, it establishes a demanding set of conditions. This Article has demonstrated that the protectability of a prompt is not a matter of its inherent nature, but a function of its characteristics and the context of its creation and use. A prompt that is the product of significant investment and expertise, whose specific configuration of components is not generally known, and which provides a demonstrable competitive advantage, can satisfy the core requirements of secrecy and commercial value under Article 2(1) of the Directive.

However, this potential for protection is both precarious and heavily circumscribed. The analysis has shown that the most formidable hurdle is the requirement to have taken "reasonable steps" to maintain secrecy. This is not a passive state but an active, demonstrable, and continuous process of governance, requiring a sophisticated combination of technical, contractual, and organisational measures. Even where a prompt successfully qualifies for protection, that protection is far from absolute. It is delimited by the right of competitors to engage in lawful independent discovery and reverse engineering. More fundamentally, it is subject to a series of mandatory public interest exceptions under Article 5 of the Directive and, as the CJEU's judgment in _Dun & Bradstreet_ makes clear, must be balanced on a case-by-case basis against competing fundamental rights and regulatory transparency obligations.

Most critically, the entire legal analysis is conditioned by the practical and contractual realities of the AI ecosystem. The terms of service of the platforms on which these prompts are used can act as a dispositive barrier, potentially constituting a contractual waiver of the very secrecy upon which protection depends. Users of consumer-grade AI tools, in particular, may find that by agreeing to the provider's terms, they have failed the "reasonable steps" test before any question of misappropriation even arises. To that extent, while the ghost of a trade secret may indeed inhabit the machine—in the form of the valuable, undisclosed know-how embedded within a sophisticated prompt—its legal manifestation is contingent, fragile, and ultimately dependent on a complex and challenging interplay of doctrinal requirements, overlapping regulatory frameworks, and the unforgiving logic of private contractual ordering. The protection is possible, but it must be earned, documented, and defended at every turn.