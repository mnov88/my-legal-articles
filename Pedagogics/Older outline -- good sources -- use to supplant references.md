## **Revised Article Outline: Multiply-Loaded Pedagogy Through Generative AI in Legal Education**

**Total: ~10,000 words**

---

### **1. Introduction: From AI Adoption to Design Awareness** (~1,000 words)

**Purpose:** Establish that legal educators are increasingly using AI to generate teaching materials (86% student adoption, Nature 2025) but typically replicate single-handle approaches—rational case studies, practice problems—missing AI's potential for intentional multi-handle design. Position multiply-loaded pedagogy as design principle AI's flexibility makes practical.

**Arguments:** Open with Carnegie Report's 17-year-old critique: case method "drills abstraction" while "connecting remains outside." AI adoption is ubiquitous but mostly automating existing approaches (faster quiz generation, grading). What's missing: design awareness—using AI's flexibility to intentionally create materials engaging multiple pedagogical handles simultaneously (emotional, rational, social, sensory, metacognitive). This article demonstrates multiply-loaded pedagogy through varied examples, showing integration beats multiplication and AI enables specification over search.

**FYI - use if needed:** Critical readiness gap establishes urgency: Student AI adoption is near-universal and growing rapidly. The UK Higher Education Policy Institute's 2025 survey reports that 92% of UK undergraduates used at least one AI tool, up from 66% the previous year; globally, 86% of students across 16 countries regularly use AI in their studies (Digital Education Council, 2024). Students' primary motivations are efficiency-oriented: 51% report using AI to "save time" and 50% to "improve quality" (HEPI, 2025). Use for assessments jumped from 53% to 88% in a single year (HEPI, 2025).

Faculty adoption lags dramatically: while 61% of faculty across 28 countries have used AI in teaching, 88% of those report only minimal use (Digital Education Council, 2025, cited in Campbell University meta-summary). Only 17% of faculty rate their AI literacy as advanced or expert; 40% say they are just beginning (DEC, 2025). Institutional response remains slow: only 39% of institutions had AI-related acceptable-use policies in 2025, up from 23% the previous year (EDUCAUSE, cited in Anara, 2025).

This asymmetry produces a readiness crisis: 80% of students report their university's AI integration does not meet expectations; 58% feel they lack sufficient AI skills; 48% feel inadequately prepared for AI-enabled workplaces (DEC, 2024). Moreover, 59% of higher-education leaders believe recent graduates are unprepared for workplaces where AI tools are important (AAC&U/Elon University, cited in Campbell summary). 

This efficiency-oriented student adoption, driven bottom-up without corresponding pedagogical framework, conflicts with process-oriented learning goals—framing the design awareness problem this article addresses.


**Sources:** Carnegie Report (Sullivan et al., 2007) for opening problem; Nature (2025) for AI adoption context. Readiness gap statistics: HEPI Student Generative AI Survey 2025 (https://www.hepi.ac.uk/reports/student-generative-ai-survey-2025/); Digital Education Council Global AI Student Survey 2024 (https://www.digitaleducationcouncil.com/post/what-students-want-key-results-from-dec-global-ai-student-survey-2024) and Global AI Faculty Survey 2025 (cited in Campbell University meta-summary, 2025: https://sites.campbell.edu/academictechnology/2025/03/06/ai-in-higher-education-a-summary-of-recent-surveys-of-students-and-faculty/); EDUCAUSE data (cited in Anara, 2025: https://anara.com/blog/ai-in-education-statistics); AAC&U/Elon University survey (cited in Campbell summary). Position as "everyone uses AI, but not intentionally for multi-handle design."

---

### **2. The Case for Multiply-Loaded Pedagogy** (~2,000 words)

**Purpose:** Establish that (1) multiple pedagogical handles independently produce learning gains (effect sizes d=0.29-1.23), (2) integration within single materials is more efficient than multiplication across separate materials (cognitive load theory), and (3) existing multi-pathway frameworks like UDL failed the efficiency test, creating space for multiply-loaded approach.

**Arguments:** Present learning science evidence for each handle (emotional d=0.4-0.8; embodied d=1.23; peer assessment d=0.31-0.61; formative feedback d=0.40-0.70; dual coding d=0.28-0.53). Then pivot to integration argument: split-attention effect (Sweller) shows separate materials create extraneous cognitive load; Paivio's dual coding + Begolli et al. show simultaneous presentation more efficient when scaffolded. UDL attempted multi-pathway engagement but required resource multiplication—62% faculty cite time barriers, 4-7 years for implementation (Hills et al., 2022; Boysen 2021, 2024). Multiply-loaded pedagogy offers alternative: integration within single materials through intentional design, not multiplication across separate interventions.


**FYI - use if needed:** AI content generation research reveals a quality chasm that strengthens the intentional design argument: A peer-reviewed study evaluating 310 AI-generated eighth-grade civics lesson plans found they were predominantly "moderate to low quality," with nearly half of all learning activities coded at the lowest cognitive level ("remember") and few opportunities for higher-order thinking such as analysis or creation (CITE Journal, 2025). However, student-facing AI tools show dramatically different results: a 2025 meta-analysis following PRISMA guidelines found that AI chatbots and generative tutoring systems produced the largest positive effect on learning outcomes (Hedges' g=1.02, 95% CI 0.45-1.59, p<0.0001) compared to other educational technologies (meta-analysis published in ERIC database, 2025).

This quality chasm demonstrates that AI is more effective in responsive/scaffolding roles than in proactive content-generation roles—BUT this gap exists because current AI use lacks intentional multi-handle design. When educators specify only rational outcomes ("generate a quiz on contract law"), AI delivers single-handle materials. Multiply-loaded pedagogy addresses this by bringing design intentionality to AI specification: explicitly requesting emotional engagement, social context, metacognitive scaffolding, and sensory elements alongside rational content.


**Sources:** Meta-analyses for handle evidence (Tyng et al. 2017; Macedonia & Kriegstein 2022; Double et al. 2020; Noetel et al. 2022; Black & Wiliam 1998). Sweller (1988, 2011) and Paivio (1986) for cognitive architecture. Begolli et al. (2020) for simultaneous>sequential finding. Boysen (2021, 2024) and Hills et al. (2022) for devastating UDL critique. Kalyuga et al. (1999) for redundancy warning (quality>quantity). AI quality chasm: Lesson plan study from CITE Journal 2025 (https://citejournal.org/volume-25/issue-3-25/social-studies/civic-education-in-the-age-of-ai-should-we-trust-ai-generated-lesson-plans/); chatbot/tutoring meta-analysis from ERIC database 2025 (https://files.eric.ed.gov/fulltext/EJ1465704.pdf).

---

**2.A Individual Handle Evidence** (~800 words)

**Purpose:** Briefly establish each handle's independent effectiveness with specific effect sizes, showing multiply-loaded pedagogy builds on validated foundations.

**Arguments:** Emotional: arousal enhances consolidation (d=0.4-0.8), humor improves comprehension (η²=0.27), but benefits emerge at delayed retrieval (Kaplan & Pascoe: 6-week follow-up; Cahill & McGaugh: effects strengthen over time). Bizarreness requires mixed-list design (McDaniel & Einstein, 1986). Social: belonging interventions cut achievement gaps 50% (Walton & Cohen, 2007); peer relationships most predictive of performance (Frontiers, 2023). Sensory: dual coding d=0.28-0.53 (Noetel et al., 2022); embodied learning d=1.23 (Macedonia & Kriegstein, 2022). Metacognitive: self-regulated learning +8 months (EEF); peer assessment d=0.31 overall, d=0.61 student-initiated (Double et al., 2020). Rational: formative assessment d=0.40-0.70 (Black & Wiliam, 1998); transparent pedagogy reduces gaps (Winkelmes et al., 2016).


**FYI - use if needed:** Strengthen metacognitive handle with AI-specific evidence: A peer-reviewed study in Scientific Reports analyzed 834 reflective journal entries and found that students actively use AI as a "metacognitive scaffold," externalizing planning strategies (creating checklists), monitoring (comparing AI feedback with their own work), and evaluating understanding (explaining errors to the AI) (Scientific Reports, 2024, https://pmc.ncbi.nlm.nih.gov/articles/PMC12508024/). Another study examining an AI-enhanced practice exam system found that requiring students to explain their reasoning and rate their confidence before receiving AI feedback significantly promoted self-regulated learning—increasing textbook engagement, confidence, and recall. Notably, this structured reflection requirement appeared more impactful than sophisticated AI feedback alone (arXiv preprint, 2025, https://arxiv.org/html/2505.13381v1).

For the emotional handle: A 2025 peer-reviewed study in the European Journal of Education surveyed 816 Chinese EFL students and found that an AI-enhanced Social-Emotional Learning (SEL) framework significantly boosted student engagement and emotional well-being, improving emotional regulation and academic focus (European Journal of Education, 2025, https://www.researchgate.net/publication/387956529). Qualitative reports note that students describe AI tutors as a "safety net" that reduces anxiety about writing or asking questions due to AI's non-judgmental nature (Scientific Reports, 2024). These findings demonstrate that AI can intentionally engage metacognitive and emotional handles, not merely rational content delivery.


**Sources:** Cite specific meta-analyses and effect sizes to ground each handle empirically; emphasize these are established findings, not speculative. AI-specific evidence: Scientific Reports 2024 study on metacognitive scaffolding (https://pmc.ncbi.nlm.nih.gov/articles/PMC12508024/); arXiv 2025 preprint on metacognitive requirements in AI-enhanced practice exams (https://arxiv.org/html/2505.13381v1); European Journal of Education 2025 study on AI-enhanced SEL framework (https://www.researchgate.net/publication/387956529).

---

**2.B The Integration Thesis** (~700 words)

**Purpose:** Explain why integration within single materials beats multiplication across separate materials, grounded in cognitive architecture.

**Arguments:** Paivio's fundamental claim: humans specialized for "simultaneously" processing verbal and nonverbal information through separate working memory systems (phonological loop vs. visuospatial sketchpad). Emotional processing (amygdala-hippocampus) doesn't compete with working memory. Systems can operate in parallel when stimuli activate multiple pathways. BUT Sweller's split-attention effect: separate materials force mental integration (extraneous load). Begolli et al. (2020): simultaneous presentation superior to sequential when scaffolded with self-explanation. Critical warning from Kalyuga et al. (1999): three poorly integrated modalities worse than two well-integrated—redundancy creates problems. Integration quality matters more than handle quantity.

**Sources:** Paivio (1986, 2013) for dual coding; Baddeley for working memory model; Sweller (1988, 2011) for CLT; Begolli et al. (2020) for simultaneous advantage; Kalyuga et al. (1999) for redundancy; Tyng et al. (2017) for emotional pathway distinctness.

---

**2.C UDL's Failure and the Efficiency Gap** (~500 words)

**Purpose:** Position multiply-loaded pedagogy against UDL as dominant framework that tried multi-pathway engagement but failed efficiency test through resource multiplication.

**Arguments:** UDL (Meyer et al., 2014/2025) proposes engagement, representation, action/expression principles requiring multiple formats, assessments, rubrics. Meta-analyses show positive effects (Almeqdad et al., 2023) BUT Boysen (2021, 2024) identifies parallels to discredited learning styles and finds "little evidence" for claims—cited studies show single effective techniques, not multiple means. Implementation barriers devastating: 62% faculty cite time/workload (Hills et al., 2022), 4-7 years for 50% adoption (Novak, 2019), "change takes thought and effort." UDL = resource multiplication; multiply-loaded pedagogy = intentional integration. The efficiency gap UDL couldn't solve creates space for alternative approach.

**Sources:** Meyer et al. (2014, 2025); Boysen (2021, 2024) for critique; Hills et al. (2022) faculty survey; Novak (2019) timeline; Almeqdad et al. (2023) for context. Quote faculty barriers directly.

---

### **3. AI's Flexibility as Design Enabler** (~1,500 words)

**Purpose:** Argue AI's contribution isn't automation (everyone knows AI generates content) but enabling intentional specification of material properties—shifting from hoping to find multiply-loaded materials to systematically designing them through flexible prompting.

**Arguments:** Traditional material creation: hunt for perfect case (hours searching, might not exist) or manually draft hypotheticals (1-2 hours per scenario). Result: instructors optimize for single dimension (doctrinal precision OR emotional resonance, not both). AI changes economics from search to specification: "generate GDPR scenario that is doctrinally precise (Art. 6 lawful basis) AND emotionally engaging (sympathetic data subject) AND socially relevant (consumer context) AND includes metacognitive prompt." AI's flexibility—not specific "mechanisms" but general responsiveness—enables intentional multi-handle design. The shift is cognitive: from "I hope this case happens to engage multiple handles" to "I will specify handles I want engaged." Not automation but design agency.


**Sources:** Hills et al. (2022) on time constraints faculty face; Nature (2025) on AI adoption; position against typical AI-in-education literature focused on efficiency (grading, summarization). MIT Media Lab EEG preprint (2025, preliminary findings not yet peer-reviewed, https://www.media.mit.edu/projects/your-brain-on-chatgpt/overview/) and Stanford SCALE Initiative study (2025, https://scale.stanford.edu/ai/repository/short-term-gains-long-term-gaps-impact-genai-and-search-technologies-retention) on concerning AI effects when used for automation rather than intentional design.

---

**3.A Legal Materials as Optimal Substrate** (~500 words)

**Purpose:** Show legal materials' inherent multi-dimensionality makes them ideal for multiply-loaded design—unlike math proofs or physics problems, cases contain doctrine + human stakes + social context naturally.

**Arguments:** Legal cases involve real people (emotional stakes), policy implications (social relevance), doctrinal precision (rational analysis), often visual artifacts (sensory anchors), strategic reasoning (metacognitive). Carnegie Report recognized this potential but couldn't solve implementation—"connecting remains outside." Other disciplines lack this substrate: math problems are primarily rational, physics labs primarily sensory/rational. Legal education's challenge was always material scarcity (finding/creating perfect integration), not impossibility. AI + legal materials' natural affordance = unique opportunity for multiply-loaded pedagogy.

**Sources:** Carnegie Report (Sullivan et al., 2007); Swain & Campbell (2019) and Lipshaw on contract pedagogy limitations; Boyle-Laisure on neuroscience approaches; Pollman (2014) on cognitive load in legal writing; Finnish study on fragmented first-year knowledge.

---

**3.B From Scarcity to Specification** (~500 words)

**Purpose:** Articulate the fundamental shift AI enables—not faster searching but design specification, making intentional multi-handle integration practical.

**Arguments:** Pre-AI: binary choice between doctrinal purity (boring but rigorous) OR emotional resonance (engaging but imprecise). Finding case with both = lightning strike. Manual drafting = intensive labor. Result: rational-privileging despite knowing better (learning science says multiple handles matter, but impractical to implement). AI: specify desired properties, generate variations, iterate until right. Example: "Generate contract formation scenario that tests consideration doctrine (rational), involves sympathetic small business (emotional), uses real-world consumer context (social), and includes self-reflection prompt (metacognitive)." Thirty minutes prompting yields reusable template adaptable across semesters. Economics shift from search (hours, uncertain success) to specification (upfront design, infinite variation).


**FYI - use if needed:** Support "specification enables integration" with "personalisation without isolation" model: AI handles individualized adaptive practice (each student at own pace with tailored support), freeing classroom time for higher-order social learning (discussions, debates, collaborative projects). Instructor shifts from content delivery to orchestrating human-centric activities where students defend/synthesize knowledge developed with AI. This blended model directly addresses efficiency concerns while maintaining social learning—BUT note it currently lacks empirical validation, as identified in Section 6's research gaps (Times of India, 2024, describes the model but provides no peer-reviewed studies implementing it, https://timesofindia.indiatimes.com/education/news/ai-in-classrooms-friend-or-foe-benefits-boundaries-and-why-learning-is-still-a-human-act/articleshow/124956167.cms). The model demonstrates how AI specification enables both rational (individualized practice) AND social (collaborative in-class) handles through intentional design of different learning spaces, not separate interventions.

**Sources:** Reference time constraints from Hills et al. (2022); cognitive load theory on working memory limitations making manual creation difficult (Pollman, 2014); position as solving practical constraint not just theoretical insight.


---

**Note:** "Personalisation without isolation" model cited from Times of India 2024 (https://timesofindia.indiatimes.com/education/news/ai-in-classrooms-friend-or-foe-benefits-boundaries-and-why-learning-is-still-a-human-act/articleshow/124956167.cms); lacks empirical validation as noted in Section 6 research gaps.

### **4. Varied Examples of Multiply-Loaded Design in Practice** (~3,000 words)

**Purpose:** Demonstrate multiply-loaded pedagogy through diverse examples showing different approaches to multi-handle integration. Critical framing: these are SAMPLE applications demonstrating flexible use of design principle, NOT exhaustive taxonomy or required mechanisms.

**Arguments:** Present 4-5 detailed examples showing varied ways AI's flexibility enables multi-handle design. Each example walks through: (1) what material is, (2) which handles it engages and how, (3) student experience, (4) why integration works. Emphasize diversity—examples use different combinations of handles, different instructional contexts, different prompt strategies. Point is not "follow these four methods" but "here are different ways intentional design works—develop your own aligned with teaching style." Examples prove the principle (integration beats multiplication) through varied instantiation.

**Sources:** Return to learning science from Section 2 showing which handles each example engages; use cognitive architecture to explain why simultaneous engagement works; cite specific research on each pedagogical element (e.g., emotional memory for empathy example, error detection literature for planted error example).

---

**4.A Example: Empathy Calibration Through Comparative Scenarios** (~600 words)

**Purpose:** Show how single 8-minute exercise can engage five handles simultaneously through controlled comparison design.

**Arguments:** Prompt: "Generate three GDPR data processing scenarios—hospital treating patients, bank preventing fraud, employer managing payroll—each using different Art. 6 lawful basis (not consent). Make factual details comparable." Students rank comfort level with each processing, discuss whether legal analysis should shift when sympathy does. Walk through handles: **Emotional (empathy/surprise):** comfort shifts though doctrine identical—violation of expectation (Cahill & McGaugh, d=0.4-0.8 emotional memory). **Rational (comparison/distinguishing):** must analyze whether standard changes—core legal skill (Carnegie Report). **Metacognitive (bias awareness):** recognizing intuition ≠ legal standard sharpens professional judgment (Zimmerman, 1989; Double et al., d=0.61 self-initiated). **Social (consumer protection):** recognizable contexts make abstract doctrine concrete (Wenger, 1998; Gopalan & Brady, 2019). **Sensory (if visual):** AI-generated images of each party create memory anchors (von Restorff effect, Hunt 1995). Integration: emotional response BECOMES analytical object, not distraction from it. One exercise, multiple pathways, models expert legal cognition (empathy AS analytical question).

**Sources:** GDPR Art. 6 for accuracy; Tyng et al. (2017), Cahill & McGaugh (1998) for emotional memory; comparison as core legal skill from Carnegie; Zimmerman (1989) for metacognition; Gopalan & Brady (2019), Wenger (1998) for social; Hunt (1995) for distinctiveness; emphasize temporal effects (Kaplan & Pascoe, 1977: benefits at 6-week follow-up).

---

**4.B Example: Error Detection Materials** (~500 words)

**Purpose:** Show brevity doesn't preclude multi-loading—3-minute exercise hits four handles when error itself multi-dimensional.

**Arguments:** Prompt: "Generate 3-sentence GDPR summary with one subtle doctrinal error students commonly make." Output: "Data controllers must always obtain explicit consent..." Students identify error (ignores five other Art. 6 bases). Handles: **Rational (critique/evaluation):** spot doctrinal mistake requires understanding all lawful bases (Black & Wiliam, 1998, d=0.40-0.70 formative assessment). **Emotional (surprise):** "I almost wrote this last week!"—violation of expectation anchors correction (Cahill & McGaugh, 1998). **Metacognitive (error detection + remembered frustration):**recognizing past confusion makes mastery tangible (Double et al., 2020, d=0.61; Education Endowment Foundation +8 months). **Social (if collective):** group problem-solving BUT warning from Toda et al. (2018): competitive leaderboards undermine motivation; Deci et al. (1999) d=-0.28 to -0.40 for performance-contingent rewards. Integration: error isn't just rational puzzle—emotional jolt IS correction mechanism. Different approach than Example 1 but same principle: intentional multi-handle design through flexible prompting.

**Sources:** Black & Wiliam (1998) formative assessment; Cahill & McGaugh (1998) emotional memory; Double et al. (2020), Education Endowment Foundation for metacognition; Toda et al. (2018), Deci et al. (1999) for gamification warnings—use to caution against competitive structures.

---

**4.C Example: Counterfactual Scenarios for Transfer Testing** (~500 words)

**Purpose:** Demonstrate humor and absurdity aren't pedagogically empty—they test deep vs. surface understanding while maintaining engagement.

**Arguments:** Prompt: "Generate GDPR compliance memo for 1920s telegraph company collecting customer addresses—anachronistic but doctrinally analyzable." Students identify what's absurd (medium) vs. which principles still apply (purpose limitation, security, transparency regardless of server vs. telegram). Handles: **Emotional (humor):** anachronism creates laughter—lowers anxiety (Hackathorn et al., 2011, η²=0.27), increases memorability (McDaniel & Einstein, 1986). **Rational (pattern recognition/transfer):** must abstract principle from context—tests whether grasp WHY rules exist not just WHAT they say. **Metacognitive (depth-testing):** absurdity exposes surface vs. deep understanding—can't succeed through recognition alone (Zimmerman, 1989). **Sensory (if visual):** AI generates absurd diagram of telegram data flow adds multimodal layer. **CRITICAL CAVEATS:** McDaniel & Einstein (1986) bizarreness only works in **mixed-list design**—must intersperse with serious doctrine. Kaplan & Pascoe (1977): humor benefits emerge at **6-week follow-up**, not immediately. Integration: absurdity IS the transfer test, not decoration.

**Sources:** McDaniel & Einstein (1986) for bizarreness constraints—cite mixed-list requirement prominently; Hackathorn et al. (2011) for humor comprehension; Kaplan & Pascoe (1977) for temporal delay; pattern recognition from dual coding literature; Zimmerman (1989) for metacognition; emphasize caveats to show scholarly rigor.

---

**4.D Example: Interactive Role-Play for Professional Identity** (~500 words)

**Purpose:** Show adaptive interaction enables private practice at scale—students discover knowledge boundaries through dynamic exchange.

**Arguments:** Prompt: "You are a confused GDPR data subject who received a privacy notice. Ask student to explain your rights, respond with follow-up questions probing understanding." Student explains lawful basis; AI asks "Wait, so hospital doesn't need consent?" If answer clear, AI escalates: "What if hospital also does pharmaceutical research?" Handles: **Rational (precise application):** must explain doctrine accurately under questioning (Black & Wiliam, 1998). **Social (professional role-play + psychological safety):** practice client communication without performance anxiety (Edmondson, 1999; Tan et al., 2022 on need for safety). **Emotional (empathy/curiosity):** understanding client confusion builds professional empathy; desire to satisfy "client" sustains engagement (Loewenstein, 1994 on curiosity). **Metacognitive (self-awareness of boundaries):** AI probes until explanation breaks down—student discovers gaps privately (Education Endowment Foundation +8 months; Double et al., d=0.61). Integration: professional role creates authentic context demanding multiple competencies simultaneously. Different structure than Examples 1-3—demonstrates design principle's flexibility.


**FYI - use if needed:** CRITICAL caveat on AI interaction—"crisis of credibility": While intelligent tutoring systems show large positive effects (Hedges' g=1.02 in meta-analysis, ERIC 2025), students exhibit strong bias against AI feedback when the source is disclosed. An arXiv preprint study (not yet peer-reviewed) found that students preferred AI-generated feedback quality in blind comparison, but when the source was revealed, only AI-labeled feedback (not human or co-produced feedback) suffered a decline in perceived "genuineness" (arXiv preprint 2025, https://arxiv.org/pdf/2504.10961). This source bias threatens the proven efficacy of AI tutoring and role-play interactions. Implementation implication: Consider human-AI co-production of feedback presentation; focus on building student AI literacy to mitigate source bias. The technical effectiveness is demonstrated; the psychological acceptance requires intentional design.

**Evidence note:** The credibility study is a preprint awaiting peer review; findings are preliminary but suggest important design considerations.

**Sources:** Black & Wiliam (1998) for formative feedback through dialogue; Edmondson (1999) psychological safety—critical for legal education where Socratic method creates anxiety; Tan et al. (2022) on authentic assessment needing safety; Loewenstein (1994) on curiosity; Education Endowment Foundation, Double et al. (2020) for metacognition; Wenger (1998) for legitimate peripheral participation.

---


**4.E Example: Student-Created Assessment Materials** (~400 words)

**Sources:** AI tutoring meta-analysis (ERIC 2025, https://files.eric.ed.gov/fulltext/EJ1465704.pdf); credibility crisis study (arXiv preprint 2025, https://arxiv.org/pdf/2504.10961, not yet peer-reviewed).

**Purpose:** Show how production (not just consumption) enables multi-handle engagement—creating materials develops understanding differently than answering questions.

**Arguments:** Prompt: "Create exam question testing GDPR Art. 6 lawful basis, include model answer, then generate AI answer with 2 errors for peer grading." Students design question (rational + metacognitive: what constitutes important knowledge?), write answer (rational application), grade AI's flawed response (rational critique + metacognitive error detection). Handles: **Rational (multiple levels):** question creation, answer writing, evaluation—Bloom's synthesis/evaluation (highest levels). **Metacognitive (assessment literacy):** Van Deursen (2016) students who create questions "consistently belong to best" performers; understanding assessment criteria develops judgment. **Social (peer learning):** students grade each other's questions (Double et al., 2020, d=0.31 peer assessment, d=0.45 computer-mediated). **Emotional (ownership/agency):** creating materials generates investment (Ryan & Deci, 2000, autonomy). Integration: production requires understanding at deeper level than consumption—can't create good question without grasping what matters. Different again from Examples 1-4—shows principle's range.

**Sources:** Van Deursen (2016) for question creation; Double et al. (2020) peer assessment meta-analysis; Ryan & Deci (2000, 2020) self-determination theory for autonomy/ownership; Bloom's taxonomy for cognitive levels; emphasize this is ANOTHER different approach, not a required mechanism.

---


**FYI - use if needed:** Important caveat on AI-generated assessments: While AI can generate quizzes and rubrics, the body of empirical validation research remains limited and domain-specific. A 2025 BMC Medical Education study found that 69% of AI-generated medical exam questions were deemed fit for use after expert screening, and field testing showed comparable performance to human-authored items (BMC Medical Education 2025, https://bmcmededuc.biomedcentral.com/articles/10.1186/s12909-025-06881-w). However, this evidence is confined to specific disciplines (medicine) and relies on expert quality control; broader questions of fairness, reliability across diverse populations, and pedagogical alignment remain under-researched (see Section 6, Gap 2).

When implementing Example 4.E (student-created questions), acknowledge this limitation: use AI-generated materials as a starting point requiring human validation and expert review, not as final products. The assessment creation process itself develops student understanding (Van Deursen 2016), but quality assurance requires pedagogical judgment that emerging research shows AI cannot yet independently provide without human oversight.

**4.F Synthesis: Diverse Paths to Same Principle** (~500 words)

**Purpose:** Emphasize examples demonstrate flexible application of design principle, not exhaustive taxonomy or required methods.


**Arguments:** Five examples show varied approaches: comparative scenarios, error detection, counterfactuals, interactive role-play, student production. Different handle combinations (Example 1: all five; Example 2: four; Example 5: different four). Different instructional contexts (8-minute exercise, 3-minute cold-call, homework assignment). Different prompt strategies. Point isn't "these are THE five mechanisms"—it's "multiply-loaded pedagogy is flexible design principle adaptable to teaching style, content, student level." Teachers should develop own approaches aligned with authentic persona, not follow rigid method. What unifies examples: intentional multi-handle design through AI's flexibility. Integration beats multiplication whether achieved through empathy calibration, error detection, or student production. The principle (multiply-loaded pedagogy) is constant; implementations vary infinitely. Assessment quality research gap discussed in Section 6 (Gap 2); emerging BMC Medical Education 2025 study shows promise but validation remains limited.

**Sources:** Return to Begolli et al. (2020) simultaneous>sequential; Paivio (1986) on simultaneous processing; Kalyuga et al. (1999) on quality>quantity; emphasize flexibility enables adoption across diverse teaching styles (addressing Hills et al., 2022 barriers).

---

### **5. Developing Design Awareness: A Thinking Framework** (~1,500 words)

**Purpose:** Provide practical guidance for developing design awareness when using AI—not prescriptive checklist but reflective framework encouraging intentionality about handles.

**Arguments:** When prompting AI for teaching materials, shift from "generate case study on contract formation" to "generate case study engaging rational (doctrine), emotional (sympathetic parties), social (consumer context), metacognitive (reflection prompt)." Not mandatory to engage all five handles every time—intentionality about WHICH handles and WHY matters. Framework: (1) Identify learning objective (what should students understand?), (2) Consider which handles serve that objective (not all applicable always), (3) Specify desired properties in prompt, (4) Iterate based on output quality, (5) Assess for integration quality not handle quantity. Include practical prompting guidance, warnings about overload (Kalyuga et al.: redundancy harmful), caveats about gamification (Toda et al.: leaderboards backfire), expertise reversal (scaffolding helps novices, annoys experts), temporal expectations (benefits emerge over weeks). Teaching style flexibility: serious professor can use outrage, playful professor can use humor—same principle, different affect.


**FYI - use if needed:** Strengthen urgency of faculty development in prompt engineering/design awareness: The Digital Education Council's 2025 Global AI Faculty Survey found that only 17% of faculty rate their AI literacy as advanced or expert, despite 61% having used AI in teaching (with 88% of those reporting minimal use) (DEC 2025, cited in Campbell University meta-summary). This creates an acute need for practical guidance in intentional AI use. Students report similar gaps: 58% feel they lack sufficient AI knowledge and skills (DEC 2024). Yet 59% of higher-education leaders believe recent graduates are not prepared for workplaces where AI tools are important (AAC&U/Elon University, cited in Campbell summary). The faculty development challenge isn't merely adopting AI (which is already happening) but developing design literacy—shifting from automated replication of single-handle approaches to intentional multiply-loaded specification. This section addresses that development need directly.

**Sources:** Practical prompting draws on AI system capabilities (user's law & tech expertise); learning science warnings from Kalyuga et al. (1999), Toda et al. (2018), Deci et al. (1999), expertise reversal literature; temporal effects from Kaplan & Pascoe (1977), Cahill & McGaugh (1998); flexibility addresses Hills et al. (2022) adoption barriers.

---


**5.A Practical Prompting Strategies** (~500 words)

**Note:** AI literacy gap data from DEC 2025 faculty survey (17% advanced/expert, 40% just beginning) and DEC 2024 student survey (58% feel they lack AI skills) inform this section's practical approach.

**Purpose:** Translate design awareness into concrete prompting practices—what to specify, how to iterate, when to stop.

**Arguments:** Start broad, refine iteratively. Initial prompt: specify doctrine + one additional handle (e.g., "GDPR Art. 6 scenario with sympathetic data subject"). Evaluate output: does it authentically engage intended handles? If not, refine: "make data subject elderly patient" (emotional specificity), "set in healthcare context" (social relevance), "include question asking students to predict their initial reaction" (metacognitive). Don't over-specify initially—AI needs creative space. Iteration typical: 2-4 rounds to get multiply-loaded material working. Save successful prompts as templates, adapt across doctrines. Share prompts among faculty (collaborative development reduces individual burden). Example prompt structure: "[Doctrine] + [Emotional angle] + [Social context] + [Instructional format] + [Assessment method]." Critical: specify PROPERTIES not exact content—"sympathetic litigant" better than "64-year-old woman with cancer" (too specific limits AI flexibility).

**Sources:** Draw on user's technical expertise with AI systems; reference prompt engineering best practices; position as design skill requiring practice, not magical automation.

---

**5.B Recognizing Quality Integration vs. Overload** (~500 words)

**Purpose:** Help educators distinguish well-integrated multiply-loaded materials from cognitively overloaded ones—quality over quantity.

**Arguments:** Good integration: handles emerge naturally from material, feel unified (emotional response IS analytical object, not distraction). Poor integration: handles feel tacked on, compete for attention (case study + separate reflection + separate diagram + separate role-play = fragmentation). Warning signs of overload: students confused about what matters, switching between tasks feels jarring, materials feel redundant (Kalyuga et al., 1999: text + audio + graphic worse than audio + graphic). Optimal typically 2-3 well-integrated handles, not always all five. Test: Does adding this handle CLARIFY the learning objective or COMPLICATE it? If emotional element doesn't serve doctrinal understanding, cut it. If metacognitive prompt feels forced, skip it. Begolli et al. (2020): integration requires scaffolding—self-explanation prompts help students process multiple representations. Without scaffolding, simultaneity creates confusion.

**Sources:** Kalyuga et al. (1999) redundancy; Mou et al. (2023) video + text increased load; Begolli et al. (2020) on scaffolding requirement; Sweller (1988, 2011) CLT for cognitive load principles; emphasize quality > quantity throughout.

---

**5.C Adapting to Teaching Style and Context** (~500 words)

**Purpose:** Show multiply-loaded pedagogy preserves teaching authenticity—changes material selection, not pedagogical persona—addressing faculty resistance.

**Arguments:** Faculty resist "active learning" not from pedagogical skepticism but self-preservation—"I'm not going to sing and dance" (Hills et al., 2022). Multiply-loaded pedagogy solves this: intentional material design, not performance transformation. Serious doctrinal professor can use empathy calibration exercise without emotional performance—material itself engages affect through comparison. Professor preferring gravitas uses outrage (unjust outcomes) rather than humor. Minimal technology comfort? Text-based scenarios, no multimedia required. Each handle offers multiple angles: emotional (humor/empathy/surprise/outrage/curiosity/remembered frustration), social (consumer experience/professional role-play/cultural references/peer collaboration), sensory (visual static/dynamic, auditory, text craft). Select angles matching authentic teaching style. Same design principle (integration > multiplication), infinite stylistic implementations. The flexibility enables adoption across diverse faculty, addressing UDL's failure to scale.

**Sources:** Hills et al. (2022) on faculty resistance to change; reference handle angles table from literature review showing diversity within each handle; position as solving adoption barrier that killed UDL; emphasize authenticity preservation.

---

### **6. Limitations, Warnings, and Future Directions** (~1,200 words)

**Purpose:** Acknowledge boundaries, prevent over-claiming, show scholarly rigor through honest engagement with constraints and risks.

**Arguments:** Five research-grounded limitations: (1) **Cognitive overload real risk**—Kalyuga et al., MIT EEG study, Tsinghua retention findings show poorly integrated > well integrated can backfire; (2) **Gamification dangers**—Toda et al. 87 papers negative effects, Deci et al. extrinsic rewards undermine intrinsic motivation; (3) **Expertise reversal**—scaffolding helps novices, annoys experts, must adapt by level; (4) **Temporal expectations**—benefits emerge over weeks (Kaplan & Pascoe, Cahill & McGaugh), don't judge by immediate quiz; (5) **Context requirements**—bizarreness needs mixed lists (McDaniel & Einstein), can't use ONLY absurd examples. Additional warnings: AI generates errors requiring fact-checking; access inequities; student AI literacy assumptions; not suitable for all content (some doctrine requires focused rational analysis). This article proposes design principle and demonstrates feasibility—empirical validation needed: comparative studies (multiply-loaded vs. traditional vs. UDL), cognitive load measurement, longitudinal retention, transfer assessment, equity effects.


**Sources:** Cite all five research findings directly with specific studies; MIT Media Lab EEG preprint (2025, preliminary, not yet peer-reviewed), Stanford SCALE study (2025), systematic review (ERIC 2024), Nature (2025) for AI concerns; acknowledge this is theoretical argument + proof-of-concept, not empirical validation; identify research questions requiring study. Note varying evidence quality across sources.

---

**6.A When NOT to Use Multiply-Loaded Design** (~400 words)

**Purpose:** Provide guidance on contexts where single-handle focus appropriate—prevents dogmatic application.

**Arguments:** Not every learning objective benefits from multi-handle engagement. When students learning foundational vocabulary/concepts, focused rational engagement may be optimal (reduce load during initial acquisition). When students already expert, adding scaffolding creates expertise reversal (Sweller). When doctrine extremely complex (high intrinsic load), adding handles may overload working memory—teach doctrine first, add integration later. When time extremely limited (2-minute explanation), single handle more efficient than rushing integration. When assessment high-stakes (bar exam prep), focused practice on tested format appropriate. Multiply-loaded pedagogy most effective for: (1) foundational legal reasoning skills (where transfer matters), (2) first-year students (building schemas), (3) professional identity formation (integration models practice), (4) complex doctrine requiring connection to context (abstraction problem). Know when to integrate, when to focus.


**FYI - use if needed:** CRITICAL nuance on AI's impact on rational thinking and critical thinking—effects are mode-dependent, not technology-inherent: An MDPI peer-reviewed study (Xu et al., 2025) found that frequency of AI use was unrelated to critical thinking skills; however, using AI specifically for reflective thinking was positively correlated with critical thinking development (MDPI 2025, https://www.mdpi.com/2227-7102/15/8/977). A Duke University resource summarizes research (primary source not named) suggesting students using LLMs for research tasks showed poorer reasoning and narrower ideas versus traditional search users; note this is from an academic blog, not peer-reviewed (Duke Learning Innovation 2024, https://lile.duke.edu/ai-ethics-learning-toolkit/does-ai-harm-critical-thinking/). A systematic review of 19 peer-reviewed studies found that ChatGPT can enhance critical thinking when properly designed, but over-reliance diminishes motivation for self-reflection (ERIC 2024, https://files.eric.ed.gov/fulltext/EJ1459623.pdf).

This evidence reinforces the multiply-loaded pedagogy argument: intentional design for metacognitive engagement (Example 4.A empathy calibration, 4.B error detection, 4.D role-play probing boundaries) counteracts shallow use. When NOT to multiply-load: if the goal is simple information retrieval or when students lack foundational knowledge to engage reflectively—focused rational instruction first, then integration.

**Evidence note:** The Duke summary lacks primary source citation; the pattern across peer-reviewed studies (Xu et al., systematic review) supports mode-dependent effects.

**Sources:** Sweller (1988, 2011) on intrinsic load, expertise reversal; Pollman (2014) on cognitive load in legal writing; acknowledge complexity requires pedagogical judgment, not formulaic application.

---


**6.B AI System Limitations and Risks** (~400 words)

**Sources:** Mode-dependent critical thinking effects: MDPI 2025 (Xu et al., https://www.mdpi.com/2227-7102/15/8/977), systematic review ERIC 2024 (https://files.eric.ed.gov/fulltext/EJ1459623.pdf), Duke blog 2024 (not peer-reviewed, https://lile.duke.edu/ai-ethics-learning-toolkit/does-ai-harm-critical-thinking/).

**Purpose:** Address technical limitations and ethical concerns—user's law & tech expertise enables sophisticated treatment.


**Arguments:** AI generates plausible but sometimes inaccurate content—requires faculty fact-checking (especially case citations, statutory references). Systems may reflect training data biases (representation, stereotyping)—requires critical review. Access inequities if institutions lack resources. Student over-reliance risks shallow learning (MIT Media Lab EEG preprint 2025 found weakest neural connectivity in ChatGPT users; Stanford SCALE study 2025 found lower retention 2-3 weeks later; note both studies are preliminary). Privacy concerns with student data in prompts. Prompt engineering skill development requires time investment (not zero-cost). AI cannot replace pedagogical judgment about learning objectives, assessment criteria, student needs. Technology changes rapidly—specific tools may become obsolete, but design principle remains. Multiply-loaded pedagogy shouldn't increase surveillance or reduce human teaching—it's design support, not replacement.


**Sources:** Nature (2025) for AI adoption context; MIT Media Lab EEG preprint (2025, preliminary), Stanford SCALE study (2025) on concerning AI effects; user's GDPR expertise for privacy concerns; acknowledge technology limitations honestly while defending principle. Note evidence quality caveats for cognitive effects studies.

---


**FYI - use if needed:** Expand concerning cognitive effects with specifics, noting evidence caveats: A quasi-experimental study published via Stanford's SCALE Initiative found that students using ChatGPT or Google search initially outperformed control groups on lower-order tasks, but their advantage disappeared over time; retention scores converged, with control participants showing the highest retention at 2-3 weeks (Stanford SCALE, 2025, https://scale.stanford.edu/ai/repository/short-term-gains-long-term-gaps-impact-genai-and-search-technologies-retention). An MIT Media Lab preprint study using EEG found that participants using ChatGPT assistance exhibited the weakest neural coupling compared with search-engine and unaided groups, produced more homogeneous essays, and struggled to recall text they had just written; however, the authors caution that these findings are preliminary and not yet peer-reviewed (MIT Media Lab, 2025, arXiv preprint, https://www.media.mit.edu/projects/your-brain-on-chatgpt/overview/).

A Duke University AI ethics resource (not peer-reviewed) summarizes research suggesting that students using large language models focused on a narrower set of ideas and produced more biased, superficial analyses compared with traditional search users (Duke Learning Innovation, 2024, https://lile.duke.edu/ai-ethics-learning-toolkit/does-ai-harm-critical-thinking/); the primary study is not cited by name. A systematic review of 19 studies found that while ChatGPT can enhance critical thinking, over-reliance may reduce motivation for self-reflection and critical evaluation of AI-generated content (peer-reviewed, ERIC database, 2024, https://files.eric.ed.gov/fulltext/EJ1459623.pdf).

Mechanism: AI may reduce germane cognitive load (schema construction) while appearing helpful—creating an illusion of understanding. HEPI (2025) reports that 86% of UK students regularly use AI, but usage without intentional pedagogical design risks shallow engagement. This evidence strengthens the multiply-loaded pedagogy argument: when AI use is designed for metacognitive engagement (self-explanation, error detection, boundary testing), it can maintain germane load while providing scaffolding. The risk isn't AI itself but unreflective automation. Multiply-loaded design explicitly counters this by requiring active cognitive engagement across multiple dimensions simultaneously.

**Evidence quality note**: The MIT findings are preliminary (preprint); the Duke summary lacks primary source citation; the Stanford study is from a repository and may still be under review. However, the pattern across multiple sources suggests caution is warranted when AI is used for cognitive offloading rather than intentional engagement.

**6.C Research Agenda for Empirical Validation** (~400 words)

**Purpose:** Position article as opening research program, not concluding it—identify questions requiring empirical study.


**Arguments:** This article provides theoretical framework and proof-of-concept; rigorous validation needed. Key questions: (1) **Comparative effectiveness**—do multiply-loaded materials outperform traditional or UDL approaches? Measure retention (immediate, 6-week, 6-month), transfer to novel problems, cognitive load during learning. (2) **Optimal loading levels**—how many handles for different expertise levels, content complexity, student backgrounds? (3) **Equity effects**—do multiply-loaded materials reduce achievement gaps as UDL claims but doesn't deliver? Disaggregate by first-generation status, socioeconomic background. (4) **Long-term professional development**—does multiply-loaded pedagogy in law school predict better lawyering (client empathy, ethical reasoning, contextual analysis)? (5) **Implementation fidelity**—can principle scale across institutions without quality degradation? **Methodological needs:** experimental/quasi-experimental designs, cognitive load measurement (subjective + objective), longitudinal follow-ups, qualitative components exploring student experience, international comparative studies (Norwegian context unexplored in legal pedagogy). Adoption statistics from HEPI 2025, DEC 2024; cognitive effects from Stanford SCALE 2025, MIT Media Lab preprint 2025 (with caveats), systematic review (ERIC 2024), Duke summary 2024; emphasize these support intentional design argument while acknowledging evidence quality varies.


**FYI - use if needed:** Integrate five specific research gaps that align with multiply-loaded pedagogy's research directions: 

(1) **Empirical validation of social learning models**: The "personalisation without isolation" approach—where AI handles individual practice so class time can focus on collaborative learning—is pedagogically compelling but lacks empirical evidence. A Times of India article (2024, https://timesofindia.indiatimes.com/education/news/ai-in-classrooms-friend-or-foe-benefits-boundaries-and-why-learning-is-still-a-human-act/articleshow/124956167.cms) describes this model where AI adjusts to individual needs while teachers orchestrate discussion, but no peer-reviewed studies implementing this framework were found. More broadly, we lack evidence on how AI-enabled designs affect collaborative and communicative skills.

(2) **Quality and validity of AI-generated assessments**: This gap is beginning to close but remains substantial. A 2025 BMC Medical Education study generated 220 single-best-answer questions using GPT-4; expert review deemed 69% fit for inclusion, and field testing showed these AI-generated questions performed comparably to human-authored items on facility and discrimination indices (BMC Medical Education, 2025, https://bmcmededuc.biomedcentral.com/articles/10.1186/s12909-025-06881-w). However, this evidence is domain-specific (medical education), relies on expert screening, and does not address broader questions of fairness, reliability across diverse student populations, or pedagogical alignment with learning objectives. The body of validation research remains small and concentrated in specific disciplines. Critical for Section 4.E implementation.

(3) **Longitudinal studies on skill development**: The overwhelming majority of AI-in-education research is cross-sectional or short-term. A quasi-experimental study found that ChatGPT users showed immediate performance advantages on lower-order tasks but these gains disappeared over time; retention scores converged with control groups, and no significant differences emerged for higher-order tasks (Stanford SCALE Initiative, 2025, https://scale.stanford.edu/ai/repository/short-term-gains-long-term-gaps-impact-genai-and-search-technologies-retention). We need longer-term studies examining sustained AI use effects on critical thinking, metacognition, and domain knowledge retention—particularly distinguishing between performance boosts during AI use versus durable learning.

(4) **Sensory dimension of AI-generated content**: A "significant void" exists in literature on AI tools creating multi-sensory learning experiences in higher education. Searches reveal few empirical studies; existing work focuses on K-12 tools or theoretical proposals. This gap directly relates to the sensory handle in multiply-loaded design and represents an underexplored AI affordance.

(5) **Equity and algorithmic bias**: Differential impacts on students with disabilities, varying socioeconomic backgrounds, and non-native speakers remain under-researched. Concerns include whether AI plagiarism detection exhibits bias against non-native writing patterns, whether access disparities compound educational inequities, and how AI tools affect students with different learning needs.

These gaps independently validate multiply-loaded pedagogy's research directions, showing the field recognizes multi-dimensional integration as a critical frontier.

**Sources:** Reference methodology recommendations from literature review; position humbly as theoretical contribution requiring empirical validation; acknowledge this article doesn't prove effectiveness, demonstrates feasibility.

---


### **7. Conclusion: Design Awareness for the AI Era** (~600 words)

**Note on research gaps**: Five research gaps discussed in Section 6 independently validate multiply-loaded pedagogy's research directions, showing the field recognizes multi-dimensional integration as a critical frontier. Citations include: "personalisation without isolation" model (Times of India, 2024); emerging assessment validation evidence (BMC Medical Education, 2025); short-term vs. long-term learning effects (Stanford SCALE, 2025); sensory dimension void in literature; equity and bias concerns.

**Purpose:** Synthesize argument, position contribution clearly, end forward-looking on what becomes possible when educators develop design awareness.

**Arguments:** Legal education's abstraction problem—teaching doctrine while maintaining connection to human complexity—has persisted since Carnegie Report (2007). AI adoption now ubiquitous (86% students) but mostly replicates single-handle approaches. This article's contribution: (1) **Design principle**: multiply-loaded pedagogy (integration > multiplication) grounded in cognitive theory (CLT, dual coding), positioned against UDL's failed multiplication approach. (2) **Enabling conditions**: AI's flexibility makes intentional multi-handle specification practical, shifting from hoping to designing. Legal materials' multi-dimensionality provides optimal substrate. (3) **Design awareness framework**: when using AI, think intentionally about handles—not prescriptive method but reflective practice. (4) **Diverse proof-of-concept**: examples demonstrate principle's flexible application across teaching styles, content, contexts. The shift isn't automation ("AI grades faster") but design agency ("I specify what I want materials to do"). For legal educators: develop literacy in intentional multi-handle design. For AI researchers: recognize pedagogical affordances beyond efficiency. For learning scientists: integration mechanisms deserve study. Carnegie identified the problem—connecting remains outside. Multiply-loaded pedagogy, enabled by AI's flexibility, makes connection intrinsic.


**FYI - use if needed:** Strengthen urgency in conclusion by returning to readiness gap: The 86-92% student adoption rate (HEPI 2025; DEC 2024) isn't merely a statistic—it represents a systemic asymmetry where students, driven by efficiency (51% to "save time") and quality (50% to "improve work quality"), have adopted AI faster than institutions can respond. Only 39% of institutions had AI-related policies as of 2025 (EDUCAUSE, cited in Anara 2025), while 61% of faculty had used AI but 88% only minimally (DEC 2025, cited in Campbell summary). Result: 80% of students report their university's AI integration does not meet expectations (DEC 2024).

This gap makes multiply-loaded pedagogy urgent, not optional. If educators don't develop design literacy, students will continue using AI for efficiency-oriented automation (copying answers, outsourcing thinking) rather than intentional learning. The article offers a path from reactive adoption to intentional design—from "students are using AI anyway" to "we can design AI-enabled learning that genuinely serves pedagogical goals." Multiply-loaded pedagogy addresses the readiness gap not just by providing tools but by developing design awareness that matches student practice with institutional mission.

**Sources:** Return to Carnegie Report (Sullivan et al., 2007) for thematic bookend; Nature (2025) for AI adoption; synthesize key theoretical contributions (Paivio, Sweller, Begolli) and empirical evidence (effect sizes); position humbly as opening conversation, not final word; acknowledge limitations while defending contribution.

---


**7.A Implications for Different Stakeholders** (~300 words)

**Note**: Readiness gap data from HEPI 2025, DEC 2024-2025 surveys, EDUCAUSE data, and AAC&U/Elon survey reinforce urgency of design awareness development across stakeholder groups.

**Purpose:** Clarify what different audiences should take from this article—legal educators, AI researchers, learning scientists, institutional leaders.

**Arguments:** **Legal educators**: When using AI for materials, shift to intentional multi-handle design. Develop awareness of handles (rational, emotional, social, sensory, metacognitive), experiment with integration, iterate based on student response. This isn't prescriptive method—adapt to authentic teaching style. **AI/EdTech researchers**: Current educational AI focuses on automation; this article identifies design affordances for pedagogical engineering. Question: what prompting interfaces support intentional multi-handle specification? How might AI systems scaffold educators' design awareness? **Learning scientists**: Multiply-loaded pedagogy offers alternative to UDL's multiplication approach. Empirical questions: optimal loading levels, equity effects, long-term retention, transfer. **Institutional leaders**: Supporting faculty development in design awareness more scalable than UDL implementation (weeks vs. 4-7 years). Requires: prompt engineering workshops, shared prompt libraries, collaborative development time—not massive infrastructure.

**Sources:** Reference stakeholder-specific concerns from Hills et al. (2022), Boysen (2021, 2024), Nature (2025); position as practical next steps for different audiences.

---

**7.B Closing: From Scarcity to Agency** (~300 words)

**Purpose:** End with hopeful, forward-looking vision of what becomes possible when design awareness replaces material scarcity.

**Arguments:** For decades, legal educators faced binary: doctrinal purity OR emotional engagement, rational analysis OR social context. Material scarcity forced choices, resulting in rational-privileging despite learning science showing integration matters. AI doesn't just provide more materials—it provides design agency. When empathy calibration, surprise-inducing errors, humor-based transfer tests, and role-play practice become specifiable rather than accidental—when instructors can say "I want students to laugh while learning lawful basis" and generate it—multi-dimensional engagement moves from aspirational to systematic. The question isn't whether students use AI (86% already do) but whether educators develop design literacy matching that adoption. Carnegie Report: "connecting remains outside the case-dialogue method." Twenty years later, AI's flexibility makes connection intrinsic through intentional multiply-loaded design. The abstraction problem isn't inherent to legal education's subject matter—it was an artifact of material scarcity we no longer face. What becomes possible when every legal educator can systematically engineer materials connecting doctrine to humanity, analysis to affect, individual reasoning to social context? That's the conversation this article aims to open.

**Sources:** Carnegie Report (Sullivan et al., 2007) for final bookend; Nature (2025) for student adoption; end on note of possibility and agency, not prescription; acknowledge this is opening not conclusion.

---