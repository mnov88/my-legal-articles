# II. Economic Foundation: Why Prompt Protection Matters

In June 2022, PromptBase began selling text strings for \$1.99 each – instructions optimized to extract superior outputs from DALL-E 2 and GPT-3. Within months, the platform reported 370,000 users trading over 220,000 prompts, with sellers retaining 80 percent of revenue.[^1] That same year, Anthropic advertised a San Francisco position for "Prompt Engineer and Librarian" offering up to \$335,000 annually – compensation rivaling senior software architects.[^2] Morgan Stanley deployed GPT-4 to help wealth managers synthesize insights from 100,000 research reports, relying on carefully engineered prompts to minimize hallucinations and token costs.[^3]

[^1]: TechCrunch, 'People are getting paid to prompt AI and it can pay well' (27 July 2022) <https://techcrunch.com/2022/07/27/people-are-getting-paid-to-prompt-ai-and-it-can-pay-well/> accessed 10 November 2025.

[^2]: Market.us, 'How to Become a Prompt Engineer' (updated October 2025) <https://market.us/report/prompt-engineer-career-guide/> accessed 10 November 2025.

[^3]: McKinsey & Company, 'The Economic Potential of Generative AI: The Next Productivity Frontier' (June 2023) <https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/the-economic-potential-of-generative-ai-the-next-productivity-frontier> accessed 10 November 2025.

These vignettes raise whether market signals constitute empirical proof of economic value sufficient to justify legal protection for prompts as intellectual property. The question demands systematic examination of documented evidence across four dimensions: marketplace transactions revealing price discovery, labor market valuations expressed through professional compensation, productivity measurements quantifying efficiency gains, and appropriability concerns that might warrant legal intervention.

## A. Investment and skill requirements

Prompt engineering requires non-intuitive expertise distinct from ordinary language use. Research by Jonas Oppenlaender at the University of Oulu demonstrates that effective prompting demands understanding of model architectures, training methodologies, and systematic experimentation to identify formulations that reliably produce desired outputs.[^4] Unlike natural conversation, prompt engineering requires technical knowledge of model capabilities, limitations, and failure modes.

[^4]: Jonas Oppenlaender, 'A Taxonomy of Prompt Modifiers for Text-to-Image Generation' (2023) 50 Behaviour & Information Technology 1839.

The investment manifests in three forms. First, training costs. Organizations hiring prompt engineers require candidates with backgrounds in natural language processing, machine learning, and computational linguistics.[^5] Coursera offers prompt engineering certification programs requiring 20-40 hours of structured instruction.[^6] These educational investments precede productive work.

[^5]: Mobilunity, 'Prompt Engineer Salary: Roles and Earning Potential' (2025) <https://mobilunity.com/blog/prompt-engineer-salary/> accessed 10 November 2025.

[^6]: Coursera, 'What is a Prompt Engineer? Salary and Career Guide' (February 2025) <https://www.coursera.org/articles/prompt-engineer-salary> accessed 10 November 2025.

Second, iterative development. Effective prompts emerge through systematic testing, refinement, and optimization. McKinsey's research on software development found that developers using generative AI completed tasks 1.5 to 2.5 times faster – but only when employing "effective prompting techniques incorporating context, constraints, and iterative refinement."[^7] The productivity gains require investment in prompt optimization, not merely submitting initial queries.

[^7]: McKinsey & Company (n 17).

Third, institutional knowledge. Specialized prompts embed domain expertise. The pharmaceutical company example – prompts enabling Claude to identify promising drug candidates 60 percent faster – requires integrating chemical structure knowledge, regulatory requirements, and research literature familiarity into prompt formulations.[^8] This specialized integration represents substantial development investment distinct from general-purpose AI usage.

[^8]: ibid.

## B. Commercial value and market evidence

Three categories of evidence demonstrate commercial value. Marketplace transactions provide the most direct proof. PromptBase reports 370,000 registered users and more than 220,000 prompts, with prices ranging from \$1.99 to \$9.99 and over 24,000 five-star reviews indicating sustained commercial activity.[^9] While individual prices remain modest – suggesting commodity-level rather than premium intellectual property valuation – the platform's scale demonstrates that buyers perceive value sufficient to justify payment.

[^9]: Skywork AI, 'Prompt Marketplace Analysis' (September 2025) (citing PromptBase user statistics).

Labor market valuations provide a second measure. Glassdoor data for August 2025 indicates prompt engineers earn average annual salaries of \$123,803 in the United States, with typical ranges between \$96,661 and \$160,352.[^10] Entry-level positions average \$98,214, while senior roles reach \$128,090.[^11] Outlier positions in competitive markets reach \$335,000 for specialized hybrid roles combining prompt engineering with research expertise.[^12] These figures establish that employers value prompt engineering competency sufficiently to pay compensation comparable to software development and data science roles.

[^10]: Glassdoor, 'Prompt Engineer Salaries' (August 2025) <https://www.glassdoor.com/Salaries/prompt-engineer-salary-SRCH_KO0,15.htm> accessed 10 November 2025.

[^11]: ibid.

[^12]: Market.us (n 16).

Productivity measurements provide the most methodologically rigorous evidence. McKinsey's June 2023 report estimated that generative AI could add \$2.6 trillion to \$4.4 trillion annually to the global economy across 63 use cases – 2.6 to 4.4 percent of global GDP.[^13] Within software engineering, developers using generative AI tools completed tasks 1.5 to 2.5 times faster than control groups.[^14] GitHub Copilot users completed tasks 56 percent faster than developers without AI assistance.[^15] Critically, McKinsey explicitly identified prompt engineering as a determinant of outcome quality, finding that developers employing effective prompting techniques achieved "an additional time improvement of 1.5 to 2.5 times" compared to those using suboptimal approaches.[^16]

[^13]: McKinsey & Company (n 17).

[^14]: ibid.

[^15]: ibid (citing Cihon and others, 'GitHub Copilot Study' (2023) arXiv:2302.06590).

[^16]: McKinsey & Company (n 17).

Enterprise competitive advantage constitutes the fourth category. Organizations investing substantially in prompt engineering seek to protect that investment. The legal analytics firm example – €2.3 million invested over eighteen months developing prompts for credit scoring – demonstrates documented development costs creating economic value that competitors could misappropriate by copying rather than independently investing.[^17]

[^17]: See Section VI.C discussing commercial value element under trade secret law.

## C. Appropriability concerns and the free-riding problem

The economic case for legal protection rests on appropriability challenges. Prompts face severe commoditization pressure from zero marginal cost reproduction. Once disclosed, prompts can be copied instantaneously at no cost. PromptBase documentation acknowledges that "different users may receive the same or substantially similar outputs" from identical prompts, admitting non-exclusivity as inherent to the product category.[^18]

[^18]: PromptBase, 'About PromptBase' <https://promptbase.com/about> accessed 10 November 2025.

The free-riding problem threatens investment incentives. If competitors can appropriate prompt engineering work without incurring equivalent development costs, rational actors will under-invest in prompt optimization and instead wait to copy successful formulations developed by others. This classic appropriability failure – where social returns exceed private returns due to positive externalities – provides the traditional economic justification for intellectual property protection.[^19]

[^19]: Kenneth J. Arrow, 'Economic Welfare and the Allocation of Resources for Invention' in National Bureau of Economic Research, *The Rate and Direction of Inventive Activity: Economic and Social Factors* (Princeton University Press 1962) 609.

Reverse engineering exacerbates the challenge. Recent research demonstrates that effective prompts can be reconstructed from observing as few as five AI outputs using black-box, zero-shot methods.[^20] If prompts are reliably reconstructible from publicly available outputs through techniques requiring minimal investment, the information lacks the durability and excludability characteristic of protectable intellectual property.

[^20]: See Section VI.E discussing reverse engineering counterargument under trade secret law.

## D. Countervailing concerns: monopolization risks and complexity spectrum

Three countervailing considerations complicate the case for protection. First, monopolization risks. Granting exclusive rights over prompts could enable strategic behavior restricting access to AI capabilities. If effective prompts for common tasks receive intellectual property protection, rights holders could extract rents from users seeking to perform ordinary functions – tax on AI utilization rather than reward for genuine innovation.[^21]

[^21]: cf Brett M. Frischmann and Mark A. Lemley, 'Spillovers' (2007) 107 Columbia Law Review 257 (discussing infrastructure goods and access concerns).

Second, the labor-versus-asset distinction. The economic value concentrates in human expertise – prompt engineering as professional skill – rather than in prompts themselves as discrete tradeable assets. Labor markets compensate skilled practitioners through salaries. No licensing markets for prompt portfolios have emerged despite three years of intensive AI adoption.[^22] The absence of licensing transactions, intellectual property litigation over prompts, or regulatory recognition suggests that market participants perceive prompts as service outputs rather than valuable proprietary assets requiring legal protection.

[^22]: Comprehensive searches across Bloomberg Law, Lexis, Financial Times, and Wall Street Journal yielded no reported transactions licensing prompts as intellectual property, contrasting sharply with extensive content licensing agreements for training data. See Economic value of prompts research notes.

Third, the complexity spectrum matters. The empirical evidence suggests a bimodal distribution. Simple prompts commanding \$1.99 on PromptBase reflect commodity-level valuation requiring minimal protection. Sophisticated prompts representing months of optimization and documented investment – the pharmaceutical example, the legal analytics €2.3 million investment – might merit protection if appropriability failures genuinely threaten incentives. Legal frameworks should distinguish between these categories rather than treating all prompts uniformly.

Economic evidence establishes that prompt engineering generates measurable value through productivity gains and commands professional-tier compensation reflecting skilled labor demand. The evidence does not establish that individual prompts constitute high-value intellectual property assets requiring robust legal protection. Value concentrates in outcomes prompts enable and expertise required to engineer them, not in prompts themselves as tradeable assets with independent economic standing. This distinction – between valuing human expertise and productive efficiency versus valuing prompts as discrete intellectual property – proves critical for assessing whether existing legal frameworks accommodate prompts and whether policy reforms might be warranted.

# III. Copyright and Software Protection: Instructions Excluded as Functional Subject Matter

The most intuitive protection pathway for textual content is copyright, potentially supplemented by specialized protection for computer programs under the Software Directive. This Part demonstrates that both frameworks converge on the same conclusion: prompts constitute functional instructions—ideas, procedures, and methods of operation—that copyright law deliberately excludes from protection. The analysis proceeds systematically through the harmonized originality standard, its application to prompts of varying complexity, the identifiability requirement, and the idea-expression dichotomy as operationalized through both the InfoSoc Directive and the Software Directive. The convergence is not coincidental—it reflects fundamental policy choices about preserving the public domain of functional language, communication methods, and building blocks necessary for innovation and competition.

## A. The Harmonized Originality Standard

The starting point for copyright analysis under EU law is the harmonized originality standard articulated by the Court of Justice of the European Union in *Infopaq International A/S v Danske Dagblades Forening*. The Court held that "copyright within the meaning of Article 2(a) of Directive 2001/29 is liable to apply only in relation to a subject-matter which is original in the sense that it is its author's own intellectual creation."[^23] This formulation—drawn from Article 1(3) of the Software Directive and Article 3(1) of the Database Directive—has been extended by the CJEU to all categories of works protected under the Information Society Directive.[^24] No other criteria may be applied to determine eligibility for copyright protection; Member States cannot demand aesthetic merit, cultural value, or qualitative thresholds beyond originality as the author's own intellectual creation.[^25]

[^23]: Case C-5/08 *Infopaq International A/S v Danske Dagblades Forening* EU:C:2009:465, para 37.

[^24]: Directive 2001/29/EC of the European Parliament and of the Council of 22 May 2001 on the harmonisation of certain aspects of copyright and related rights in the information society [2001] OJ L167/10 ('InfoSoc Directive'); Directive 2009/24/EC of the European Parliament and of the Council of 23 April 2009 on the legal protection of computer programs [2009] OJ L111/16 ('Software Directive'); Directive 96/9/EC of the European Parliament and of the Council of 11 March 1996 on the legal protection of databases [1996] OJ L77/20 ('Database Directive').

[^25]: *Infopaq* (n 1) para 38.

What does this standard require? The CJEU clarified in *Painer v Standard Verlags* that "an intellectual creation is an author's own if it reflects the author's personality," which occurs when "the author was able to express his creative abilities in the production of the work by making free and creative choices."[^26] Originality demands that the author stamp the work with their "personal touch" through decisions that are neither dictated by technical considerations nor compelled by functional constraints leaving no room for creative freedom.[^27]

[^26]: Case C-145/10 *Eva-Maria Painer v Standard VerlagsGmbH and Others* EU:C:2011:798, para 89.

[^27]: Case C-604/10 *Football Dataco Ltd and Others v Yahoo! UK Ltd and Others* EU:C:2012:115, para 38.

The threshold is deliberately low but not nonexistent. As the Court held in *Football Dataco*, "the fact that the setting up of the database required, irrespective of the creation of the data which it contains, significant labour and skill of its author" cannot justify protection "if that labour and that skill do not express any originality in the selection or arrangement of that data."[^28] EU copyright law has explicitly rejected the "sweat of the brow" doctrine; investment and effort alone cannot generate copyright protection absent creative choices reflecting the author's personality.[^29]

[^28]: *Football Dataco* (n 5) para 42.

[^29]: ibid para 41.

The CJEU consolidated these principles in *Cofemel v G-Star Raw*, confirming at paragraph 29 that "a subject matter can be classified as a 'work' within the meaning of Directive 2001/29 only if it is an original subject matter in that it is the author's own intellectual creation."[^30] Critically, at paragraph 30, the Court held that "the assessment of the originality of a subject matter is therefore primarily based on whether that subject matter reflects the personality of its author, as an expression of his or her free and creative choices."[^31] This established a uniform, harmonized standard across all Member States.

[^30]: Case C-683/17 *Cofemel v G-Star Raw* EU:C:2019:721, para 29.

[^31]: ibid para 30.

*Cofemel* forecloses any argument that prompts merit protection under criteria other than originality or that Member States might establish special regimes for AI-related subject matter. At paragraphs 30-32, the Court emphasized that Member States cannot apply alternative criteria—no aesthetic merit requirements, no applied art distinctions, no utilitarian function tests.[^32] The originality test is exclusive and admits no exceptions for technological novelty or economic value considerations. This uniformity principle proves critical for prompts: if Member States cannot lower the originality threshold for established work categories, they certainly cannot do so for emerging technologies. The harmonized standard applies with full force to prompts, without accommodation for their functional utility or the investment required to develop them.

[^32]: ibid paras 30-32.

Two cumulative conditions must be satisfied for subject matter to qualify as a "work" under EU copyright law, as the CJEU synthesized in *Levola Hengelo BV v Smilde Foods*.[^33] First, the subject matter must be original in the sense just described—the author's own intellectual creation resulting from free and creative choices. Second, and critically for prompts, "only something which is the expression of the author's own intellectual creation may be classified as a 'work'" under the InfoSoc Directive.[^34]

[^33]: Case C-310/17 *Levola Hengelo BV v Smilde Foods BV* EU:C:2018:899.

[^34]: ibid para 36.

This second requirement imposes an identifiability constraint, examined in detail in Part D below. For present purposes, the key principle is that copyright requires not merely originality but also that the subject matter constitute *expression* rather than *ideas, procedures, or methods*. The originality standard and the idea-expression dichotomy function as two independent filters, each capable of defeating protection.

The Copyright Term Directive adds a temporal dimension relevant to policy analysis. Article 1(1) provides that "the rights of an author of a literary or artistic work within the meaning of Article 2 of the Berne Convention shall run for the life of the author and for 70 years after his death."[^35] This extraordinarily long term—justified by Recital 5 as necessary to "protect works for two generations after the author's death" given increased human longevity—sits uncomfortably with functional subject matter that may become technologically obsolete within months or years as AI models evolve and prompting conventions change.[^36] The mismatch between copyright's default term and the useful life of functional instructions constitutes a policy consideration that counsels against extending copyright protection to prompts, as examined further in Part G below.

[^35]: Directive 2006/116/EC of the European Parliament and of the Council of 12 December 2006 on the term of protection of copyright and certain related rights [2006] OJ L372/12, art 1(1).

[^36]: ibid recital 5.

## B. Application to Simple Prompts

Three possible theories present themselves for classifying prompts as copyrightable works under EU law. First, prompts might constitute literary works under Article 2 of the InfoSoc Directive. Second, prompts might be protected as computer programs under the Software Directive, particularly given its extension of protection to "preparatory design material."[^37] Third, complex collections of prompts might qualify as databases under the Database Directive if their selection or arrangement reflects the author's intellectual creation.[^38] This section examines the first theory—prompts as literary works—while subsequent analysis addresses software protection in Part F and database protection in Part J.

[^37]: Software Directive (n 2) art 1(1).

[^38]: Database Directive (n 2) art 3(1).

To determine whether a prompt constitutes a literary work, one must apply the *Infopaq* originality test: does the prompt reflect the author's personality through free and creative choices that stamp the author's personal touch on the text?

For the one-word prompt "Summarize," the answer is straightforward and negative.

Single words are explicitly excluded from copyright protection. The CJEU held in *Infopaq* that "words as such do not constitute elements covered by the protection" because "it is only through the choice, sequence and combination of those words that the author may express his creativity in an original manner."[^39] No creative choices are evident in selecting the single word "Summarize" to instruct an AI to perform summarization; the selection is dictated entirely by the functional goal of conveying a standard instruction.

[^39]: *Infopaq* (n 1) para 45.

Even if one imagined minimal creativity in word choice, the prompt would fail the requirement articulated in *Football Dataco* that originality cannot arise from "significant labour and skill" alone but only from choices "through which its author expresses his creative ability in an original manner by making free and creative choices" reflecting personality.[^40]

[^40]: *Football Dataco* (n 5) para 38.

Consider a slightly more complex example: "Write a formal business letter declining a job offer, emphasizing gratitude for the opportunity while explaining the decision is based on accepting a position better aligned with long-term career goals in environmental policy." This 33-word prompt involves choices in framing, sequencing, and specification—the author chose to request a "formal" letter, to emphasize "gratitude," to specify the explanation structure, and to particularize the career field as "environmental policy."

Do these choices suffice to meet the *Infopaq* standard?

The question is whether the choices reflect creative freedom or functional necessity—in the language of *Football Dataco*, whether "the setting up" of the prompt "is dictated by technical considerations, rules or constraints which leave no room for creative freedom."[^41] Here, functional constraints dominate: the prompt's purpose is to convey instructions, and the specifications respond to practical requirements for generating useful output. The author's "creative choices" reduce to selecting among conventional descriptive terms for standard concepts.

[^41]: ibid para 39.

National court practice confirms the difficulty of protecting functional instructions under the harmonized EU originality standard. The German Bundesgerichtshof's *Bedienungsanleitung* decision held that operating instructions—user manuals explaining how to operate equipment—require "eigenschöpferische Gedankenformung" (creative intellectual formulation) in arrangement beyond technical necessities. The Court further held that protection demands that the work "deutlich überragen der Durchschnittsgestaltung" (distinctly exceeds average design through creative arrangement).[^42] Simple, routine formulations receive no protection regardless of the labor invested in their creation.

[^42]: BGH 12 November 1993, I ZR 61/92 (Bedienungsanleitung) [1994] GRUR 363.

French courts have held that cooking recipes "do not in themselves constitute an intellectual work, but rather a savoir-faire" because they constitute a "succession of instructions, a method."[^43] The Cour de Cassation emphasized that recipes belong to the category of procedures rather than expressions, though copyright may protect creative literary description accompanying functional instructions.[^44] The distinction is critical: functional instructions themselves remain unprotectable; only substantial creative expression in presenting those instructions might qualify for independent protection.

[^43]: Cour de Cassation [1974] Bulletin civil IV n° 267.

[^44]: CA Paris 25 February 1974 (Société Albin Michel) [1974] RIDA 161.

The Czech Municipal Court in Prague addressed prompt copyrightability directly in a 2023 decision, holding *obiter* that a prompt "could only be regarded as a theme or idea for a work" and thus fell outside copyright protection.[^45] The Court drew an explicit analogy to recipes—just as recipes constitute unprotectable methods rather than expressions, prompts constitute unprotectable specifications of desired outputs rather than creative works themselves. While this is a first-instance decision without binding precedential value, it represents the first judicial opinion directly addressing prompt copyrightability and confirms the functional instruction characterization developed in CJEU case law.[^46]

[^45]: Municipal Court in Prague, decision of 11 April 2023, reported in Bird & Bird, 'Czech Court denies copyright protection of AI-generated work' (29 May 2024) <https://www.twobirds.com/en/insights/2024/czech-republic/czech-court-denies-copyright-protection-of-ai-generated-work> accessed 10 November 2025.

[^46]: ibid.

The Dutch Hoge Raad's *Endstra* decision requires works to result from "creative human labour and thus creative choices," excluding mechanical arrangements and routine compilations even where substantial effort was invested.[^47]

[^47]: Hoge Raad 30 May 2008, ECLI:NL:HR:2008:BC2153 (Endstra).

The common pattern across jurisdictions is this: functional texts conveying procedures, methods, or instructions face substantially higher originality thresholds than artistic or literary works. Courts distinguish between creative expression in *presenting* functional information (which may be protected) and functional instructions themselves (which remain free for all to use). Prompts fall squarely on the unprotectable side of this distinction—they are functional specifications for AI operation, not literary works incidentally involving AI systems.

Across jurisdictions, the pattern is consistent: functional texts that convey procedures, methods, or instructions face substantially higher originality thresholds than artistic or literary works, and simple or routine formulations fail regardless of the labour invested in their creation.

## C. Application to Complex Prompts

The extensive system prompt—400 words specifying tone, vocabulary constraints, citation formats, rhetorical strategies, prohibited topics, required factual accuracy standards, and iterative refinement protocols—presents the strongest candidate for copyright protection based on length and apparent complexity.

Academic analysis of national court practice reveals that courts generally find longer texts more likely to exhibit originality because greater length provides more scope for individual creative choices.[^48] The German Bundesgerichtshof has held that even functional texts like operating instructions may be protected where they "distinctly exceed average design" through creative arrangement beyond routine formulation.[^49]

[^48]: Thomas Dreier and Gernot Schulze, *Urheberrechtsgesetz: UrhG Kommentar* (7th edn, C.H. Beck 2022) § 2 Rn. 47–52.

[^49]: *Bedienungsanleitung* (n 20).

However, three obstacles undermine copyright protection even for elaborate system prompts.

First, the prompt remains fundamentally a set of instructions—procedures and methods for the AI to follow—and such functional specifications are excluded from copyright protection under TRIPS Article 9(2) and the Software Directive regardless of length or complexity. This is examined in detail in Part E below.

Second, originality requires that creative choices not be "dictated by technical considerations, rules or constraints which leave no room for creative freedom,"[^50] yet system prompts are precisely constrained by the functional requirements of effective AI interaction.

[^50]: *Football Dataco* (n 5) para 39.

The CJEU's decision in *Brompton Bicycle v Chedech* establishes the framework. The Court held at paragraph 24 that "where the realisation of a subject matter has been dictated by technical considerations, rules or other constraints which have left no room for creative freedom, that subject matter cannot be regarded as being original."[^51] The Court continued at paragraph 25 that even where "certain aesthetic elements...co-exist with certain technical functionalities," copyright protection may apply provided the author "express[es] his or her creativity in an original manner by making free and creative choices, which allows the author to stamp his or her 'personal touch' on that subject matter."[^52]

[^51]: Case C-833/18 *Brompton Bicycle Ltd v Chedech/Get2Get* EU:C:2020:461, para 24.

[^52]: ibid para 25.

The *Brompton Bicycle* framework thus addresses precisely the situation prompts present: *some* word-choice freedom exists, but structural decisions are dictated by functional requirements. The critical question is whether creative freedom predominates despite functional constraints. The test does not require *complete* absence of creative freedom—it asks whether constraints have left "*no room* for creative freedom" such that choices are dictated by function rather than by expressive personality.

Applied to prompts, the balance tips decisively toward functional constraint. Many prompt elements—parameter specifications ("temperature=0.3"), formatting conventions ("use markdown"), strategic keyword placement—are dictated by AI model architecture requirements rather than authorial creativity. The prompt engineer learns through experimentation which phrasings produce desired effects, which parameter values optimize output quality, and which structural patterns improve consistency. These choices reflect skill and accumulated knowledge about AI system behavior, but they are dictated by the functional goal of effective communication with the AI rather than by expressive choices reflecting the author's personality.

Even where some flexibility exists in word choice, *Brompton Bicycle* establishes that predominant functional constraint suffices to defeat originality. The Court's framework rejects the notion that any creative freedom, no matter how marginal, automatically satisfies the originality requirement. Instead, the question is whether the author had meaningful latitude to express personality through choices unconstrained by functional necessity. For prompts, functional optimization dominates—choices respond to what works effectively with AI models rather than to aesthetic, literary, or expressive preferences.

Consider specific examples. Specifying "formal tone" rather than "casual tone" in a prompt reflects a functional requirement for the desired output's register, not a creative literary choice by the prompt author. Similarly, requesting "Chicago citation style" rather than "MLA citation style" responds to the user's documentation needs, not to creative expression. Setting "temperature at 0.3" rather than "temperature at 0.7" reflects technical knowledge about controlling output randomness, not personality-stamping creativity. Even sequences of such specifications, when aggregated into multi-paragraph system prompts, remain fundamentally constrained by functional optimization concerns.

Third, the question becomes whether the prompt's selection and arrangement of specifications reflects sufficient originality. Here the analogy to databases proves instructive—as the CJEU held in *Football Dataco*, mere compilation of functional elements without creative selection principle fails the originality test.[^53]

[^53]: ibid para 42.

The strongest affirmative argument for prompt copyrightability relies on *Infopaq*'s holding that even 11-word excerpts "may be suitable for conveying to the reader the originality of a publication such as a newspaper article, by communicating to that reader an element which is, in itself, the expression of the intellectual creation of the author."[^54] If 11 words can be protected, surely 400 words of carefully crafted specifications can be.

[^54]: *Infopaq* (n 1) para 47.

This argument founders on a distinction the CJEU has drawn consistently.

*Infopaq* concerned literary expression in newspaper articles where the journalist exercised creative freedom in word choice, phrasing, and presentation of ideas. The Court emphasized that "through the choice, sequence and combination of those words the author may express his creativity in an original manner and achieve a result which is an intellectual creation."[^55] Prompts, by contrast, function as instructions rather than as literary communication. Their purpose is to specify procedures for the AI to execute, not to express the author's creative vision through language selected for its aesthetic or communicative qualities.

[^55]: ibid para 45.

Prompts fall on the functional side of the line the CJEU has drawn between creative expression and utilitarian specification. The distinction is not one of length but of purpose and constraint. Where the purpose of text is to convey instructions efficiently and accurately, the range of expression narrows to the point where idea and expression merge. Protecting the resulting text would monopolize the underlying method or procedure in violation of the fundamental principle that copyright extends only to expression, not to ideas, procedures, or methods of operation.[^56]

[^56]: Agreement on Trade-Related Aspects of Intellectual Property Rights (adopted 15 April 1994, entered into force 1 January 1995) 1869 UNTS 299 ('TRIPS Agreement'), art 9(2).

The merger doctrine—though not articulated under that label in EU law—operates through the CJEU's framework. When limited ways exist to express a particular instruction, protecting any formulation would monopolize the instruction itself. Consider specific examples. Instructing an AI to "increase brightness" can be expressed as "make brighter," "brighten," "enhance luminosity," or "raise brightness level"—but these are functionally equivalent formulations differing only in trivial word choice. Similarly, requesting "formal tone" could be phrased as "professional tone," "business-appropriate style," or "corporate register," but each communicates the same functional constraint to the AI. Specifying "use active voice" admits only minimal variation: "employ active voice," "write in active voice," "prefer active constructions." Protecting any of these formulations would enable monopolization of the underlying instruction—precisely what the idea-expression dichotomy forbids.

The Court's analysis in *BSA* (examined in detail in Part E below) applies directly: where "the idea and the expression become indissociable," protection must be denied because "to accept that the functionality...can be protected by copyright would amount to making it possible to monopolise ideas, to the detriment of technological progress and industrial development."[^57] Even complex multi-clause prompts face this constraint. A prompt specifying "Write a 500-word essay in academic style with Harvard citations addressing climate policy" contains functional specifications that can be expressed only in limited ways. The word count, style designation, citation format, and topic are ideas about what should be created; the particular words chosen to convey these specifications represent the only practical means of communicating them to an AI system.

[^57]: Case C-393/09 *Bezpečnostní softwarová asociace v Ministerstvo kultury* EU:C:2010:816, para 50.

## D. Prompts and the Identifiability Requirement

An independent barrier to copyright protection emerges from the identifiability constraint articulated in *Levola Hengelo*. The Court held that "for there to be a 'work' as referred to in Directive 2001/29, the subject matter protected by copyright must be expressed in a manner which makes it identifiable with sufficient precision and objectivity."[^58] The rationale addresses legal certainty: "it is important, for the purposes of enforcement by the competent authorities, and for legal certainty, that the subject matter protected by copyright, which may accordingly be the subject of the exclusive rights provided for in Directive 2001/29, can be identified clearly and precisely."[^59] Competitors and the public must be able to determine with clarity what third parties have monopolized through copyright protection; authorities must be able to enforce rights against clearly identified subject matter.

[^58]: *Levola Hengelo* (n 11) para 40.

[^59]: ibid para 41.

Prompts face a distinctive identifiability problem arising from the probabilistic nature of AI inference. The same prompt submitted to the same AI model at different times produces varying outputs due to stochastic sampling, temperature parameters, and non-deterministic neural network processing. This variability undermines the claim that prompts constitute identifiable "works" within the meaning of the InfoSoc Directive.

If a prompt is claimed as a protected work, authorities and competitors must be able to identify precisely what is protected. Yet when the same prompt yields different outputs across invocations, the "work" claimed cannot be identified with the precision *Levola* requires. Is the protected subject matter the literal text of the prompt? The intended output? The range of probable outputs? The relationship between prompt and output is fundamentally indeterminate—temperature settings, sampling methods, model versions, and random seed values all affect the output generated from identical prompt text.

This non-determinism creates insurmountable enforcement challenges. Consider a copyright infringement claim based on alleged copying of a protected prompt. The claimant would need to prove that the defendant's prompt constitutes a reproduction or adaptation of the protected work. But if the same prompt text produces different outputs on each invocation, how can substantial similarity be assessed? Traditional copyright infringement analysis compares the allegedly infringing work to the protected work to determine whether substantial parts have been reproduced. For prompts, there is no stable "work" to serve as the comparator—each invocation creates a different result.

Moreover, the variability problem extends beyond outputs to the prompts themselves. Conversational AI interfaces allow users to refine prompts iteratively, with each refinement potentially changing the effective instruction. Is each iteration a separate work? Is the sequence of prompts collectively a single work? The CJEU's requirement that works be identifiable "with sufficient precision and objectivity" cannot be satisfied when the boundaries of the claimed work remain fundamentally uncertain.

This problem distinguishes prompts from traditional preparatory materials. Pseudocode, architectural diagrams, and technical specifications enable deterministic implementation—multiple programmers working from the same specification produce functionally equivalent results. The specification itself constitutes a stable, identifiable work whose boundaries can be determined with precision. Prompts operate probabilistically, triggering existing AI models to generate outputs that vary across invocations even when all explicit parameters remain constant. The instability is inherent to how large language models function—they are probabilistic systems that sample from learned distributions rather than deterministic programs that execute fixed algorithms.

Academic commentary reinforces this analysis. Professor Andres Guadamuz argues that prompts cannot qualify under the Software Directive because they do not "lead to a computer program at a later stage" but rather trigger probabilistic processes that generate variable outputs.[^60] Ana Sampaio articulates the point with precision: "the same prompt to the same model will not deliver the same results," fundamentally distinguishing prompts from preparatory design material, which must be sufficiently precise to enable deterministic program implementation.[^61]

[^60]: Andres Guadamuz, 'The Monkey Selfie: Copyright Lessons for Originality in Photographs and AI Works' (2018) 5 Internet Policy Review 1, 12.

[^61]: Ana Sampaio, 'Are Prompts Copyrightable?' (Kluwer Copyright Blog, 14 June 2023) <http://copyrightblog.kluweriplaw.com/2023/06/14/are-prompts-copyrightable> accessed 10 November 2025.

The identifiability requirement thus provides an independent ground for denying copyright protection to prompts, separate from and complementary to the originality and idea-expression analyses. Where originality concerns whether the author made sufficiently creative choices, identifiability concerns whether the claimed work can be defined with sufficient precision to permit enforcement. Prompts fail both tests—they lack originality because choices are functionally dictated, and they lack identifiability because their probabilistic operation prevents stable definition of the protected subject matter.

This identifiability barrier operates regardless of prompt complexity. Whether the prompt consists of a single word or 400 words, the non-deterministic relationship between prompt and output prevents the precise identification *Levola* requires. Copyright protection demands stable, identifiable works whose boundaries can be determined objectively; prompts' inherent variability places them outside this requirement.

The policy rationale for the identifiability requirement reinforces its application to prompts. Copyright grants monopoly rights that restrict competitors' freedom of action; such restrictions are justified only when the boundaries of the monopoly can be clearly defined. Granting copyright protection to prompts would create uncertainty about what language users may freely employ when interacting with AI systems. Every effective prompting technique would become a potential infringement trap, chilling experimentation and the cumulative learning essential to developing AI literacy. The *Levola* identifiability requirement prevents this outcome by ensuring that copyright attaches only to subject matter whose boundaries can be determined with precision.

## E. The idea-expression dichotomy and Software Directive exclusions

The principle that copyright protects expression but not ideas, procedures, or methods of operation has constitutional status in EU copyright law. Article 9(2) of the TRIPS Agreement provides that "copyright protection shall extend to expressions and not to ideas, procedures, methods of operation or mathematical concepts as such."[^62] The WIPO Copyright Treaty contains an identical provision in Article 2.[^63] The Software Directive operationalizes this principle in Article 1(2), providing that "protection in accordance with this Directive shall apply to the expression in any form of a computer program" while "ideas and principles which underlie any element of a computer program, including those which underlie its interfaces, are not protected by copyright under this Directive."[^64]

[^62]: Agreement on Trade-Related Aspects of Intellectual Property Rights (adopted 15 April 1994, entered into force 1 January 1995) 1869 UNTS 299 ('TRIPS Agreement'), art 9(2).

[^63]: WIPO Copyright Treaty (adopted 20 December 1996, entered into force 6 March 2002) 2186 UNTS 121, art 2.

[^64]: Software Directive (n 2) art 1(2).

This express exclusion of interfaces proves dispositive for prompts. Recital 11 elaborates that "only the expression of a computer program is protected and that ideas and principles which underlie any element of a program, including those which underlie its interfaces, are not protected by copyright."[^65] The CJEU has treated this formulation as fundamental to copyright's proper scope across all work categories.

[^65]: ibid recital 11.

What distinguishes an unprotectable idea, procedure, or method from a protectable expression? The CJEU has addressed this question through three decisions that converge on prompts' exclusion: *BSA v Ministerstvo kultury* on interfaces, *SAS Institute v World Programming* on functionality, and *Sony Computer Entertainment Europe v Datel Design & Development* on data inputs. Each provides an independent ground for denying protection; together they establish that prompts fall squarely within excluded categories under both the InfoSoc Directive and the Software Directive.

### Interfaces excluded: BSA and the parallel to prompts

The CJEU addressed interface protection in *Bezpečnostní softwarová asociace v Ministerstvo kultury*. The Court held that graphical user interfaces "do not enable the reproduction of the computer program, but merely constitute one element of that program by means of which users make use of the features of a computer program."[^66] Only source code or object code constituting the program's expression receives Software Directive protection. User-facing elements through which individuals interact with software fall outside the Directive's scope.[^67]

[^66]: Case C-393/09 *Bezpečnostní softwarová asociace v Ministerstvo kultury* EU:C:2010:816, para 42.

[^67]: ibid para 45.

GUIs are not protected because they are user-facing interaction mechanisms, not program expressions themselves.

This principle applies directly to prompts. Just as GUIs enable users to interact with software through visual elements, prompts enable users to interact with AI systems through natural language. Both are interfaces — mechanisms for communicating with existing computational systems. Neither constitutes the program itself.

The parallel is exact. GUIs provide visual interfaces — inputs to programs through graphical elements. Prompts provide textual interfaces — inputs to AI programs through natural language. The Software Directive excludes interfaces under Article 1(2). If visual interfaces enabling user interaction with software are not protected as program expressions, then natural language prompts enabling user interaction with AI systems fall under the same exclusion.

The *BSA* Court's reasoning applies without modification. Prompts "do not enable the reproduction" of AI models. They do not contain or express the trained neural network weights, inference algorithms, or computational processes constituting the AI system. They are instructions *to* programs, not programs themselves.

### Functionality excluded: SAS Institute and prompts as specifications

The Court reinforced this in *SAS Institute Inc v World Programming Ltd*, which concerned whether copyright protected the functionality, programming language, and data file formats of statistical analysis software. The Court held categorically that "neither the functionality of a computer program nor the programming language and the format of data files used in a computer program in order to exploit certain of its functions constitute a form of expression" protected under the Software Directive.[^68]

[^68]: Case C-406/10 *SAS Institute Inc v World Programming Ltd* EU:C:2012:259, para 39.

The reasoning proves dispositive. "To accept that the functionality of a computer program can be protected by copyright would amount to making it possible to monopolise ideas, to the detriment of technological progress and industrial development."[^69] Copyright's purpose is to protect creative expression while leaving ideas, concepts, and functional methods free for others to use and build upon. Protecting functionality would transform copyright into a patent-like monopoly without the stringent requirements of novelty, non-obviousness, and limited duration that justify patent protection.[^70]

[^69]: ibid para 40.

[^70]: ibid para 45.

Prompts specify functionality. They describe what the AI should do, what outputs it should generate, what constraints it should observe, and what format results should take. A prompt stating "write a 500-word essay in academic style with Harvard citations addressing climate policy" specifies functionality as precisely as a software specification document stating "the program shall generate reports in PDF format containing statistical analyses with graphical visualizations." Both describe what outputs the system should produce. Neither constitutes the expression of how the system produces those outputs.

The *SAS Institute* framework applies without modification. If formal programming languages — Python syntax, SQL query structures, JavaScript conventions — are unprotectable ideas and principles under Article 1(2), then natural language prompts are equally unprotectable.[^71] Both are methods for instructing computational systems. Both specify desired operations. A Python command `print("Hello, world")` and a prompt "Write 'Hello, world'" function equivalently — both instruct a computational system to produce output. The natural language formulation does not transform the instruction into protectable program expression any more than translating a programming command into English makes the command copyrightable.

[^71]: ibid paras 39-40.

This principle extends beyond software to all work categories. The *Levola Hengelo* case articulated the broader framework: copyright requires that "only something which is the expression of the author's own intellectual creation may be classified as a 'work'" under the InfoSoc Directive.[^72] The Court noted that "in accordance with the [TRIPS] Agreement...and with the WIPO Copyright Treaty...copyright protection may be granted to expressions, but not to ideas, procedures, methods of operation or mathematical concepts as such."[^73]

[^72]: *Levola Hengelo* (n 11) para 36.

[^73]: ibid para 37.

Copyright's fundamental design requires that ideas remain the common property of all, while monopoly rights attach only to particular expressions of those ideas.

### Data inputs excluded: Sony Datel and the RAM variable analogy

The CJEU's decision in *Sony Computer Entertainment Europe Ltd v Datel Design & Development Ltd* (2024) extends this restrictive approach to data inputs that control program behavior. The Court held that "the content of the variables which are stored temporarily in a console's RAM memory during the playing of a video game does not itself constitute a form of expression of the computer program which is protected by copyright."[^74] Variables stored in RAM — data values that directly affect how the program executes and what outputs it generates — are not protected as program expressions even when they control system operation.[^75]

[^74]: Case C-159/23 *Sony Computer Entertainment Europe Ltd v Datel Design & Development Ltd* EU:C:2024:649, para 33.

[^75]: ibid para 34.

The Court reasoned that treating such data as protected program expression would impermissibly extend copyright to functional elements beyond the program code itself.[^76]

[^76]: ibid para 35.

The parallel to prompts is direct and dispositive.

Prompts function as inputs to AI systems that control how the system processes information and generates outputs — precisely analogous to RAM variables that control video game behavior. RAM variables are data inputs to existing programs. Prompts are textual inputs to existing AI programs. RAM variables control program behavior. Prompts control AI behavior. RAM variables affect outputs generated. Prompts affect outputs generated. RAM variables are not program expressions. Prompts are not program expressions.

If data inputs that directly affect program operation are not protected as program expressions, then textual prompts that control AI operation fall under the same exclusion. Both are functional inputs to existing programs rather than expressions of the programs themselves.

### Application to prompts: the unified framework

The Software Directive and CJEU case law converge on a unified framework excluding prompts from protection through three independent grounds.

First, prompts are interfaces under Article 1(2) and *BSA*. They provide natural language mechanisms for communicating with AI systems, not the systems themselves. Just as GUIs enable visual interaction with software, prompts enable textual interaction with AI programs. The Software Directive expressly excludes interfaces from protection.

Second, prompts specify functionality under *SAS Institute*. They describe what outputs AI should generate, not expressions of how it generates them. Protecting functional specifications would monopolize ideas, precisely what *SAS Institute* prohibits. Programming languages that provide formal methods for instructing computers are unprotectable; natural language prompts that provide informal methods for instructing AI fall under the same exclusion.

Third, prompts are data inputs under *Sony Datel*. They function as textual control parameters for existing programs, not as program expressions. RAM variables controlling game behavior are unprotected; prompts controlling AI behavior receive identical treatment.

Each ground independently suffices to exclude prompts from Software Directive protection. Together, they establish that prompts cannot be protected as computer programs or preparatory design material.

This framework reinforces the general copyright analysis in Parts A through D. Prompts fail as literary works under the InfoSoc Directive through originality failure and identifiability problems. They fail as computer programs under the Software Directive because they are interfaces, functional specifications, and data inputs — all expressly excluded categories.

The failures converge on the same fundamental reason. Prompts are functional instructions — ideas about how to use AI systems, methods of operation, procedures for eliciting outputs — rather than creative expressions warranting monopoly protection.

This is not an oversight or gap in the law. It reflects deliberate policy choices about preserving the public domain of methods of communication with computational systems, functional specifications, and building blocks necessary for competition and cumulative innovation. The Commission's preparatory work for the Software Directive emphasized that copyright's advantage is leaving "latitude to create similar or even identical programs" through independent development.[^77] Extending protection to prompts would eliminate that latitude by monopolizing methods of AI interaction.

[^77]: Commission, 'Proposal for a Council Directive on the legal protection of computer programs' COM(88) 816 final, 8.

### Recipes, operating instructions, and game rules: the functional instruction pattern

Prompts belong to a broader category of functional instructions that copyright doctrine consistently excludes from protection. French courts held in 1974 that cooking recipes "do not in themselves constitute an intellectual work, but rather a savoir-faire" because they are a "succession of instructions, a method."[^78] Copyright may protect creative literary description accompanying recipes — vivid prose, personal anecdotes, evocative explanations — but not the functional list of ingredients or procedural steps, which remain free for all to use.[^79]

[^78]: Cour de Cassation [1974] Bulletin civil IV n° 267.

[^79]: CA Paris 25 February 1974 (Société Albin Michel) [1974] RIDA 161.

The CJEU's *Levola Hengelo* decision reinforced this distinction. Advocate General Wathelet's opinion emphasized that "copyright does not protect the recipe as such (the idea)" because "copyright protection extends to original expressions and not to ideas, procedures, methods of operation."[^80] At paragraph 59, he noted that "it is perfectly legitimate...to use a recipe in order to prepare a dish, and to be inspired by a work in order to create another work."[^81] The parallel to prompts is direct: just as recipes are functional instructions for producing dishes, prompts are functional instructions for producing AI outputs. Protecting the functional instructions themselves — rather than any creative literary expression in which they might be clothed — would monopolize methods and ideas.

[^80]: *Levola Hengelo* (n 11) (Opinion of AG Wathelet) para 40.

[^81]: ibid para 59.

German courts have consistently held that simple operating manuals — "Press button A, then B" — constitute unprotectable procedures, with copyright attaching only to substantial creative expression in the arrangement or explanation of functional information.[^82] The abstract rules of a game constitute unprotectable methods and procedures, though the creative literary expression of those rules in a rulebook may be protected.[^83] Anyone can create a game with identical rules by expressing those rules differently.

[^82]: *Bedienungsanleitung* (n 20).

[^83]: *BSA* (n 44) para 49.

The relevant parallel is to functional specifications in software development. The CJEU held in *SAS Institute* that program specifications — documents describing what software should do, what functions it should perform, and how it should respond to inputs — are not protected as expressions of computer programs.[^84] The functionality described remains unprotectable. Only the creative expression within specification documents — unique phrasing, creative explanations beyond functional necessity — might qualify for protection as literary works separate from the program itself.[^85]

[^84]: *SAS Institute* (n 46) para 45.

[^85]: ibid para 46.

Prompts bear the same relationship to AI systems that specifications bear to software: they describe what the AI should do, what functions it should perform, what constraints it should observe, and what outputs it should generate. The fact that prompts are written in natural language rather than formal specification languages does not alter their functional character. They remain instructions about methods and procedures of operation rather than literary expressions for their own sake.

## F. Software protection: preparatory design material

A final theory under the Software Directive examines whether prompts might qualify as preparatory design material protected under Article 1(1) and Recital 7. Article 1(1) provides that "the term 'computer programs' shall include their preparatory design material."[^86] Recital 7 elaborates that protection extends to "preparatory design work leading to the development of a computer program provided that the nature of the preparatory work is such that a computer program can result from it at a later stage."[^87]

[^86]: Software Directive (n 2) art 1(1).

[^87]: ibid recital 7.

Three arguments might support treating prompts as preparatory design material. First, prompts directly influence AI computational processes — when a user provides a system prompt specifying response parameters, the AI adjusts probability distributions, attention mechanisms, and output generation accordingly. This functional relationship resembles the connection between preparatory design materials and final program code. Second, complex system prompts establishing persistent operational parameters function similarly to configuration files or initialization scripts controlling program behavior. Third, the Software Directive's protective approach — extending copyright to preparatory materials that can lead to programs at later stages — suggests an expansive interpretation that might encompass prompts as preliminary specifications for AI-mediated computation.

Three obstacles defeat this theory.

First, Recital 7 requires that the preparatory work be "such that a computer program can result from it at a later stage."[^88] Prompts do not lead to computer programs. They lead to AI-generated outputs — text, images, analyses. The AI model itself already exists as a complete program. A prompt given to ChatGPT does not generate program code. It generates natural language responses by invoking existing computational processes within pre-trained AI systems. The prompt does not constitute design work for creating the program; it constitutes instructions for using an existing program.

[^88]: ibid.

Second, preparatory design material protected under the Software Directive must possess sufficient technical specificity to constrain program implementation — what academic commentary describes as "quasi-coding" approaching the precision of actual source code.[^89] Flow charts, detailed technical specifications, and architecture documents qualify because they provide sufficiently detailed instructions that programmers can implement them with minimal additional creative choices. Prompts lack this technical specificity. They are high-level natural language instructions that leave implementation entirely to the AI system's existing algorithms. A prompt does not specify how neural networks should process inputs or which mathematical operations should execute — it specifies desired output characteristics in functional terms.

[^89]: Thomas Dreier and Gernot Schulze, *Urheberrechtsgesetz: UrhG Kommentar* (7th edn, C.H. Beck 2022) § 69a Rn. 23–27.

Third, preparatory design material exhibits determinism. The same specifications lead consistently to functionally equivalent implementations. Multiple programmers working from identical pseudocode produce programs that behave equivalently. Prompts submitted to AI systems at different times generate varying outputs due to probabilistic sampling, temperature parameters, and stochastic inference processes.[^90] This non-determinism fundamentally distinguishes prompts from preparatory design materials, which must be sufficiently specified to enable consistent program implementation.

[^90]: Sampaio (n 39).

Prompts do not qualify for protection as preparatory design material under the Software Directive. They do not lead to programs but to outputs generated by existing programs. They lack the technical specificity required for materials constraining program development. They operate probabilistically rather than deterministically.

## G. Policy justifications for functional instruction exclusion

The Software Directive's exclusion of interfaces and functionality from copyright protection reflects deliberate policy choices about preserving interoperability and enabling competition. These policies reinforce the doctrinal analysis excluding prompts from protection.

### Interoperability requires interface freedom

Article 6 of the Software Directive establishes a right to decompile programs to achieve interoperability.[^91] Recital 10 explains that "the main objective of this exception is to make it possible to connect all components of a computer system, including those of different manufacturers, so that they can work together."[^92] This interoperability policy would be undermined if interfaces themselves received copyright protection.

[^91]: Software Directive (n 2) art 6.

[^92]: ibid recital 10.

The Commission's preparatory work emphasized that copyright's comparative advantage over patents is that it leaves "latitude to create similar or even identical programs" through independent development, provided programmers avoid copying expression.[^93] Applied to prompts, protecting them as interfaces would create the barriers to interoperability that Article 6 seeks to prevent. Users must be free to discover which instructions work with particular AI systems and to share that functional knowledge without fear of infringement. If prompts were protected, every effective method of communicating with an AI model would become a potential legal trap for follow-on innovators.

[^93]: Commission, 'Proposal for a Council Directive on the legal protection of computer programs' COM(88) 816 final, 8.

### Decompilation rights and reverse engineering

The CJEU's interpretation of Article 6 in *UsedSoft v Oracle* confirmed that interface information necessary for interoperability must remain accessible even when obtained through reverse engineering.[^94] The Court held that lawful users have broad rights to observe, study, and test software to determine how it functions. Prompts are precisely the kind of interface information that *UsedSoft* reasoning suggests should remain free. When users experiment with AI systems to discover which prompts yield desired results, they engage in the same interface discovery that Article 6 protects in the software context.

[^94]: Case C-128/11 *UsedSoft GmbH v Oracle International Corp* EU:C:2012:407, paras 60–62.

Technical research demonstrates that prompts are readily reverse-engineered from outputs through prompt extraction techniques. These techniques — analyzing output patterns to infer input instructions — constitute lawful reverse engineering under both the Software Directive and Directive 2016/943 on trade secrets. Granting copyright protection to prompts would create legal barriers to reverse engineering that EU policy deliberately avoids.

### Term mismatch and innovation policy

Copyright's 70-year post mortem auctoris term creates perverse incentives when applied to functional instructions. The Copyright Term Directive justifies this extraordinarily long term as necessary to "protect works for two generations after the author's death" given increased human longevity.[^95] This rationale makes sense for creative literary and artistic works whose cultural value persists across generations. It makes no sense for functional instructions that become obsolete as AI models evolve.

[^95]: Copyright Term Directive (n 13) recital 5.

Prompts optimized for GPT-4 may fail entirely on GPT-5. System prompts carefully tuned to one model architecture require complete redesign when architectures change. Applying 70-year monopolies to ephemeral functional content creates structural barriers to AI adoption and iteration. Users would face uncertainty about whether decades-old prompt formulations remain protected, chilling experimentation and the cumulative learning essential to prompt engineering. Copyright's default rules assume valuable works justify long protection to incentivize creation. Functional instructions with six-month useful lives invert that logic.

## H. Scholarly consensus on prompt copyrightability

Academic commentary on prompt copyrightability has converged on the conclusion that prompts likely fail the originality threshold and idea-expression barrier under EU law.

Professor Xiyin He, writing in *GRUR International*, argues that "judicial recognition of text-to-image copyrightability at the current stage is dangerous" because "the practice is not in accordance with our traditional understanding of originality."[^96] He emphasizes that prompts constitute "merely unprotectable ideas" rather than expressions.[^97] The functional nature of prompts — their purpose of instructing AI systems how to generate outputs — places them squarely within the category of methods and procedures excluded from copyright protection under TRIPS Article 9(2) and Software Directive Article 1(2).[^98]

[^96]: Xiyin He, 'Human Authorship and AI-Generated Works: A Chinese Perspective' (2024) 55 IIC 321, 335.

[^97]: ibid 336.

[^98]: ibid.

Professors Daniel Gervais and P Bernt Hugenholtz identify the critical problem: "The hard question is whether those creative choices — the originality, if any — of the prompt is 'transferable' into the product or output of the AI machine. This gets dangerously close to owning the underlying idea, and thus goes against a fundamental principle of international copyright law."[^99] They conclude that "if the originality of the instructions is not sufficiently reflected in the machine's product, there is no protected work in the output. That should be the default position."[^100] Extending copyright protection to prompts would enable monopolization of methods for interacting with AI systems and foreclose the competitive experimentation essential to technological development.[^101]

[^99]: Daniel Gervais and P Bernt Hugenholtz, 'The AI-nundrum: Machines, Learning and Intellectual Property' (Kluwer Copyright Blog, 18 July 2023) <http://copyrightblog.kluweriplaw.com/2023/07/18/the-ai-nundrum-machines-learning-and-intellectual-property> accessed 10 November 2025.

[^100]: ibid.

[^101]: ibid.

Professor João Pedro Quintais and Professor P Bernt Hugenholtz argue that current EU copyright rules are "generally suitable and sufficiently flexible to deal with the challenges posed by AI-assisted output" when properly applied, emphasizing that where subject matter has been dictated by technical considerations leaving no room for creative freedom, originality cannot be found.[^102] Technical constraints inherent in prompt engineering — conforming to AI model requirements, optimizing for effective inference — leave no room for creative freedom of the kind required by the CJEU's originality standard.[^103]

[^102]: João Pedro Quintais and P Bernt Hugenholtz, 'The New Copyright Directive: A Complete (EU) Copyright Codification?' (2020) 51 IIC 28, 45–47.

[^103]: ibid.

Professors Rita Matulionyte and Ana Ramalho observe that prompts function as "instructions for the AI system" and argue that protecting them would "grant exclusive rights over methods of operation," violating the fundamental principle that copyright extends to expression but not to ideas, procedures, or methods.[^104]

[^104]: Rita Matulionyte and Ana Ramalho, 'Artificial Intelligence and Copyright: An EU Perspective' in Jyh-An Lee, Reto M Hilty and Kung-Chung Liu (eds), *Artificial Intelligence & Intellectual Property* (Oxford University Press 2024) 187, 201.

Professor Andres Guadamuz and Ana Sampaio both emphasize the non-deterministic nature of AI systems as a fundamental barrier to treating prompts as protectable preparatory design material. Guadamuz argues that prompts cannot qualify under the Software Directive because they do not "lead to a computer program at a later stage" but rather trigger probabilistic processes that generate variable outputs.[^105] Sampaio articulates the point with precision: "the same prompt to the same model will not deliver the same results," fundamentally distinguishing prompts from preparatory design material, which must be sufficiently precise to enable deterministic program implementation.[^106]

[^105]: Guadamuz (n 38) 12.

[^106]: Sampaio (n 39).

The scholarly literature reinforces the restrictive approach to functional texts established by the CJEU. Where the purpose of text is to convey instructions efficiently and accurately, the range of expression narrows to the point where idea and expression merge. Protecting such text would monopolize the underlying method or procedure in violation of the fundamental principle that copyright extends only to expression, not to ideas, procedures, or methods of operation.

## J. Database protection for prompt collections

While individual prompts fail both ordinary copyright and software protection, collections of prompts raise distinct questions under the Database Directive. The Directive establishes two forms of protection: copyright protection for original databases under Article 3, and a sui generis right protecting investment in databases under Article 7.[^107]

[^107]: Database Directive (n 2) arts 3, 7.

Article 1(2) defines "database" as "a collection of independent works, data or other materials arranged in a systematic or methodical way and individually accessible by electronic or other means."[^108] A collection of prompts clearly satisfies this definition — individual prompts constitute independent textual materials that can be arranged systematically by category, function, or effectiveness and accessed individually in digital repositories.

[^108]: ibid art 1(2).

Database copyright protection requires that "by reason of the selection or arrangement of their contents," databases "constitute the author's own intellectual creation."[^109] The CJEU held in *Football Dataco* that originality demands "free and creative choices" in selection or arrangement that stamp the author's "personal touch" on the database.[^110] Where "the setting up of the database is dictated by technical considerations, rules or constraints which leave no room for creative freedom," the originality requirement fails.[^111]

[^109]: ibid art 3(1).

[^110]: *Football Dataco* (n 5) para 38.

[^111]: ibid para 39.

Applied to prompt collections, this standard proves difficult to satisfy. If prompts are selected based on effectiveness for different tasks — customer service versus creative writing versus technical documentation — the selection principle reflects functional optimization rather than creative choices expressing personality. If prompts are arranged alphabetically, by task type, or by effectiveness metrics, the arrangement follows conventional organizational schemes rather than reflecting creative ability.

The rejection of "sweat of the brow" protection in *Football Dataco* proves dispositive: "the fact that the setting up of the database required...significant labour and skill of its author...cannot as such justify the protection of it by copyright...if that labour and that skill do not express any originality in the selection or arrangement of that data."[^112] Investment in prompt engineering, testing, and optimization does not generate database copyright protection absent creative selection or arrangement principles.

[^112]: ibid para 42.

Even where database copyright might apply to a prompt collection exhibiting genuinely creative selection or arrangement, Article 3(2) expressly provides that "the copyright protection of databases...shall not extend to their contents and shall be without prejudice to any rights subsisting in those contents themselves."[^113] Database copyright protects the structure — creative selection and arrangement — but not the data elements within the collection. Users could extract and reuse individual prompts without infringing database copyright, which protects only against extraction or reuse of substantial portions reflecting the protected selection or arrangement.

[^113]: Database Directive (n 2) art 3(2).

The sui generis right established in Article 7 provides an alternative protection mechanism independent of originality requirements. Article 7(1) grants database makers who demonstrate "qualitatively and/or quantitatively a substantial investment in either the obtaining, verification or presentation of the contents" the right "to prevent extraction and/or re-utilization of the whole or of a substantial part...of the contents of that database."[^114] This protection regime — created precisely because the CJEU's restrictive originality standard left commercially valuable databases unprotected by copyright — might apply to prompt collections involving substantial investment.

[^114]: ibid art 7(1).

The CJEU's interpretation in *British Horseracing Board v William Hill* dramatically narrowed sui generis protection through a critical distinction between investment in creating data versus investment in obtaining existing data.[^115] The Court held that "the resources used to seek out existing independent materials and collect them in the database" qualifies as protected investment, but "not the resources used for the creation of materials which make up the contents of a database."[^116] British Horseracing Board invested £4 million annually in creating horse racing data — determining race dates, creating lists of runners and riders — but the Court ruled this was investment in creating data, not obtaining data, and therefore did not qualify for sui generis protection.[^117]

[^115]: Case C-203/02 *British Horseracing Board Ltd v William Hill Organization Ltd* EU:C:2004:695.

[^116]: ibid para 31.

[^117]: ibid paras 33–34.

This distinction creates a fundamental obstacle for prompt collections. Most prompt engineering involves creating new prompts through iterative testing, trial-and-error refinement, and development of effective formulations. This is investment in creation, not obtaining. Under *British Horseracing Board*, such creative investment does not qualify for sui generis protection. The labour of developing effective prompts, testing variations, and optimizing formulations — the primary source of value in prompt libraries — constitutes creation of data rather than obtaining existing data.

Two narrow pathways might provide sui generis protection. First, investment in "verification" or "presentation" of contents qualifies even where obtaining investment is absent.[^118] If a prompt library maker invests substantially in systematically testing prompts across multiple AI systems, quality control verification, effectiveness validation, and reliability assurance, this verification activity could constitute protected investment. The investment must be documented and substantial — cursory testing is insufficient.

[^118]: Database Directive (n 2) art 7(1).

Second, investment in sophisticated presentation systems — advanced search and categorization frameworks, metadata systems, recommendation algorithms, or technical interfaces requiring substantial resources — might qualify as presentation investment.[^119] The presentation must involve genuine technical sophistication and documented resource expenditure beyond routine database administration.

[^119]: Thomas Aplin and Jennifer Davis, *Intellectual Property Law: Text, Cases, and Materials* (4th edn, Oxford University Press 2020) 374–377.

The practical conclusion for prompt collections is nuanced. Collections where investment primarily focuses on creating original prompts receive no sui generis protection under current CJEU interpretation. Collections where substantial documented investment has been made in systematically collecting prompts created by third parties, in rigorous verification and testing protocols, or in sophisticated presentation systems might qualify. Protection extends only to preventing extraction and reutilization of substantial portions of the collection, not to preventing independent creation or use of individual prompts. The term is fifteen years from completion.[^120]

[^120]: Database Directive (n 2) art 10(1).

This pathway remains narrow and creates perverse incentives — it rewards aggregation over innovation, protecting compilation investment while leaving creative development unprotected. German courts applying corresponding national law have required claimants to quantify investment and demonstrate that extraction would unfairly benefit from that investment.[^121] Most businesses developing prompt libraries focus investment on prompt creation rather than verification of existing prompts, placing them outside the *British Horseracing Board* framework.

[^121]: Matthias Leistner, 'The Protection of Databases' in Ansgar Ohly (ed), *Common Principles of European Intellectual Property Law* (Mohr Siebeck 2012) 139–158.

## K. Counterarguments and rebuttals

The analysis has established multiple grounds for denying copyright protection to prompts. This section examines the strongest affirmative arguments — not to dismiss them superficially but to demonstrate why they fail to overcome the structural barriers identified above.

### Economic incentive argument

Denying copyright protection eliminates incentives to invest in prompt engineering. Developing effective prompts requires substantial time, expertise, and experimentation. Without protection, competitors can freely copy optimized prompts, appropriating the fruits of another's investment and undermining incentives for prompt development. Copyright's purpose is to incentivize creative production through temporary monopolies. Extending that logic to prompts would reward prompt engineering investment.

Three reasons defeat this argument.

First, the CJEU has definitively rejected investment-based protection in *Football Dataco*. The Court held that "the fact that the setting up of the database required...significant labour and skill of its author...cannot as such justify the protection of it by copyright" where creative choices rather than labor determine originality.[^122] EU copyright law deliberately excludes the "sweat of the brow" doctrine. Accepting the economic incentive argument would resurrect investment-based protection the CJEU expressly rejected.

[^122]: *Football Dataco* (n 5) para 42.

Second, alternative protection mechanisms exist and may be more appropriate. Trade secret protection for confidential prompts, contract-based restrictions through NDAs and employment agreements, and technical protection measures can preserve competitive advantages without the 70-year monopoly copyright provides. Trade secrets protect against misappropriation while allowing independent development and reverse engineering — a more balanced incentive framework than copyright's exclusive rights.

Third, the term mismatch demonstrates structural unsuitability. Copyright's 70-year post mortem auctoris term is wildly excessive for functional content with useful lives measured in months. The Copyright Term Directive's rationale — protecting works "for two generations after the author's death" — assumes cultural value persisting across generations.[^123] Functional prompts optimized for specific AI model versions become obsolete as models evolve. Applying multi-generational protection terms to ephemeral functional instructions creates perverse incentives and inappropriate barriers to cumulative innovation.

[^123]: Copyright Term Directive (n 13) recital 5.

### Creative expression argument

Elaborate system prompts exhibit genuine literary creativity warranting copyright protection independent of functional considerations. A 400-word system prompt may employ distinctive phrasing, unique organizational structure, and creative linguistic choices reflecting the author's personality and style. The author selects specific words from among alternatives, chooses particular explanatory approaches, and structures specifications in non-obvious sequences — precisely the "free and creative choices" the CJEU identified as hallmarks of originality in *Painer* and *Football Dataco*. If an 11-word newspaper excerpt can be protected under *Infopaq* when it reflects the author's intellectual creation, surely a 400-word carefully crafted prompt can be protected when it exhibits creative linguistic choices.

This argument conflates linguistic sophistication with creative expression and mischaracterizes the nature of prompts.

First, prompts are instructions about what to produce, not creative works in their own right. The distinction between literary expression and functional instruction proves decisive. *Infopaq* protected newspaper text communicating information through creative journalistic expression, where the journalist exercised creative freedom in word choice, narrative structure, and presentation unconstrained by functional optimization. System prompts make linguistic choices dictated by effectiveness concerns.

The parallel to recipes is exact. French courts protect "creative literary description accompanying recipes" — vivid prose, personal anecdotes, evocative explanations — but not the functional list of ingredients or procedural steps.[^124] The distinction is critical: creative expression in *presenting* functional information may be protected; functional instructions themselves remain free. A prompt specifying "formal tone" rather than "casual tone" reflects functional specification, not literary creativity — analogous to a recipe specifying "medium heat" rather than "high heat."

[^124]: CA Paris 25 February 1974 (n 57).

Second, even creative linguistic choices do not overcome the idea-expression barrier when those choices serve functional purposes. The *Brompton Bicycle* framework confirms that where technical considerations predominate, originality fails even if some creative freedom exists.[^125] Prompt engineering choices — parameter specifications, keyword placement, structural conventions — respond to technical optimization requirements rather than artistic expression. These are skill-based functional decisions, not creative choices expressing personality.

[^125]: *Brompton Bicycle* (n 29) paras 24-25.

Third, the merger doctrine applies where limited ways exist to express particular instructions. Instructing an AI to "use active voice" can be expressed as "employ active voice," "write in active voice," or "prefer active constructions" — functionally equivalent formulations differing only in trivial word choice. Protecting any formulation would monopolize the underlying instruction — precisely what the idea-expression dichotomy forbids.

The Court's analysis in *BSA* applies directly: where "the idea and the expression become indissociable," protection must be denied because "to accept that the functionality...can be protected by copyright would amount to making it possible to monopolise ideas, to the detriment of technological progress and industrial development."[^126]

[^126]: *BSA* (n 44) para 50.

### Complexity threshold argument

While simple prompts like "Summarise" clearly lack originality, sufficiently complex prompts cross the originality threshold by virtue of their length, elaboration, and non-obviousness. Copyright law establishes a low bar — "no aesthetic or qualitative criteria should be applied" per *Cofemel*.[^127] A multi-paragraph system prompt specifying tone, vocabulary, citation formats, rhetorical strategies, prohibited topics, accuracy standards, and refinement protocols surely exceeds the minimal creativity threshold. The author makes numerous choices reflecting personality and creativity even if the overall purpose remains functional.

[^127]: *Cofemel* (n 8) para 30.

This argument conflates quantity with creativity and complexity with originality.

Originality requires "free and creative choices" rather than choices "dictated by technical considerations, rules or constraints which have left no room for creative freedom."[^128] System prompts, no matter how lengthy or detailed, consist of functional specifications responsive to technical requirements for effective AI interaction. The specifications are not arbitrary creative choices but optimized instructions. Their inclusion and formulation reflect functional necessity rather than artistic expression.

[^128]: *Football Dataco* (n 5) para 39.

The analogy to elaborate operating instructions proves instructive. A 400-page user manual for complex machinery involves countless choices about what to explain, how to structure explanations, and what terminology to use, yet German courts hold that routine functional instructions lack originality regardless of length because they respond to functional rather than creative imperatives.[^129] French courts hold that detailed recipes with extensive instructions remain unprotected as "know-how" rather than creative works.[^130]

[^129]: *Bedienungsanleitung* (n 20).

[^130]: Cour de Cassation [1974] (n 56).

Where idea and expression merge — where functional requirements narrow the range of possible expressions — protection must be denied to avoid monopolizing ideas. The *BSA* Court's warning applies: "to accept that the functionality...can be protected by copyright would amount to making it possible to monopolise ideas, to the detriment of technological progress and industrial development."[^131] Length and complexity do not transform functional monopolies into protectable expression.

[^131]: *BSA* (n 44) para 50.

### Technological neutrality argument

Copyright law should not discriminate based on technological context. Literary works receive protection regardless of whether they appear in printed books, digital files, or physical inscriptions. If a 400-word passage describing desired characteristics of written content would be protected when appearing in a writing guide or editorial manual, it should receive the same protection when functioning as a system prompt. Denying protection to prompts while protecting functionally similar text in non-AI contexts creates unprincipled technological distinctions undermining copyright's purpose.

This argument misidentifies the relevant distinction, which concerns function rather than technology.

Copyright law discriminates based on whether text serves creative or functional purposes. Recipes, operating instructions, game rules, and functional specifications receive limited or no protection precisely because they embody methods, procedures, and instructions rather than creative literary expression. The distinction is not between prompts (technological) and other text (non-technological) but between functional instructions (unprotected) and creative expression (protected).

A 400-word passage in a writing guide providing creative advice, insightful analysis, and original perspectives on writing technique might be protected as literary expression. The same passage reformulated as a system prompt specifying AI behavior becomes a set of functional instructions. The technological context matters because it changes the purpose and function of the text — not arbitrarily, but because purpose determines whether text constitutes protectable expression or unprotectable instruction.

French recipe jurisprudence illustrates this precisely. A cookbook's narrative introduction — personal anecdotes, culinary philosophy, evocative descriptions — receives protection as creative literary expression. The recipes themselves — functional lists of ingredients and procedural steps — remain unprotected as methods.[^132] Both appear in the same book, yet function determines protection. A guide to effective writing may be protected as creative exposition, while prompts instructing AI how to write constitute unprotected functional specifications.

[^132]: CA Paris 25 February 1974 (n 57).

Denying prompt protection maintains rather than undermines copyright's principled distinction between ideas, procedures, and methods (unprotected) and expressions (protected). The Software Directive codifies this principle explicitly in Article 1(2)'s exclusion of interfaces — regardless of whether interfaces are visual (GUIs), textual (command-line instructions), or natural language (prompts).

## L. Synthesis: three independent barriers

The analysis reveals three independent and cumulative barriers to prompt copyrightability under EU law. Each alone suffices to defeat protection; together they are dispositive.

**First, originality failure.** Prompts fail to meet the harmonized originality standard because their choices are dictated by functional constraints rather than reflecting free and creative choices expressing the author's personality. The *Brompton Bicycle* framework confirms that even where some creative freedom exists, predominant functional constraint defeats originality.[^133] Prompt engineering choices — parameter specifications, keyword placement, structural conventions — respond to technical optimization requirements rather than artistic expression. National court practice across Member States consistently excludes functional instructions from protection absent substantial creative expression beyond functional necessity.

[^133]: *Brompton Bicycle* (n 29) para 24.

**Second, identifiability failure.** Prompts' non-deterministic nature — the same prompt produces varying outputs across invocations due to probabilistic inference — prevents identification of the claimed "work" with the precision and objectivity *Levola Hengelo* requires.[^134] Enforcement would be impossible when the allegedly protected subject matter yields unpredictable, variable results. This barrier operates independently of originality. Even if prompts exhibited creative choices, their inherent variability would prevent the stable identification copyright demands.

[^134]: *Levola Hengelo* (n 11) para 40.

**Third, idea-expression exclusion.** Prompts constitute instructions about what to create — specifications of ideas, methods, and procedures — rather than expression of creative works. They fall squarely within the categories TRIPS Article 9(2) and the Software Directive Article 1(2) exclude from copyright protection.[^135] The CJEU's decisions in *BSA*, *SAS Institute*, and *Sony Datel* establish that prompts are interfaces, functional specifications, and data inputs — all expressly excluded from protection under both the InfoSoc Directive and the Software Directive.[^136] Protecting prompts would monopolize methods of AI interaction, violating the fundamental principle that copyright extends to expression but not to underlying ideas, procedures, or methods of operation.

[^135]: TRIPS Agreement (n 40) art 9(2); Software Directive (n 2) art 1(2).

[^136]: *BSA* (n 44) para 42; *SAS Institute* (n 46) para 39; *Sony Datel* (n 52) para 33.

Each barrier independently suffices to deny protection. Together they are dispositive. Prompts are quintessential examples of functional instructions that EU copyright law deliberately excludes from protection to preserve the public domain of methods, procedures, and building blocks necessary for innovation and competition.

The convergence is not coincidental. Both the InfoSoc Directive and the Software Directive reflect the same fundamental policy choices. The Commission's preparatory work for the Software Directive emphasized that copyright's comparative advantage is leaving "latitude to create similar or even identical programs" through independent development.[^137] Extending protection to prompts would eliminate that latitude by monopolizing methods of communication with AI systems. Article 6's interoperability provisions and *UsedSoft*'s reverse engineering protections reinforce this policy — interface information must remain free to enable competition and cumulative innovation.[^138]

[^137]: Commission, 'Proposal for a Council Directive' (n 71) 8.

[^138]: *UsedSoft* (n 72) paras 60-62.

The term mismatch underscores the unsuitability of copyright protection for prompts. A 70-year post mortem auctoris term designed to protect cultural works across generations makes no sense for functional instructions that become obsolete within months as AI architectures evolve. Copyright's default rules assume works whose value persists across time. Prompts optimized for GPT-4 may fail entirely on GPT-5. The structural mismatch between copyright's protections and prompts' functional nature confirms that the exclusion reflects deliberate design rather than oversight.

## M. Exceptional cases

Two narrow scenarios might permit limited copyright protection related to prompts, though neither protects the functional instructions themselves.

### Prompts embedded in literary works

Where a prompt is embedded within a larger literary work — a novel, screenplay, or technical treatise — and the prompt exhibits substantial creative literary expression beyond its functional content, that creative embellishment might be protected independently of the functional instructions. French courts have protected creative narrative descriptions accompanying recipes while leaving the functional ingredient lists and procedural steps unprotected.[^139] The same principle applies to prompts: a creative essay about prompt engineering techniques, featuring example prompts enriched with literary commentary, might be protected as a literary work even though the functional prompts themselves remain free for use.

[^139]: CA Paris 25 February 1974 (n 57).

This exception is narrow. Protection extends only to the creative literary expression, not to the functional prompt content. A competitor could extract the functional specifications from the literary work and use them without infringing copyright. The protection guards against verbatim copying of creative prose, not against use of functional instructions the prose describes.

### Prompts as source code modules

Where prompts are hard-coded into computer programs as string constants or configuration parameters, those prompts might receive protection as part of the program's source code under the Software Directive. Article 1(1) protects programs "in any form" including source code.[^140] A prompt embedded as a string literal in Python source code — `system_prompt = "You are a helpful assistant..."` — becomes part of the program's expression.

[^140]: Software Directive (n 2) art 1(1).

This protection remains limited. First, the prompt receives protection only as part of the program, not as an independent work. Extracting the functional content of the prompt — the instructions it conveys — and expressing those instructions differently would not infringe. Article 1(2) excludes ideas and principles underlying program elements from protection.[^141] Second, the protection extends to the specific expression within the source code, not to the functional method the prompt implements. A competitor could achieve identical functionality through different prompt formulations without infringing.

[^141]: ibid art 1(2).

Both exceptions confirm rather than undermine the general rule. Copyright may protect creative literary embellishment accompanying functional instructions or the specific textual expression within protected program source code. The functional instructions themselves — the methods, procedures, and ideas the prompts convey — remain unprotected and free for all to use. This distinction preserves copyright's fundamental balance between incentivizing creative expression and maintaining the public domain of functional methods essential for innovation.

# V. Patent Protection

## A. Patentability Requirements under the European Patent Convention

Patent protection for prompts requires analysis under the European Patent Convention rather than EU directives, as patent law remains governed by the EPC – an international treaty to which all EU Member States are parties – rather than harmonized EU legislation.[^142]

[^142]: Convention on the Grant of European Patents (adopted 5 October 1973, entered into force 7 October 1977, as amended) 1065 UNTS 199 ('EPC').

Article 52(1) EPC establishes the foundational requirement: "European patents shall be granted for any inventions, in all fields of technology, provided that they are new, involve an inventive step and are susceptible of industrial application."[^143] However, Article 52(2) excludes specific categories from patentability, stating that "the following in particular shall not be regarded as inventions": "(a) discoveries, scientific theories and mathematical methods; (b) aesthetic creations; (c) schemes, rules and methods for performing mental acts, playing games or doing business, and programs for computers; (d) presentations of information."[^144]

[^143]: ibid art 52(1).

[^144]: ibid art 52(2).

The qualification in Article 52(3) proves critical: "Paragraph 2 shall exclude the patentability of the subject-matter or activities referred to therein only to the extent to which a European patent application or European patent relates to such subject-matter or activities as such."[^145] This "as such" limitation has driven EPO practice toward allowing patents for computer-implemented inventions that provide technical effects beyond the excluded subject matter itself.

[^145]: ibid art 52(3).

EPO jurisprudence has developed the "technical character" requirement as the threshold for patent eligibility. The landmark Board of Appeal decision in *Computer Program Product/IBM* established that a computer program is not excluded from patentability if "when it is run on a computer, it produces a further technical effect which goes beyond the 'normal' physical interactions between program (software) and computer (hardware)."[^146] Examples of sufficient technical effects include controlling anti-lock braking systems, managing processor load balancing, optimizing memory allocation, and improving digital image processing.[^147]

[^146]: EPO Board of Appeal, T 1173/97 *Computer Program Product/IBM* [1999] OJ EPO 609, para 13.

[^147]: ibid.

The Enlarged Board of Appeal in *Programs for Computers* clarified that technical character requires providing "technical teaching" – instruction on how to solve a technical problem using technical means.[^148] The *Two Identities/COMVIK* decision established that non-technical features making no contribution to technical character cannot support inventive step; they are treated as constraints in formulating the objective technical problem.[^149]

[^148]: EPO Enlarged Board of Appeal, G 3/08 *Programs for Computers* [2011] OJ EPO 10, para 10.4.

[^149]: EPO Board of Appeal, T 641/00 *Two Identities/COMVIK* [2003] OJ EPO 352.

## B. Application to Prompts: Absence of Technical Character

Prompts fail patent protection for three fundamental reasons.

First, prompts constitute excluded subject matter under Article 52(2) EPC. They fall within multiple exclusions simultaneously: methods for performing mental acts (linguistic formulation is cognitive activity), presentations of information (prompts structure how information is requested), and programs for computers as such (prompts direct AI operation through textual instructions).[^150] The natural language formulation does not disguise their essentially excluded character – they remain linguistic constructs communicating intent rather than technical implementations.

[^150]: Martin J Adelman and others, *Cases and Materials on Patent Law* (5th edn, West Academic Publishing 2021) 127–132.

Second, prompts lack technical character within the meaning of EPO jurisprudence. The EPO requires "technical teaching" on how to solve a technical problem using technical means. Prompts do not provide such teaching – they specify what outputs are desired, not how to achieve them technically. The prompt does not control hardware, does not improve computer functioning, and does not process technical data in a technical manner. The AI model processes the prompt using its existing trained weights and algorithms, but the model is separate from the prompt. The prompt is input data, not a technical implementation.

The distinction proves dispositive. A technical problem must relate to a technical field and be solved by technical means producing technical effects. Prompt engineering addresses linguistic and cognitive problems: how to formulate instructions to improve AI output quality, relevance, format, or style. These are content quality issues, not technical problems in the EPO sense. As the Board of Appeal held in *Hitachi*, "an invention which would be obvious to a person skilled in the art using common general knowledge cannot be considered to involve an inventive step merely because a technical effect results when the invention is carried out in a computer."[^151]

[^151]: EPO Board of Appeal, T 0258/03 *Hitachi* [2004] OJ EPO 575, para 5.7.

Third, under the COMVIK approach, prompt innovations would be treated as non-technical constraints. Even if one claims "a computer-implemented method using prompts," the novelty and inventiveness resides in the prompt formulation – linguistic and cognitive choices – not in technical implementation. These non-technical features contribute nothing to inventive step. The technical problem reduces to "implement this linguistic requirement on a computer," which would be obvious to a competent computer scientist. The skilled person, defined as a computer scientist or AI engineer rather than a linguist, would find this obvious.

The parallel to business methods proves instructive. In *Pension Benefit Systems Partnership*, the Board of Appeal held that "features which do not contribute to the technical character of an invention cannot support the presence of an inventive step."[^152] Business method innovations, no matter how clever, cannot render obvious technical implementations non-obvious. Similarly, linguistic innovations in prompt formulation, no matter how sophisticated, cannot render obvious computer processing non-obvious.

[^152]: EPO Board of Appeal, T 0931/95 *Pension Benefit Systems Partnership* [2001] OJ EPO 441, para 6.

## C. Conclusion: Patents as an Unavailable Protection Mechanism

The conclusion is unequivocal: AI prompts cannot receive patent protection under current EPO practice. They constitute excluded subject matter as methods for performing mental acts, presentations of information, and computer programs as such. They lack technical character because they address linguistic and cognitive problems rather than technical problems. They fail to provide technical teaching on how to solve technical problems using technical means. Under the COMVIK approach, their innovative aspects are non-technical features that cannot support inventive step.

Academic commentary confirms this assessment. Professor Andres Guadamuz observes that prompts "are essentially instructions to the AI, much like a search query is an instruction to a search engine" and that "it would be difficult to argue that such instructions possess the technical character necessary for patent protection."[^153] Professor Daniel Gervais notes that "patent protection requires a technical contribution, which prompts – being linguistic formulations – do not provide."[^154]

[^153]: Andres Guadamuz, 'The Monkey Selfie: Copyright Lessons for Originality in Photographs and AI Works' (2018) 5 Internet Policy Review 1, 13.

[^154]: Daniel Gervais, 'Is Intellectual Property Law Ready for Artificial Intelligence?' (2020) 9 GRUR International 117, 123.

Patent law's technical character requirement, appropriate for its purpose of protecting technological innovation, means patents cannot accommodate linguistic or cognitive innovations like prompts regardless of their commercial value. The analysis must therefore turn to trade secrets as the potentially viable protection mechanism for commercially valuable prompts.

# VI. Trade Secrets

## A. The Directive 2016/943 Framework

Copyright, software, database, and patent protections all fail to accommodate prompts' functional character and instructional nature. Trade secrets offer a fundamentally different protection mechanism – one based on secrecy rather than creativity or technical innovation. Directive (EU) 2016/943 on the protection of undisclosed know-how and business information, adopted 8 June 2016 with Member State transposition required by 9 June 2018, harmonizes trade secret protection across the European Union by establishing minimum standards for civil remedies against unlawful acquisition, use, and disclosure.[^155]

[^155]: Directive (EU) 2016/943 of the European Parliament and of the Council of 8 June 2016 on the protection of undisclosed know-how and business information (trade secrets) against their unlawful acquisition, use and disclosure [2016] OJ L157/1 ('Trade Secrets Directive').

The Directive implements the EU's obligations under Article 39 of the TRIPS Agreement, which requires WTO members to protect undisclosed information that is secret, has commercial value because it is secret, and has been subject to reasonable steps to maintain secrecy.[^156] Article 2(1) of Directive 2016/943 defines "trade secret" through a three-part cumulative test requiring that information: "(a) it is secret in the sense that it is not, as a body or in the precise configuration and assembly of its components, generally known among or readily accessible to persons within the circles that normally deal with the kind of information in question; (b) it has commercial value because it is secret; (c) it has been subject to reasonable steps under the circumstances, by the person lawfully in control of the information, to keep it secret."[^157]

[^156]: TRIPS Agreement (n 14) art 39(2).

[^157]: Trade Secrets Directive (n 109) art 2(1).

The definition remained essentially unchanged from the European Commission's November 2013 proposal through final adoption in June 2016, demonstrating consensus that the TRIPS Article 39 formulation provides an appropriate international standard.[^158] The three requirements are cumulative – failure to satisfy any single element defeats trade secret status entirely. Recital 14 emphasizes that the definition "should cover know-how, business information and technological information where there is both a legitimate interest in keeping them confidential and a legitimate expectation that such confidentiality will be preserved."[^159]

[^158]: European Commission, 'Proposal for a Directive on the protection of undisclosed know-how and business information (trade secrets) against their unlawful acquisition, use and disclosure' COM(2013) 813 final.

[^159]: Trade Secrets Directive (n 109) recital 14.

The Directive balances protection against competing policy objectives. Article 1(3) provides that "nothing in this Directive shall be understood to offer any ground for restricting the mobility of employees" and specifically excludes "employees' use of experience and skills honestly acquired in the normal course of their employment."[^160] Article 3 establishes that acquisition of a trade secret is lawful when obtained by "independent discovery or creation," "observation, study, disassembly or testing of a product or object that has been made available to the public or that is lawfully in the possession of the acquirer," reverse engineering, or "any other practice which, under the circumstances, is in conformity with honest commercial practices."[^161]

[^160]: ibid art 1(3).

[^161]: ibid art 3(1).

These exclusions prove critical for prompts. Reverse engineering from AI outputs – reconstructing effective prompts by analyzing generated content – constitutes lawful acquisition under Article 3(1)(b). Independent discovery through parallel prompt engineering experimentation is protected under Article 3(1)(a). The policy framework thus permits competitors to reach similar prompts through their own efforts while prohibiting misappropriation of prompts through unlawful means such as breach of confidentiality agreements, hacking, or inducement of breach of contract.

## B. The Secrecy Requirement and the Cloud Disclosure Paradox

The first element – that information be "secret in the sense that it is not, as a body or in the precise configuration and assembly of its components, generally known among or readily accessible to persons within the circles that normally deal with the kind of information in question" – establishes an objective standard based on accessibility within relevant professional circles.[^162] This requirement confronts AI prompts with a fundamental obstacle: cloud-based AI services require transmitting prompts to third-party providers with each API call or chat interface interaction.

[^162]: ibid art 2(1)(a).

OpenAI's GPT-4, Anthropic's Claude, Google's Gemini, and similar commercial offerings process prompts on the provider's infrastructure. Prompts necessarily travel across networks and reside, at least temporarily, on systems controlled by the AI provider rather than the user. This creates a doctrinal tension: does third-party disclosure destroy the secrecy required for trade secret protection, or can contractual confidentiality provisions with service providers sufficiently preserve secrecy despite physical disclosure?

Academic scholarship examining information flows in cloud computing contexts demonstrates that third-party disclosure potentially destroys trade secret status absent express or implied confidentiality agreements establishing duties not to use or disclose the information.[^163] Sharon K. Sandeen's analysis emphasizes that without contractual protections, information "known outside" the company by a service provider may lack the required secrecy, and the information becomes "readily ascertainable" by the provider who possesses it.[^164]

[^163]: Sharon K. Sandeen and Elizabeth A. Rowe, *Trade Secrecy and International Transactions: Law and Practice* (Edward Elgar 2015) 42–47.

[^164]: ibid 45.

National court decisions across Member States demonstrate strict application of the secrecy requirement in contexts involving third-party disclosure. The German Higher Regional Court of Düsseldorf held in 2021 that disclosure to third parties without executed confidential disclosure agreements can result in loss of trade secret protection.[^165] The court emphasized that vetting partners, ensuring minimum necessary disclosure, and maintaining executed non-disclosure agreements constitute essential reasonable steps.[^166]

[^165]: OLG Düsseldorf 4 November 2021, I-20 U 16/20, ECLI:DE:OLGD:2021:1104.I20U16.20.00.

[^166]: ibid para 47.

The Dutch District Court Middle Netherlands held in August 2018 that technical drawings marked as confidential but shared with third parties without NDAs failed to qualify as trade secrets.[^167] The policy of maintaining secrecy existed, but the practice of unprotected disclosure defeated the claim. The Paris Court of Appeal similarly held in 2022 that sharing technical drawings with third parties without non-disclosure agreements failed both the secrecy element and the reasonable steps test.[^168]

[^167]: Rechtbank Midden-Nederland 15 August 2018, ECLI:NL:RBMNE:2018:3992.

[^168]: CA Paris 9 June 2022, RG n° 19/08167.

The judicial consensus across Germany, France, and the Netherlands establishes a clear principle: third-party disclosure without contractual protections defeats trade secret status regardless of other protective measures the holder may have implemented.

Applied to AI prompts, this doctrine creates a critical distinction between service tiers. Consumer-tier AI services – including free ChatGPT, free Claude.ai, and similar offerings – generally include terms of service permitting the provider to use inputs for model training and service improvement. OpenAI's terms of service for the free tier state that "we may use Content to provide, maintain, develop, and improve our Services," representing contractually authorized use that defeats trade secret status.[^169] Google's terms similarly authorize broad use of user content.[^170] Anthropic's terms for free Claude.ai access permit use "to provide, maintain, and improve our Services."[^171]

[^169]: OpenAI, 'Terms of Use' (14 November 2023) <https://openai.com/policies/terms-of-use> accessed 10 November 2025.

[^170]: Google, 'Google Terms of Service' (5 January 2024) <https://policies.google.com/terms> accessed 10 November 2025.

[^171]: Anthropic, 'Consumer Terms of Service' (22 July 2024) <https://www.anthropic.com/legal/consumer-terms> accessed 10 November 2025.

These terms grant the provider rights to use prompts for training, fundamentally defeating secrecy. Information disclosed to a party with contractual authorization to use it cannot be "secret" within the meaning of Article 2(1)(a). The provider's engineers, researchers, and data scientists who have authorized access to user prompts constitute "persons within the circles that normally deal with the kind of information in question" – they are AI specialists to whom the prompts are "readily accessible."

Enterprise-tier AI services present a different picture. Microsoft Azure OpenAI Service contractually provides that "Customer Data" including prompts "will not be available to other customers" and "will not be used to improve Azure OpenAI or any other Microsoft offering."[^172] Anthropic's Enterprise plan provides that customer data "will not be used for training or improving our models."[^173] Google Cloud's Vertex AI terms provide that customer data "will not be used to improve Google's products or services."[^174]

[^172]: Microsoft, 'Azure OpenAI Service Data, Privacy, and Security' (1 March 2024) <https://learn.microsoft.com/en-us/legal/cognitive-services/openai/data-privacy> accessed 10 November 2025.

[^173]: Anthropic, 'Enterprise Features' <https://www.anthropic.com/enterprise> accessed 10 November 2025.

[^174]: Google Cloud, 'Data Usage FAQ' <https://cloud.google.com/vertex-ai/docs/generative-ai/data-governance> accessed 10 November 2025.

These contractual provisions prohibit the provider from using prompts for any purpose beyond processing the specific customer's requests. The prompts remain disclosed to the provider – they must be, to function – but the disclosure occurs under confidentiality obligations analogous to disclosure to employees under NDAs. Just as disclosing a trade secret to employees bound by confidentiality agreements does not destroy secrecy, disclosing prompts to AI providers bound by contractual confidentiality provisions potentially preserves secrecy.

The German courts' framework supports this distinction. The Higher Regional Court of Düsseldorf's requirement of "executed confidential disclosure agreements" with third parties implies that properly documented contractual protections satisfy the secrecy requirement even where service providers necessarily access the information.[^175] The emphasis is on contractual controls over use and disclosure, not exclusive physical possession.

[^175]: OLG Düsseldorf (n 119) para 47.

The third-party disclosure framework yields a bright-line rule for prompts: only prompts used exclusively through enterprise AI services with robust contractual confidentiality provisions can potentially satisfy the secrecy requirement. Prompts submitted through consumer-tier services without such protections fail Article 2(1)(a) and cannot qualify as trade secrets under EU law.

The rule reflects the structural reality that cloud AI architecture requires third-party disclosure. Trade secret law accommodates such disclosure where contractual safeguards substitute for exclusive physical control. The accommodation is conditional – the contractual protections must be documented, the enterprise service tier must be deliberately selected rather than defaulting to consumer services, and internal controls must ensure employees comply with the requirement to use only protected services.

Businesses maintaining prompt libraries as trade secrets must therefore implement strict policies: prohibit use of consumer AI services for any prompts containing confidential information; require use only of enterprise services with verified contractual confidentiality provisions; document service agreements and maintain evidence of their terms; train employees on the distinction between consumer and enterprise tiers; monitor compliance through technical controls and audit procedures; and enforce violations through disciplinary measures demonstrating that policies are implemented in practice, not merely stated on paper.

## C. Commercial Value Derived from Secrecy

The second element – that information "has commercial value because it is secret" – requires both that information possess commercial value and that this value derive causally from secrecy rather than from other characteristics.[^176] The Commission's Impact Assessment explained that information has commercial value "whether actual or potential" when "its unauthorized acquisition, use or disclosure is likely to harm the interests of the person lawfully controlling it."[^177] The causal link – "because it is secret" – distinguishes trade secrets from other valuable information; information retaining value even if publicly disclosed does not meet this requirement.[^178]

[^176]: Trade Secrets Directive (n 109) art 2(1)(b).

[^177]: European Commission, 'Impact Assessment accompanying the Proposal for a Directive on the protection of undisclosed know-how and business information (trade secrets)' SWD(2013) 471 final, 19.

[^178]: ibid.

AI prompts present a challenge for the commercial value element because their utility depends fundamentally on the underlying large language model they instruct. A prompt engineered for ChatGPT produces value only when processed by OpenAI's GPT-4 or similar models; the same prompt applied to a different architecture may produce inferior results or fail entirely. The dependency raises whether prompts possess independent commercial value or merely derivative value flowing primarily from access to proprietary AI models.

The argument against independent commercial value proceeds from model dependency. The pharmaceutical company example – prompts enabling 60% faster drug candidate identification – produces value only because Claude processes them effectively; Claude's capabilities derive from Anthropic's investment in model development rather than from the user's prompt engineering work. A prompt for a specific AI model is worthless without access to that model. This distinguishes prompts from paradigmatic trade secrets like chemical formulas or manufacturing processes, which have value independent of any third party's proprietary assets. If a prompt's value derives primarily from the model rather than the prompt itself, and if disclosure would not harm the holder's competitive position because competitors lack access to the same model configuration, the commercial value element might fail.[^179]

[^179]: OLG Düsseldorf (n 119) para 52 (holding that unauthorized use must harm holder's competitive position for commercial value requirement to be met).

However, three considerations support finding independent commercial value for sophisticated prompts.

First, commercial prompt marketplaces demonstrate market recognition of prompts as valuable assets independent of any particular user's access to AI models. PromptBase, launched June 2022, reports over 370,000 users and more than 220,000 prompts available for purchase at prices ranging from \$1.99 to \$4.99.[^180] FlowGPT offers millions of prompts with community ratings and verification.[^181] ChatX pays up to 39 CAD per successful prompt submission.[^182] Prompts sold on these platforms derive value from their effectiveness across multiple users, each of whom has independent access to the underlying AI service; the prompt's value thus transcends any single user's model access and resides in the optimized formulation itself.

[^180]: PromptBase, 'About PromptBase' <https://promptbase.com/about> accessed 10 November 2025.

[^181]: FlowGPT, 'Community Prompts' <https://flowgpt.com> accessed 10 November 2025.

[^182]: ChatX, 'Prompt Marketplace' <https://chatx.ai/marketplace> accessed 10 November 2025.

Second, specialized prompts that significantly improve output quality or efficiency provide measurable economic benefits. The pharmaceutical example – 60% faster drug candidate identification – represents quantifiable time savings worth potentially millions of euros in accelerated research. The legal analytics firm example – €2.3 million invested in eighteen months of prompt engineering – demonstrates substantial documented development costs that create economic value competitors could misappropriate by copying rather than independently investing.[^183] German courts require objective proof that information has economic value, considering factors including value to the company, development costs, type of information, and importance to competitive position.[^184] Documented investment in prompt development and quantified performance improvements satisfy this standard.

[^183]: See generally Sharon K. Sandeen, 'The Reasonable Secrecy Requirement' in Rochelle C. Dreyfuss and Katherine J. Strandburg (eds), *The Law and Theory of Trade Secrecy: A Handbook of Contemporary Research* (Edward Elgar 2011) 105, 115–118.

[^184]: OLG Düsseldorf (n 119) para 49.

Third, system prompts embedded in proprietary AI applications – instructions that customize how an AI model behaves within a specific application context – can represent substantial engineering investment and provide differentiation among competing products using the same underlying AI model. The automotive manufacturer example – proprietary system prompts customizing Anthropic's models for supply chain optimization – illustrates prompts as valuable business assets independent of mere model access.

The better view distinguishes between simple prompts that any competent user could develop through brief experimentation and sophisticated prompts representing substantial investment in development, testing, and refinement. The distinction parallels established trade secret doctrine protecting customer lists: publicly available contact information does not qualify as a trade secret, but a curated compilation of customers derived from substantial effort, investment, and analysis qualifies as a protectable compilation with commercial value deriving from the compilation itself rather than individual data points.[^185] Similarly, individual prompting techniques may be publicly known, but a refined prompt representing months of optimization, A/B testing, and fine-tuning constitutes a valuable compilation whose "precise configuration and assembly" – Article 2(1)(a)'s language – has commercial value because competitors lack this optimized formulation.

[^185]: Case C-30/14 *Ryanair Ltd v PR Aviation BV* EU:C:2015:10, para 29 (addressing database compilations); applied by analogy to trade secret compilations.

The causal link – "because it is secret" – requires that disclosure would harm the holder's competitive advantage. For AI prompts, this test distinguishes between prompts whose disclosure would enable competitors to immediately replicate valuable outputs and prompts providing minimal competitive benefit. Prompts that codify novel applications, combine techniques in non-obvious ways, or represent substantial optimization work satisfy this requirement because their disclosure allows competitors to appropriate the results of investment without incurring equivalent development costs. Prompts that merely implement widely known techniques or achieve results competitors have independently achieved fail this test – the value does not derive from secrecy because disclosure provides no competitive advantage.

The commercial value element therefore operates as a filter, excluding trivial or widely known prompts while potentially protecting sophisticated prompts representing substantial investment and providing genuine competitive advantages to their holders.

## D. Reasonable Steps under the Circumstances

The third element – that information "has been subject to reasonable steps under the circumstances, by the person lawfully in control of the information, to keep it secret" – requires trade secret holders to exercise what Recital 13 characterizes as a "duty of care as regards the preservation of the confidentiality of their valuable trade secrets."[^186] The "under the circumstances" qualifier establishes that the requirement is context-specific and proportionate, not absolute.[^187]

[^186]: Trade Secrets Directive (n 109) recital 13.

[^187]: European Commission, 'Impact Assessment' (n 131) 21–22.

National courts have developed detailed frameworks for assessing reasonable steps under their implementations of Directive 2016/943. German courts apply the Geschäftsgeheimnisgesetz through a comprehensive three-level framework requiring measures at legal, organizational, and technical levels.[^188] Legal measures include non-disclosure agreements with employees, confidentiality provisions in employment contracts, and contractual restrictions with business partners. Organizational measures include access restrictions, need-to-know policies, classification systems identifying confidential information, employee training on confidentiality obligations, and exit procedures for departing employees. Technical measures include passwords, encryption, access controls, authentication systems, and monitoring for unauthorized access.[^189]

[^188]: Case C-203/22 *Dun & Bradstreet Austria GmbH v Bundeswettbewerbsbehörde* EU:C:2025:144.

[^189]: ibid para 53.

The Higher Regional Court of Düsseldorf established nine factors for proportionality assessment: type of trade secret, specific circumstances of use, value and development costs, nature of information, importance to company, size of company, usual confidentiality measures in the company, type of labeling or marking, and contractual provisions with employees and partners.[^190] This framework emphasizes proportionality – small and medium enterprises need not implement the same expensive security measures as large corporations, but measures must be reasonable given the information's value and the circumstances of its use.

[^190]: ibid paras 58–60.

French courts applying Code de Commerce provisions implementing the Directive emphasize that measures must be specific and targeted rather than blanket designations.[^191] Generic "all information confidential" declarations in employment contracts are insufficient; holders must specifically identify and mark confidential information, document protection measures taken, and implement both technical restrictions and contractual protections.[^192] The Paris Court of Appeal's decisions require demonstrable, implemented protection rather than merely stated policies.[^193]

[^191]: EUIPO, 'Trade Secrets Litigation Trends in the European Union' (2023) 47–49 (noting developments needed to clarify trade secrets role in data economy and algorithmic transparency contexts).

[^192]: OLG Düsseldorf (n 119) para 47 (requiring "executed confidential disclosure agreements" with third parties).

[^193]: European Commission, 'Impact Assessment' (n 131) 19 (explaining commercial value requires that unauthorized acquisition, use, or disclosure would harm holder's interests).

Dutch courts apply the Wet bescherming bedrijfsgeheimen with particular strictness, exemplified in the pithy formulation that "policy without practice fails the reasonable steps test."[^194] Stated confidentiality policies that employees routinely violate without consequence demonstrate that reasonable steps have not been taken in practice, regardless of written policies. This approach focuses on actual implementation and enforcement rather than formal documentation.

[^194]: Rechtbank Midden-Nederland (n 121).

Applied to AI prompts, these requirements create significant challenges because the fundamental architecture of cloud AI services requires transmitting prompts across networks to third-party providers. The legal analytics firm maintaining NDAs, restricting internal access, and encrypting its prompt library satisfied legal and organizational measures but necessarily transmitted prompts to OpenAI's servers thousands of times daily. The pharmaceutical company's scientists using consumer ChatGPT accounts clearly failed by disclosing prompts without contractual safeguards. The automotive manufacturer storing prompts in encrypted files accessible to only three senior engineers potentially satisfied reasonable steps if, and only if, using Anthropic's enterprise service with contractual confidentiality protections.

The decisive question is whether use of enterprise AI services with contractual confidentiality provisions, combined with internal controls, constitutes "reasonable steps under the circumstances" or whether transmitting prompts to third-party servers fundamentally defeats the requirement. National court guidance on third-party service providers suggests that contractual confidentiality provisions can suffice. The German courts' emphasis on "executed confidential disclosure agreements" implies that properly documented contractual protections with service providers satisfy reasonable steps even though the provider necessarily accesses the information.[^195]

[^195]: As of November 2025, no CJEU preliminary ruling under TFEU art 267 has addressed core definitional questions under Directive 2016/943 regarding algorithmic or computational information.

However, cloud AI services present a structural challenge distinct from traditional third-party relationships. Trade secret law developed in contexts where holders could maintain physical or exclusive digital control over secret information – formulas in locked laboratories, customer lists on access-controlled servers. Cloud AI inverts this model by requiring disclosure to third parties as a condition of using the information at all. The prompt cannot function without transmission to the AI provider's infrastructure; there is no equivalent to maintaining a chemical formula in a secured laboratory while using it in-house.

The resolution depends on whether contractual protections can substitute for exclusive physical control. German courts' proportionality framework suggests they can: the nine-factor test includes "specific circumstances of use" as a factor, indicating that if information's use necessarily requires third-party involvement, reasonable steps must be assessed relative to that constraint rather than requiring impossible exclusive control.[^196] The approach recognizes that in some contexts – cloud computing, outsourced manufacturing, collaborative research – third-party involvement is inherent to using the information, and contractual protections combined with internal controls can satisfy the reasonable steps requirement.

[^196]: Regulation (EU) 2024/1689 of the European Parliament and of the Council of 13 June 2024 laying down harmonised rules on artificial intelligence [2024] OJ L184/1 ('AI Act') arts 11–13, 53.

For AI prompts, reasonable steps therefore require a comprehensive protection program acknowledging the necessity of third-party disclosure while minimizing associated risks:

Legal measures: use exclusively enterprise AI services with documented contractual confidentiality protections; execute non-disclosure agreements with employees and contractors; include confidentiality provisions in employment contracts specifically identifying prompts as confidential; maintain agreements with AI service providers and document their confidentiality terms.

Organizational measures: implement access controls limiting which employees can create and submit prompts; establish classification systems identifying which prompts contain trade secret information; provide employee training on proper use of AI services and the distinction between consumer and enterprise tiers; institute monitoring and audit procedures detecting unauthorized disclosure; establish incident response plans addressing breaches; enforce policies through disciplinary action demonstrating implementation in practice.

Technical measures: encrypt prompts in transit and at rest; implement authentication systems controlling prompt access; sanitize prompts to remove unnecessary sensitive information before submission; monitor AI service usage for compliance; maintain audit logs of prompt submissions; establish technical controls preventing use of consumer AI services on company devices.

This comprehensive framework parallels protections German courts require for traditional trade secrets but adapted to accommodate cloud AI's distributed architecture. The requirement is straightforward doctrinally – reasonable steps must be "under the circumstances," and the circumstances of AI prompt use include technical necessity of third-party processing – but demanding practically, requiring substantial investment in legal, organizational, and technical infrastructure.

The conclusion is that contractual protections with enterprise AI providers, combined with rigorous internal controls, can satisfy Article 2(1)(c)'s reasonable steps requirement. However, the accommodation is conditional and demanding. Businesses must document enterprise service agreements, implement comprehensive internal protection measures, train employees, monitor compliance, and enforce violations. The Dutch principle – "policy without practice fails" – requires demonstrating that stated protections are implemented and enforced in reality, not merely documented on paper.

## E. Synthesis: conditional protection under enterprise frameworks

The CJEU's decision in *Dun & Bradstreet Austria GmbH v Bundeswettbewerbsbehörde* provides authoritative guidance on whether algorithmic information can qualify for trade secret protection under Directive 2016/943.[^197] The Court addressed whether trade secret claims can justify withholding information about automated decision-making logic from data subjects under GDPR transparency obligations. The Court held that controllers must provide "meaningful information about the logic involved" to data subjects, but need not disclose algorithms themselves where doing so would reveal trade secrets.[^198] Austrian law creating a blanket exemption for trade secrets was impermissible; instead, controllers claiming trade secret protection must provide allegedly protected information to supervisory authorities or courts for case-by-case proportionality assessment balancing commercial confidentiality against transparency rights.[^199]

[^197]: Case C-203/22 *Dun & Bradstreet Austria GmbH v Bundeswettbewerbsbehörde* EU:C:2025:144.

[^198]: ibid para 53.

[^199]: ibid paras 58–60.

*Dun & Bradstreet* confirms two principles relevant to prompts. First, algorithmic information – including logical instructions controlling AI system behavior – can in principle qualify as trade secrets; the Court did not categorically exclude computational instructions from protection. Second, trade secret protection is not absolute and must yield to competing fundamental rights and regulatory transparency where proportionality requires. Businesses cannot invoke trade secrecy to avoid disclosure obligations under the GDPR, the AI Act, or sector-specific regulations where transparency outweighs commercial confidentiality.[^200]

[^200]: EUIPO, 'Trade Secrets Litigation Trends in the European Union' (2023) 47–49 (noting developments needed to clarify trade secrets role in data economy and algorithmic transparency contexts).

Applied to prompts, this framework yields a qualified answer. Prompts can qualify as trade secrets, but only sophisticated prompts subjected to rigorous protection measures, and even then subject to potential displacement by regulatory transparency requirements.

The three cumulative requirements create distinct barriers. Under Article 2(1)(a)'s secrecy element, prompts submitted through consumer-tier AI services fail because terms of service authorize provider use for training, defeating the requirement that information be "not readily accessible" to specialists in the field. Only prompts used exclusively through enterprise AI services with contractual prohibitions on provider use or disclosure can potentially satisfy secrecy – the third-party disclosure is unavoidable given cloud architecture, but contractual protections function analogously to employee NDAs in preserving information as "not generally known."[^201]

[^201]: OLG Düsseldorf (n 119) para 47 (requiring "executed confidential disclosure agreements" with third parties).

Under Article 2(1)(b)'s commercial value element, simple prompts that any competent user could develop through brief experimentation fail because they lack the economic value required for protection. Sophisticated prompts representing substantial documented investment – months of optimization, quantified performance improvements, integration into proprietary systems – satisfy this requirement because their disclosure would enable competitors to appropriate development results without incurring equivalent costs. The causal link – "because it is secret" – requires that disclosure would harm competitive position, distinguishing valuable prompt compilations from widely known techniques.[^202]

[^202]: European Commission, 'Impact Assessment' (n 131) 19 (explaining commercial value requires that unauthorized acquisition, use, or disclosure would harm holder's interests).

Under Article 2(1)(c)'s reasonable steps element, cloud AI's distributed architecture creates structural tension. Trade secret law developed assuming holders could maintain exclusive physical or digital control; cloud AI inverts this by requiring third-party disclosure as a condition of use. However, the "under the circumstances" qualifier establishes context-specific proportionality rather than absolute control. Enterprise service agreements prohibiting provider use or disclosure, combined with comprehensive internal measures – access controls, encryption, classification systems, employee training, monitoring, enforcement – can satisfy this requirement. The Dutch principle that "policy without practice fails" demands demonstrable implementation, not merely formal documentation.[^203]

[^203]: Rechtbank Midden-Nederland (n 121).

These three requirements interact to exclude most prompts while potentially protecting a narrow category. Simple prompts fail all three elements. Intermediate prompts representing modest optimization face challenges under reasonable steps proportionality – protective measures may exceed value. Sophisticated prompts representing substantial investment can qualify if, and only if, used exclusively through enterprise services with documented contractual protections and subject to comprehensive internal controls.

The resolution faces unresolved tensions requiring CJEU clarification or legislative guidance. No preliminary ruling has directly interpreted Directive 2016/943's three-part test for algorithmic information. National courts have developed divergent approaches – Germany's nine-factor proportionality framework differs from the Netherlands' stringent practice requirement and France's procedural protections. Cross-border uncertainty will persist until the CJEU addresses whether third-party disclosure with contractual safeguards satisfies secrecy and reasonable steps requirements.[^204]

[^204]: As of November 2025, no CJEU preliminary ruling under TFEU art 267 has addressed core definitional questions under Directive 2016/943 regarding algorithmic or computational information.

More fundamentally, the intersection between trade secret protection and AI transparency requirements under the AI Act remains incompletely theorized. The AI Act imposes transparency obligations on high-risk AI systems including technical documentation, training data disclosure, and deployment logs.[^205] Recital 75 acknowledges that trade secret information "should be safeguarded" but provides no detailed operational guidance on balancing commercial confidentiality against regulatory transparency.[^206] *Dun & Bradstreet* establishes the framework – case-by-case balancing by authorities or courts – but implementing this for AI Act compliance will require either Commission guidance or judicial decisions establishing when transparency obligations override trade secret protection.

[^205]: Regulation (EU) 2024/1689 of the European Parliament and of the Council of 13 June 2024 laying down harmonised rules on artificial intelligence [2024] OJ L184/1 ('AI Act') arts 11–13, 53.

[^206]: Trade Secrets Directive (n 109) art 3(1)(b).

AI prompts can qualify as trade secrets under current EU law. The qualification is conditional – requiring sophisticated prompts, enterprise service frameworks, rigorous protective measures, and acceptance that regulatory transparency may require disclosure where fundamental rights or public interest outweigh commercial confidentiality. Trade secret protection for prompts exists doctrinally, but it is demanding, contested, and ultimately provisional pending authoritative interpretation.

## E. Synthesis: When Prompts Qualify as Trade Secrets

The analysis of Directive 2016/943's three-part cumulative test establishes that AI prompts can potentially qualify as trade secrets under EU law, but only under narrow and demanding conditions. The framework requires satisfying all three elements simultaneously – failure on any single element defeats protection entirely.

**Simple prompts categorically fail trade secret protection.** Basic instructions like "Summarize this text" or "Write a marketing email" do not meet the secrecy requirement because they are generally known among AI users; they lack commercial value because any competent user can develop them through minimal experimentation; and they cannot justify the substantial protective measures required for reasonable steps given their minimal value. These prompts resemble individual publicly available facts – they may have utility, but they do not constitute protectable information under trade secret law.

**Intermediate prompts representing modest optimization face significant obstacles.** Domain-specific queries, tested formulations that improve reliability, or structured templates that standardize outputs might satisfy the commercial value element if they represent genuine efficiency improvements. However, they face challenges under the secrecy element if widely shared within professional communities, and they struggle under the reasonable steps requirement because the investment required to protect them through comprehensive legal, organizational, and technical measures may exceed their value, failing the proportionality test. Moreover, the high probability of independent discovery for intermediate prompts – any competent practitioner working in the same domain will likely develop similar approaches through parallel experimentation – undermines claims that value derives from secrecy rather than from general domain expertise.

**Sophisticated prompts representing substantial investment can potentially qualify as trade secrets if subjected to rigorous protection measures.** These prompts must satisfy four cumulative conditions:

First, **exclusive use through enterprise AI services** with documented contractual confidentiality provisions. Consumer-tier services with terms permitting training use categorically defeat the secrecy requirement. Enterprise agreements must contractually prohibit the provider from using prompts for model training, from disclosing prompts to other customers, and from accessing prompts except as necessary to process the specific user's requests. The agreements must be documented, maintained, and periodically reviewed to ensure continued compliance.

Second, **substantial documented investment** in prompt development creating quantifiable economic benefits. This includes documented development costs (specialist salaries, testing expenses, computational resources), quantified performance improvements (efficiency gains, quality metrics, competitive advantages), and evidence that competitors could misappropriate these benefits by copying rather than independently investing. German courts' emphasis on objective proof of economic value requires documentation beyond mere assertions of worth.

Third, **comprehensive internal protection measures** spanning legal, organizational, and technical domains. Legal measures must include non-disclosure agreements with employees and contractors, employment contract provisions specifically identifying prompts as confidential, and documented agreements with AI service providers. Organizational measures must include access controls limiting who can create and submit prompts, classification systems identifying trade secret prompts, employee training on proper AI service use, monitoring and audit procedures, incident response plans, and enforcement through disciplinary action. Technical measures must include encryption in transit and at rest, authentication systems, prompt sanitization, usage monitoring, audit logging, and controls preventing consumer service use. The Dutch "policy without practice fails" principle requires demonstrating actual implementation and enforcement, not merely written policies.

Fourth, **limited disclosure scope** minimizing the risk that prompts become "readily accessible" through reconstruction or observation. Prompts whose effectiveness can be easily reverse-engineered from publicly available outputs face substantial risk that the secrecy element will fail because competitors can lawfully reconstruct them through observation and testing under Article 3(1)(b). Prompts used in contexts where outputs are publicly visible must be evaluated for whether skilled competitors could reconstruct similar prompts through analysis – if reconstruction is feasible, secrecy may be defeated regardless of internal protective measures.

The practical reality is that **trade secret protection for AI prompts is feasible but fragile**. Protection exists in principle but requires continuous vigilance, substantial investment in protection infrastructure, and acceptance that protection remains provisional. Three structural vulnerabilities limit trade secret protection's effectiveness for prompts.

First, **the reverse engineering vulnerability**. Article 3(1)(b) explicitly permits acquisition through "observation, study, disassembly or testing of a product or object that has been made available to the public."[^207] Academic research demonstrates that prompts can be reconstructed from analyzing AI outputs, and this reconstruction constitutes lawful acquisition that trade secret law cannot prevent. Businesses relying on trade secret protection must accept that competitors engaging in systematic reverse engineering commit no violation.

[^207]: Trade Secrets Directive (n 109) art 3(1)(b).

Second, **the independent discovery vulnerability**. Article 3(1)(a) protects "independent discovery or creation" as lawful acquisition.[^208] Prompt engineering requires no specialized equipment, substantial capital investment, or rare expertise. The barrier to independent discovery is relatively low compared to paradigmatic trade secrets like chemical formulas or manufacturing processes. Businesses must accept that competitors may independently develop similar or functionally equivalent prompts through parallel experimentation, and such independent development defeats any trade secret claim regardless of the holder's investment.

[^208]: ibid art 3(1)(a).

Third, **the employee mobility tension**. Article 1(3) emphasizes that trade secret protection "should not offer any ground for restricting the mobility of employees" and explicitly protects "employees' use of experience and skills honestly acquired in the normal course of their employment."[^209] When employees develop prompt engineering expertise while working for one company, they retain the right to use that general skill at subsequent employers. The boundary between protectable specific prompts and unprotectable general prompt engineering skills remains unclear and fact-intensive. Former employees arguing they merely applied general skills rather than copied specific prompts present difficult cases that may require litigation to resolve.

[^209]: ibid art 1(3); recital 13.

These three vulnerabilities mean that trade secret protection for prompts provides weaker and more contingent protection than for traditional trade secrets like chemical formulas or customer lists. The protection is real but limited – it prevents misappropriation through unlawful means (breach of confidentiality agreements, hacking, inducement of breach) but cannot prevent acquisition through lawful means (reverse engineering, independent discovery, employee mobility with general skills).

**The Court of Justice has not yet addressed these issues.** Directive 2016/943 entered into force in June 2016 with Member State transposition required by June 2018, but as of November 2025, no CJEU preliminary ruling under Article 267 TFEU has interpreted the Directive's core provisions as applied to AI prompts or cloud computing contexts. The analysis above synthesizes national court decisions from Germany, France, and the Netherlands applying their respective implementations, but these decisions may diverge in emphasis and application. Cross-border uncertainty persists until the CJEU provides authoritative interpretation.[^210]

[^210]: EUIPO, 'Trade Secrets Litigation Trends in the EU Member States' (2023) 47–52 (documenting divergent national approaches to reasonable steps assessment).

The regulatory landscape adds further complexity. The AI Act imposes transparency obligations on high-risk AI systems including technical documentation, training data disclosure, and deployment logging.[^211] These transparency requirements may conflict with trade secret confidentiality, requiring case-by-case balancing. The CJEU's decision in *Dun & Bradstreet Austria* established that trade secret protection can justify withholding algorithmic information from data subjects but not from supervisory authorities or courts conducting proportionality assessments.[^212] This framework – acknowledging trade secret protection while requiring disclosure where fundamental rights or regulatory transparency obligations outweigh commercial confidentiality – will likely govern conflicts between prompt trade secrets and AI Act transparency requirements.

[^211]: Regulation (EU) 2024/1689 of the European Parliament and of the Council of 13 June 2024 laying down harmonised rules on artificial intelligence [2024] OJ L184/1 ('AI Act'), arts 11–13, 53.

[^212]: Case C-203/22 *CK and Dun & Bradstreet Austria GmbH* EU:C:2024:173, paras 55–62.

**Practical guidance for businesses** seeking to protect prompt engineering work through trade secrets requires implementing the comprehensive framework described above while accepting its limitations. Use exclusively enterprise AI services with verified contractual confidentiality provisions; prohibit consumer service use for any confidential prompts; document all service agreements and maintain evidence of confidentiality terms; implement access controls, classification systems, employee training, and monitoring procedures; encrypt prompts in transit and at rest; sanitize prompts to remove unnecessary sensitive information; maintain audit logs; enforce violations through disciplinary action demonstrating implementation in practice; accept that reverse engineering and independent discovery remain lawful and cannot be prevented; prepare for potential conflicts with transparency requirements under the GDPR, AI Act, or other regulatory frameworks; and recognize that trade secret protection, while real, provides weaker and more contingent protection than copyright or patent monopolies.

Trade secrets represent the most viable intellectual property protection mechanism for AI prompts under current EU law, but the protection is conditional, demanding, and ultimately provisional. It exists for sophisticated prompts subjected to rigorous protection measures, but even then remains vulnerable to lawful acquisition through reverse engineering, independent discovery, and employee mobility. The legal framework accommodates prompt protection within existing doctrine, but businesses must invest substantially in protection infrastructure and accept substantial residual risk that protection will prove inadequate in contested cases.

