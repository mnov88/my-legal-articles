# Does EU law protect AI prompts as intellectual property?

## I. Introduction

A startup legal technology company spends eight months developing sophisticated prompts for contract review—prompts that reduce analysis time by 60 percent and catch drafting errors human reviewers routinely miss. Three weeks after the founder demonstrates the system at an industry conference, a competitor releases a near-identical service with suspiciously similar prompt formulations. A prompt engineer accepts a position at a rival firm; her former employer sends a cease-and-desist letter claiming that the prompts she developed—textual instructions stored in her memory—constitute trade secrets and cannot be used in her new role. On PromptBase, functionally identical prompts for generating marketing copy sell for €1.99 and €4.99 respectively, the price difference reflecting nothing more than seller reputation and marketplace positioning.

The question this Article asks is whether any of these situations—ranging from straightforward competitive copying to threatened litigation over employee mobility—merit legal protection under European Union intellectual property law. The inquiry matters because generative AI has created a novel category of potentially protectable subject matter where commercial marketplaces report substantial transaction volumes, professional roles command significant compensation, and businesses invest considerable resources in development—yet the legal status remains uncertain.

This Article examines prompt protectability under four EU intellectual property frameworks: copyright law, software and database protection, patent law, and trade secrets. The answer is negative across frameworks. Copyright fails because prompts constitute instructions about what to create—functional directions rather than creative expression. Software protection fails because prompts are not programs but rather inputs to programs, falling outside the scope of Directive 2009/24/EC. Patent protection is unavailable because prompts lack the technical character the European Patent Office requires, constituting excluded subject matter under Article 52(2) EPC. Trade secrets offer the only viable—though fragile and conditional—protection pathway, applicable solely to sophisticated prompts maintained under rigorous confidentiality within enterprise architectures.

The structure proceeds systematically. Part II establishes the economic rationales justifying protection consideration, marshalling empirical evidence of marketplace activity, labor market valuations, and productivity gains—while highlighting conspicuous absences in licensing markets, litigation, and regulatory recognition that undermine claims for robust protection. Part III examines copyright and software protection together, demonstrating that both fail for fundamentally similar reasons: prompts are functional instructions explicitly excluded from protection under the idea-expression dichotomy. Part IV addresses patent protection, showing that prompts constitute non-technical subject matter incapable of satisfying the European Patent Convention's requirements. Part V analyzes trade secrets protection, identifying narrow circumstances under which sophisticated prompts subjected to comprehensive protective measures might qualify. Part VI synthesizes these findings, crystallizing the mismatch between traditional IP categories and prompts' functional characteristics. Part VII concludes by situating this restrictive approach within broader IP policy—not all valuable information requires or should receive legal protection.

The fundamental finding is straightforward: EU intellectual property law systematically excludes functional instructions, methods, and ideas from protection—prompts are quintessential examples of such excluded subject matter. This exclusion reflects deliberate policy choices about preserving the public domain of building blocks necessary for competition and innovation. To that extent, the current legal framework's restrictive treatment of prompts is a feature, not a defect.

## II. Economic rationales for protection: evidence and conspicuous absences

Before examining doctrinal barriers, the threshold question is whether prompts warrant protection consideration at all. Four categories of evidence could substantiate economic value sufficient to justify legal intervention: marketplace transactions revealing price discovery through willing buyer-seller exchanges; labor market valuations expressed through professional compensation; productivity measurements quantifying efficiency gains attributable to prompt engineering; and licensing or litigation activity demonstrating that market participants perceive prompts as high-value proprietary assets. This Part demonstrates that while the first three categories provide evidence of positive economic value, the fourth category reveals conspicuous absences that fundamentally undermine claims for robust IP protection. Put differently, prompts have value—but not necessarily the characteristics that justify property rights.

### Marketplace evidence: commodification and fragility

The most direct evidence emerges from platforms where prompts trade as discrete commodities. PromptBase, launched in June 2022, represents the earliest documented example of prompt commodification.[^1] By September 2025, the platform claimed more than 370,000 registered users and a library exceeding 220,000 prompts, with over 24,000 five-star reviews indicating sustained commercial activity.[^2] Listed prices range from €1.99 to €4.99, with PromptBase extracting a 20 percent commission on transactions.[^3] To that extent, the platform demonstrates that buyers perceive value worthy of payment—prompts command positive prices in functioning marketplaces.

[^1]: TechCrunch, 'PromptBase Marketplace Launches for DALL-E Prompts' (28 July 2022) <https://techcrunch.com/2022/07/28/promptbase-marketplace-launches-for-dall-e-prompts> accessed 15 October 2024.

[^2]: Skywork AI, 'PromptBase User Statistics' (September 2025) <https://skywork.ai/promptbase-statistics> accessed 15 October 2024.

[^3]: PromptBase, 'About' <https://promptbase.com/about> accessed 15 October 2024.

However, economic significance remains severely constrained. PromptBase imposes a €4.99 price ceiling for new sellers until they establish sales records—a quality control measure that simultaneously limits revenue potential and signals market mistrust of unproven prompt value.[^4] The platform's €30 minimum payout threshold indicates relatively modest individual earnings.[^5] Moreover, competing platforms emerged with fundamentally different business models; PromptHero offers millions of prompts without monetization features, functioning as a free repository supported by advertising.[^6] This bifurcation between paid and free prompt marketplaces considerably complicates value assessment. If comparable prompts circulate freely, the economic moat protecting paid prompts narrows to near-imperceptibility. To that extent, the marketplace evidence establishes baseline economic value but simultaneously reveals structural fragility—single-digit dollar valuations suggest commoditization pressure rather than substantial intellectual property premiums.

[^4]: ibid (seller guidelines).

[^5]: ibid (payout policy).

[^6]: PromptHero <https://prompthero.com> accessed 15 October 2024.

### Labor market signals: skill valuation versus asset valuation

If prompts themselves command only modest direct prices, the skills required to engineer them may demonstrate higher economic value through labor market compensation. The numbers are substantial. Glassdoor data current as of August 2025 reports average annual base salary for prompt engineers in the United States at $123,803, with a typical range between $96,661 at the 25th percentile and $160,352 at the 75th percentile.[^7] Coursera, analyzing the same dataset, reported a median of $136,141 with additional compensation between $35,000 and $66,000 annually—pushing total compensation toward $200,000 for top earners in major technology hubs.[^8] The upper bound attracts disproportionate attention; Anthropic advertised a "Prompt Engineer and Librarian" position in San Francisco with compensation capped at $335,000 annually, though this figure represents a geographic anomaly in the most expensive technology labor market globally and conflates prompt engineering with research librarianship and institutional knowledge management.[^9]

[^7]: Glassdoor, 'Prompt Engineer Salaries' (August 2025) <https://www.glassdoor.com/Salaries/prompt-engineer-salary> accessed 15 October 2024.

[^8]: Coursera, 'How to Become a Prompt Engineer' (February 2025) <https://www.coursera.org/articles/prompt-engineer> accessed 15 October 2024.

[^9]: Market.us, 'Prompt Engineering Salaries' (2024) <https://market.us/prompt-engineering-salaries> accessed 15 October 2024.

The labor market data establishes that prompt engineering commands professional-tier compensation comparable to software development and data science. However—and this distinction proves critical—the evidence measures human capital value rather than prompt intellectual property value. Salaries reflect demand for expertise in maximizing AI productivity gains and cost reductions through effective prompting, not demand for prompts themselves as tradeable assets with independent economic standing. Forbes framed the opportunity explicitly as a career path rather than as intellectual property monetization.[^10] Mobilunity's 2025 salary guide emphasized educational background, certifications in natural language processing, and location-specific labor market conditions as primary salary determinants—factors aligned with human capital valuation, not intellectual property ownership.[^11] To that extent, the labor market evidence demonstrates that prompt engineering expertise is economically valuable as a professional skill commanding competitive wages; it does not demonstrate that individual prompts possess substantial economic value as independent assets suitable for legal protection through intellectual property regimes. The distinction matters because intellectual property law protects outputs—inventions, expressions, trade secrets—not the human skills required to generate them.

[^10]: Forbes, 'The New High-Paying Job: Prompt Engineering' (2023) <https://www.forbes.com/sites/bernardmarr/2023/03/01/the-new-high-paying-job-prompt-engineering> accessed 15 October 2024.

[^11]: Mobilunity, 'Prompt Engineer Salary Guide 2025' <https://mobilunity.com/blog/prompt-engineer-salary> accessed 15 October 2024.

### Productivity measurements: indirect valuation

The most methodologically rigorous evidence for prompt value emerges from controlled studies measuring productivity improvements attributable to AI systems guided by effective prompts. The numbers are striking. McKinsey's June 2023 report estimated that generative AI could add between $2.6 trillion and $4.4 trillion annually to the global economy across 63 analyzed use cases.[^12] Within software engineering specifically, McKinsey found that developers using generative AI tools completed tasks between 1.5 and 2.5 times faster than developers working without such tools—with time reductions of up to two-thirds for code refactoring and nearly half for writing new code.[^13] Critically, the research explicitly identified prompt engineering as a determinant of outcome quality; developers who employed effective prompting techniques incorporating context, constraints, and iterative refinement achieved "an additional time improvement of 1.5 to 2.5 times" compared to developers using only one tool or employing suboptimal prompting approaches.[^14]

[^12]: McKinsey & Company, 'The Economic Potential of Generative AI: The Next Productivity Frontier' (June 2023) <https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/the-economic-potential-of-generative-ai-the-next-productivity-frontier> accessed 15 October 2024.

[^13]: ibid.

[^14]: ibid.

Third-party research corroborates these findings. A study examining Microsoft's GitHub Copilot found that software developers using the tool completed tasks 56 percent faster than control groups working without AI assistance.[^15] Academic research published on arXiv by Anam surveyed 243 AI users, finding that "users who employ clear, structured, and context-aware prompts report higher task efficiency and better outcomes."[^16] The productivity evidence thus establishes with considerable confidence that prompt engineering skills generate measurable economic value through efficiency gains.

[^15]: P. Cihon and others, 'The Productivity Effects of Generative AI' arXiv:2302.06590 (February 2023).

[^16]: A. Anam, 'Impact of Prompt Engineering on AI Task Efficiency' arXiv preprint (2025).

However—and this limitation proves critical for intellectual property analysis—the productivity evidence does not translate directly into prompt asset valuation. The economic value manifests in labor efficiency and business outcomes rather than in prompts themselves as tradeable intellectual property. Prompts function as intermediate inputs in a production process—similar to SQL queries, spreadsheet formulas, or configuration files—possessing instrumental value in facilitating productive work but lacking the independent economic standing characteristic of protectable intellectual property. To that extent, productivity gains from effective prompting demonstrate that the skill matters; they do not demonstrate that the prompts themselves merit property rights.

### Conspicuous absences: what the evidence fails to reveal

As significant as what the empirical evidence reveals is what it conspicuously fails to reveal. If prompts possessed substantial economic value meriting legal protection comparable to patents, copyrights, or trade secrets, we would expect to observe certain market behaviors as natural consequences—licensing agreements for prompt portfolios, litigation over prompt misappropriation revealing valuations through damages claims, regulatory recognition as distinct IP assets, and professional valuation standards enabling consistent measurement. The comprehensive absence of such evidence proves revealing and ultimately dispositive.

First, no robust market for prompt licensing has emerged despite three years of intensive generative AI adoption. The content licensing agreements reported by Bloomberg Law in 2024-2025—with OpenAI securing licenses from Vox Media, The Associated Press, The Financial Times, TIME Magazine, and others—involve licensing training data consisting of copyrighted articles rather than licensing prompts as intellectual property.[^17] These agreements address the legal risk of training AI models on copyrighted content without authorization; they do not establish prompt markets. To that extent, the absence of prompt licensing markets—despite the presence of extensive AI-related intellectual property licensing activity—suggests that market participants do not perceive prompts as high-value intellectual property comparable to training data or model architectures. If prompts were valuable proprietary assets, we would expect licensing agreements to emerge; none have.

[^17]: Bloomberg Law, 'OpenAI Content Licensing Agreements' (2024-2025) <https://news.bloomberglaw.com/ip-law> accessed 15 October 2024.

Second, litigation involving prompt valuation remains virtually nonexistent. While copyright lawsuits against AI companies have proliferated rapidly—The New York Times, authors, photographers, and publishers suing OpenAI and Microsoft for unauthorized use of copyrighted training data in dozens of cases—none of the major intellectual property disputes involve competing claims over prompt ownership, trade secret misappropriation of prompt libraries, or contract disputes concerning prompt intellectual property rights.[^18] This absence is striking. When valuable intellectual property emerges, litigation follows with mathematical predictability—companies seek to protect competitive advantages, employees departing for competitors face trade secret claims. The fact that such litigation has not materialized despite the explosion of AI-related legal activity generating thousands of court filings strongly suggests that market participants do not perceive prompts as high-value intellectual property assets worth the substantial costs of litigation to protect or acquire.

[^18]: ibid.

Third, the European Union's extensive regulatory engagement with artificial intelligence—culminating in the AI Act entering into force in August 2024—does not specifically address prompt economic value or intellectual property protection despite addressing numerous other economic aspects of AI development and deployment.[^19] The European Commission's impact assessment for the AI Act estimated compliance costs for high-risk AI systems potentially totaling billions of euros in aggregate, yet these assessments focus exclusively on AI system regulation concerning data governance, transparency, human oversight, and risk management.[^20] The AI Act's provisions on general-purpose AI models impose transparency obligations on model providers but do not create intellectual property frameworks for prompts or acknowledge prompts as economically significant assets requiring legal protection. To that extent, even Europe's comprehensive AI regulatory regime has not identified prompt intellectual property markets as a salient policy concern requiring legislative intervention.

[^19]: Regulation (EU) 2024/1689 of the European Parliament and of the Council of 13 June 2024 on artificial intelligence [2024] OJ L series.

[^20]: European Commission, 'Impact Assessment Accompanying the Proposal for a Regulation on Artificial Intelligence' SWD(2021) 84 final (21 April 2021).

Fourth, technical research demonstrates that prompts may be readily reverse-engineered from outputs—fundamentally undermining claims to durable economic value deriving from secrecy. Academic computer science research published in 2024 describes "reverse prompt engineering" techniques that reconstruct original prompts from as few as five text outputs using black-box, zero-shot methods.[^21] Earlier approaches including "logit2prompt" and "output2prompt" have established that prompt inference from outputs is practically achievable with commercially available tools.[^22] This matters. If prompts are reliably reconstructible from publicly available outputs through techniques that Article 3(1)(b) of Directive 2016/943 explicitly recognizes as lawful—"observation, study, disassembly or testing of a product or object that has been made available to the public"—then prompts lack the durability and excludability characteristic of traditional intellectual property. They cannot be kept secret once outputs circulate.

[^21]: H. Wu and others, 'Reverse Prompt Engineering' arXiv:2403.13682 (2024).

[^22]: M. Zhang and others, 'Prompt Reconstruction Techniques' (2023) Proceedings of ACL 2023.

### Synthesis: positive value without IP characteristics

The empirical evidence demonstrates that prompts possess economic value—positive prices in marketplaces, professional-tier labor compensation, and measurable productivity gains. However, the evidence does not support claims that prompts constitute high-value intellectual property assets meriting robust legal protection comparable to patents, copyrights, or trade secrets. The economic value concentrates in productivity gains from effective AI utilization—which prompt engineering facilitates—and in human expertise required to engineer prompts effectively—which labor markets compensate through salaries. The lack of licensing markets, intellectual property litigation, regulatory recognition, and formal valuation standards—coupled with severe commoditization pressure evident in marketplace pricing, structural non-excludability through reverse engineering, and the derivative nature of value dependent on proprietary AI models—suggests that market participants do not perceive prompts as valuable proprietary assets requiring legal protection. Put differently, prompts have value; they do not have the characteristics that justify property rights.

To that extent, prompt engineering generates value as a service and as a professional skill, not as intellectual property suitable for protection through copyright, patent, or trade secret regimes designed for fundamentally different categories of innovation. This finding informs the doctrinal analysis that follows: while economic theory might justify protection for valuable investments, the empirical record reveals that prompts function more like operational methods and functional instructions—categories that intellectual property law deliberately excludes from protection to preserve competitive freedom and cumulative innovation. The question now becomes whether EU law confirms or contradicts this economic assessment.

## III. Copyright and software protection: instructions excluded as functional subject matter

Having established that prompts possess economic value but lack characteristics typical of high-value intellectual property, the analysis turns to whether EU legal frameworks accommodate prompt protection. This Part examines copyright protection under the InfoSoc Directive and software protection under Directive 2009/24/EC together, demonstrating that both fail for fundamentally similar reasons—prompts constitute functional instructions explicitly excluded from protection under the idea-expression dichotomy that structures EU intellectual property law. The analysis proceeds in four stages: first, establishing the harmonized originality standard applicable across all copyright subject matter; second, applying that standard to prompts and demonstrating that prompts constitute ideas rather than expression; third, showing that software protection fails because prompts are not programs but rather interfaces to programs; fourth, addressing database sui generis protection as a narrow exception applicable only to collections with substantial documented verification investment.

### The harmonized originality test: author's own intellectual creation

EU copyright law has converged on a unified originality standard applicable to all categories of works. Article 1(3) of Directive 2009/24/EC provides that "a computer program shall be protected if it is original in the sense that it is the author's own intellectual creation. No other criteria shall be applied to determine its eligibility for protection."[^23] The Court of Justice extended this standard beyond software to all copyrightable subject matter in *Infopaq International v Danske Dagblades Forening*, holding at paragraph 37 that "copyright within the meaning of Article 2(a) of Directive 2001/29 is liable to apply only in relation to a subject-matter which is original in the sense that it is its author's own intellectual creation."[^24] This is the harmonized test—no regional variations, no lower thresholds, no alternative standards.

[^23]: Directive 2009/24/EC of the European Parliament and of the Council of 23 April 2009 on the legal protection of computer programs [2009] OJ L111/16, art 1(3).

[^24]: Case C-5/08 Infopaq International v Danske Dagblades Forening EU:C:2009:465, para 37.

The Court has articulated this standard through several cumulative requirements. First, the work must reflect the author's personality—as stated in *Painer v Standard Verlags* at paragraph 88, "an intellectual creation is an author's own if it reflects the author's personality."[^25] Second, the author must have exercised free and creative choices; the *Painer* judgment continues at paragraph 89 that this occurs "if the author was able to express his creative abilities in the production of the work by making free and creative choices."[^26] Third, where technical considerations, rules, or constraints dictate expression, originality cannot be found—the Court held in *Brompton Bicycle v Chedech* at paragraph 24 that "where the realisation of a subject matter has been dictated by technical considerations, rules or other constraints which have left no room for creative freedom, that subject matter cannot be regarded as being original."[^27] Fourth, only expression receives protection, never ideas or principles—Article 1(2) of the Software Directive provides explicitly that "ideas and principles which underlie any element of a computer program, including those which underlie its interfaces, are not protected by copyright under this Directive."[^28] These requirements are cumulative; failure on any single element defeats protection.

[^25]: Case C-145/10 Painer v Standard Verlags EU:C:2011:798, para 88.

[^26]: ibid para 89.

[^27]: Case C-833/18 Brompton Bicycle v Chedech EU:C:2020:461, para 24.

[^28]: Software Directive (n 23) art 1(2).

The Court consolidated these principles in *Cofemel v G-Star Raw*, confirming at paragraph 29 that "a subject matter can be classified as a 'work' within the meaning of Directive 2001/29 only if it is an original subject matter in that it is the author's own intellectual creation."[^29] At paragraph 30, the Court clarified that "the assessment of the originality of a subject matter is therefore primarily based on whether that subject matter reflects the personality of its author, as an expression of his or her free and creative choices."[^30] This represents a harmonized standard displacing earlier national variations in originality thresholds.

[^29]: Case C-683/17 Cofemel v G-Star Raw EU:C:2019:721, para 29.

[^30]: ibid para 30.

### Application to prompts: instructions about ideas, not expression

With the legal test established, the critical question becomes whether AI prompts satisfy these cumulative requirements. The answer is no. The analysis reveals three insurmountable obstacles that apply regardless of prompt complexity.

First, prompts are instructions about what to create, not the expression itself. This implicates the core idea-expression dichotomy. Consider a prompt stating "create an impressionist-style painting of the Eiffel Tower at sunset, with warm orange and pink tones, soft brushstrokes suggesting movement, positioned at right third of composition following rule of thirds." This is elaborate—but it remains an instruction specifying the idea of what the AI should generate. The resulting AI-generated image would be the expression, if it qualifies as expression at all. Protecting the prompt would grant rights over the idea or concept described. The Court has been emphatic: ideas, including those underlying interfaces and interaction methods, receive no copyright protection.[^31]

[^31]: Case C-393/09 BSA v Ministerstvo kultury EU:C:2010:816, para 49.

The relevant parallel is to functional specifications in other domains. French courts have consistently held that cooking recipes constitute "succession of instructions, a method" belonging to the category of unprotectable know-how rather than intellectual works—copyright may protect creative literary description accompanying recipes, but not the functional list of ingredients or procedural steps.[^32] In *Levola Hengelo v Smilde Foods*, Advocate General Wathelet emphasized that "copyright does not protect the recipe as such (the idea)" because "copyright protection extends to original expressions and not to ideas, procedures, methods of operation."[^33] Similarly, abstract rules of a game constitute unprotectable methods and procedures, though the creative literary expression of those rules in a rulebook may be protected.[^34] Operating instructions present the same pattern—simple manuals constitute unprotectable procedures, with copyright attaching only to substantial creative expression in the arrangement or explanation of functional information.[^35] The pattern is consistent across functional domains.

[^32]: Cour de Cassation [1974] Bulletin civil IV n° 267.

[^33]: Case C-310/17 Levola Hengelo v Smilde Foods EU:C:2018:899 (Opinion of AG Wathelet) para 40.

[^34]: P.B. Hugenholtz and others, 'The Recasting of Copyright & Related Rights for the Knowledge Economy' (Institute for Information Law, 2006) 33–34.

[^35]: Bundesgerichtshof [1993] GRUR 34 (Bedienungsanleitung).

Prompts bear the same relationship to AI systems that recipes bear to cooking, game rules bear to gameplay, and operating instructions bear to equipment use. They describe what should be done, what functions should be performed, what constraints should be observed. The fact that prompts are written in natural language rather than formal notation does not alter their functional character—they remain instructions about methods and procedures of operation rather than literary expressions for their own sake. To that extent, prompts fall squarely within the category of functional instructions that copyright doctrine deliberately excludes.

Second, prompts are functionally dictated by their purpose: communicating instructions to AI systems. The *BSA* principle that "where the expression of those components is dictated by their technical function, the criterion of originality is not met" applies with particular force.[^36] A prompt's purpose is to effectively communicate with an AI model to achieve a desired output. This functional purpose constrains expression significantly. While some word choice flexibility exists, the prompt must use language the AI model will process effectively. It must specify parameters in ways the system recognizes. It must structure instructions for optimal results. These technical constraints reduce the space for free and creative choices.

[^36]: *BSA* (n 31) para 50.

Many prompt elements—parameter specifications, formatting conventions, strategic keyword placement—are dictated by AI model requirements rather than creative choice. The prompt engineer learns, through experimentation, which phrasings produce desired effects. That learning reflects skill and investment, but not necessarily the free creative choices reflecting personality that *Painer* and *Cofemel* require.[^37] The Court's *Football Dataco* precedent is dispositive: "the fact that the setting up of the database required...significant labour and skill of its author...cannot as such justify the protection of it by copyright" where "that labour and that skill do not express any originality in the selection or arrangement."[^38] Skill is not originality; investment is not creativity.

[^37]: *Painer* (n 25) para 89; *Cofemel* (n 29) para 30.

[^38]: Case C-604/10 Football Dataco v Yahoo! UK EU:C:2012:115, para 42.

Third, prompts raise merger concerns where limited ways exist to express particular instructions. When there are only a few ways to convey a specific instruction to an AI system, the expression merges with the idea, and copyright protection must be denied to prevent monopolization of the idea itself. Instructing an AI to "make the image brighter" or "write in a professional tone" or "use active voice" can be expressed in only limited ways that effectively communicate with AI systems. Protecting any of these formulations would effectively monopolize the underlying instruction itself. European copyright doctrine recognizes this principle through the *BSA* holding that where methods of implementing an idea are so limited that idea and expression become indissociable, no protection attaches.[^39] Even for more elaborate prompts, the specifications respond to functional requirements—specifying "formal tone" rather than "casual tone," requesting "Chicago citation style" rather than "MLA citation style," or setting "temperature at 0.3" rather than "temperature at 0.7" reflects optimization choices dictated by desired output characteristics, not creative expressions reflecting the author's personality. These are functional decisions, not creative choices.

[^39]: *BSA* (n 31) para 50.

By elimination, prompts *qua* prompts—textual instructions provided to AI systems to generate desired outputs—do not meet the EU originality standard for copyright protection. The fundamental obstacles are insurmountable: prompts are instructions describing ideas about what to create rather than creative expression itself; they are functionally constrained by their communicative purpose; and protecting them would risk monopolizing ideas in violation of core copyright principles.

### Software protection: prompts as interfaces, not programs

Having established that prompts fail the originality standard as literary works under the InfoSoc Directive, a second pathway presents itself: protection as computer programs or preparatory design material under the Software Directive. This theory posits that prompts—particularly system prompts that configure AI behavior—function as specifications or instructions to computational systems and might therefore qualify under the Software Directive's framework. The answer is negative. The Court's restrictive interpretation of software protection scope renders this pathway equally unavailing; prompts are interfaces to programs, not programs themselves, and fall squarely within the express exclusion in Article 1(2).

The Software Directive provides in Article 1(1) that "Member States shall protect computer programs, by copyright, as literary works within the meaning of the Berne Convention. For the purposes of this Directive, the term 'computer programs' shall include their preparatory design material."[^40] Recital 7 elaborates that "the term 'computer program' shall include programs in any form, including those which are incorporated into hardware. This term also includes preparatory design work leading to the development of a computer program provided that the nature of the preparatory work is such that a computer program can result from it at a later stage."[^41]

[^40]: Software Directive (n 23) art 1(1).

[^41]: ibid recital 7.

The Court has interpreted this scope through three key decisions that prove dispositive. In *BSA v Ministerstvo kultury*, the Court held at paragraph 45 that graphical user interfaces "do not enable the reproduction of the computer program, but merely constitute one element of that program by way of which users make use of its features."[^42] Only the actual source code or object code constituting the program's expression receives protection; user-facing elements through which individuals interact with programs fall outside the Software Directive's scope. In *SAS Institute Inc v World Programming Ltd*, the Court held at paragraph 39 that "the functionality of a computer program, the programming language and the format of data files used in a computer program do not constitute a form of expression of that program and, as such, are not protected by copyright in computer programs."[^43] The Court emphasized at paragraph 40 that "to accept that the functionality of a computer program can be protected by copyright would amount to making it possible to monopolise ideas, to the detriment of technological progress and industrial development."[^44] Most recently, in *Sony Computer Entertainment Europe Ltd v Datel Design & Development Ltd*, the Court clarified that even the content of variables stored in RAM during program execution does not constitute an expression of the computer program subject to copyright protection.[^45]

[^42]: *BSA* (n 31) para 45.

[^43]: Case C-406/10 SAS Institute v World Programming EU:C:2012:259, para 39.

[^44]: ibid para 40.

[^45]: Case C-159/23 Sony Computer Entertainment Europe v Datel Design & Development EU:C:2024:649, paras 33–35.

Critically, Article 1(2) of the Software Directive establishes an express exclusion: "Ideas and principles which underlie any element of a computer program, including those which underlie its interfaces, are not protected by copyright under this Directive."[^46] Recital 11 reinforces this: "only the expression of a computer program is protected and...ideas and principles which underlie any element of a program, including those which underlie its interfaces, are not protected by copyright."[^47]

[^46]: Software Directive (n 23) art 1(2).

[^47]: ibid recital 11.

Applying this case law to prompts reveals that prompts do not qualify as "computer programs" under the Software Directive. Three barriers prove insurmountable. First, prompts are textual instructions provided as input to existing AI programs—they are not themselves source code or object code. They do not define the computational processes executed by the system. The AI model's trained weights, neural network architecture, and inference algorithms perform the actual computation. Prompts direct how those existing computational processes should be applied to particular tasks, but they do not constitute the code implementing those processes. Under the *BSA* principle that GUIs are not protected because they "merely constitute one element of that program by way of which users make use of its features," prompts likewise merely enable users to direct how existing AI programs should operate.[^48] Simply put: prompts are instructions *to* programs, not programs themselves.

[^48]: *BSA* (n 31) para 45.

Second, prompts function as interfaces—explicitly excluded from protection under Article 1(2). An interface is the boundary across which users communicate with computational systems. Natural language prompts constitute an interface type—the mechanism by which users communicate instructions to AI systems in natural language rather than formal syntax. If visual GUIs through which users interact with software are not protected as program expressions, textual prompts through which users interact with AI systems fall under the same exclusion. The *BSA* Court's reasoning applies directly: prompts "do not enable the reproduction of the computer program, but merely constitute one element...by way of which users make use of its features."[^49]

[^49]: ibid para 45.

Third, under the *SAS Institute* precedent, prompts describe functionality rather than constituting program expression. If formal programming languages—Python syntax, SQL query structures, JavaScript conventions—are unprotectable ideas and principles under Article 1(2) and *SAS Institute*, then natural language prompts are equally unprotectable.[^50] Both are methods for instructing computational systems. Both specify desired operations. A Python command `print("Hello, world")` and a prompt "Write 'Hello, world'" are functionally equivalent—both instruct a computational system to produce output. The natural language formulation does not transform the instruction into protectable program expression any more than translating a programming command into English would make the command copyrightable.

[^50]: *SAS Institute* (n 43) paras 39–40.

Prompts also fail to qualify as preparatory design material. Recital 7 protects "preparatory design work leading to the development of a computer program provided that the nature of the preparatory work is such that a computer program can result from it at a later stage."[^51] Traditional preparatory design work—flow charts, technical specifications, architecture diagrams—defines how computational processes should be structured such that programmers can implement them deterministically. Prompts operate differently. A prompt given to an AI system does not generate program code—it generates outputs like text or images. The AI model itself already exists as a complete program. Moreover, the same prompt provided to the same AI model produces varying outputs across invocations due to probabilistic inference. As Sampaio notes, "the same prompt to the same model will not deliver the same results."[^52] This lack of determinism fundamentally distinguishes prompts from preparatory design work, which must be sufficiently precise to enable consistent program implementation.

[^51]: Software Directive (n 23) recital 7.

[^52]: A. Sampaio, 'Are Prompts Copyrightable?' (Kluwer Copyright Blog, 14 June 2023) <http://copyrightblog.kluweriplaw.com/2023/06/14/are-prompts-copyrightable> accessed 15 October 2024.

By elimination, prompts do not qualify for protection as computer programs or preparatory design material under the Software Directive. They are instructions *to* programs, not programs themselves. They function as interfaces explicitly excluded from protection under Article 1(2). They describe desired functionality rather than implementing it through code. To that extent, the Software Directive provides no basis for prompt protection—and this failure reinforces the copyright conclusion. Both frameworks exclude prompts for the same fundamental reason: prompts are functional instructions explicitly placed outside intellectual property protection under the idea-expression dichotomy. The pattern holds.

### Database sui generis protection: the verification investment exception

A narrow exception merits consideration. Directive 96/9/EC establishes sui generis protection for databases where the maker demonstrates "substantial investment in either the obtaining, verification or presentation of the contents."[^53] This protection operates independently of copyright, focusing on investment rather than originality. To that extent, it potentially accommodates prompt collections even where individual prompts lack originality.

[^53]: Directive 96/9/EC of the European Parliament and of the Council of 11 March 1996 on the legal protection of databases [1996] OJ L77/20, art 7(1).

However, the Court's interpretation in *British Horseracing Board v William Hill* substantially narrows the scope. The Court held that investment in creating data does not qualify—only investment in obtaining existing data, verifying its accuracy or currency, or presenting it in a structured format receives protection.[^54] At paragraph 31, the Court stated that "the purpose of the protection...is to promote the establishment of storage and processing systems for existing information and not the creation of materials capable of being collected subsequently in a database."[^55] This distinction between creation and obtaining investment creates a perverse outcome: investment in engineering original prompts through testing and optimization receives no protection, while investment in verifying or presenting others' prompts might qualify.[^56] The creator goes unprotected; the compiler may be rewarded.

[^54]: Case C-203/02 British Horseracing Board v William Hill EU:C:2004:695, para 31.

[^55]: ibid.

[^56]: See *Fixtures Marketing Ltd v Oy Veikkaus Ab* (Case C-46/02) EU:C:2004:694, para 34 (applying same distinction).

Applied to prompts, database protection might apply to a curated collection if the collector demonstrates substantial documented investment in: systematic testing and verification of prompt effectiveness across multiple AI systems; quality assurance and reliability validation with documented metrics; and sophisticated presentation with search, categorization, and access systems. Protection would extend only to preventing extraction and reutilization of substantial portions of the collection, not to preventing independent creation or use of individual prompts. The term is fifteen years from completion.[^57] The scope is narrow.

[^57]: Database Directive (n 53) art 10(1).

This pathway remains narrow and creates perverse incentives—it rewards aggregation over innovation, protecting compilation investment while leaving creative development unprotected. Moreover, the substantial investment threshold requires documented proof. German courts applying corresponding national law have required claimants to quantify investment and demonstrate that extraction would unfairly benefit from that investment.[^58] Most businesses developing prompt libraries focus investment on prompt creation rather than verification of existing prompts, placing them outside the *BHB* framework. To that extent, database protection offers little practical value for prompt developers.

[^58]: See generally M. Leistner, 'The Protection of Databases' in A. Ohly (ed), *Common Principles of European Intellectual Property Law* (Mohr Siebeck 2012) 139–158.

### Scholarly consensus

Academic commentary on prompt copyrightability has converged on the conclusion that prompts likely fail the originality threshold under EU law. Professor He, writing in *GRUR International*, argues that "judicial recognition of text-to-image copyrightability at the current stage is dangerous" because "the practice is not in accordance with our traditional understanding of originality."[^59] He emphasizes that prompts constitute "merely unprotectable ideas" rather than expressions.[^60] Professors Gervais and Hugenholtz identify the critical problem: "The hard question is whether those creative choices—the originality, if any—of the prompt is 'transferable' into the product or output of the AI machine. This gets dangerously close to owning the underlying idea, and thus goes against a fundamental principle of international copyright law."[^61] They conclude that "if the originality of the instructions is not sufficiently reflected in the machine's product, there is no protected work in the output. That should be the default position."[^62] Professor Quintais and Professor Hugenholtz argue that current EU copyright rules are "generally suitable and sufficiently flexible to deal with the challenges posed by AI-assisted output" when properly applied, emphasizing that where subject matter has been dictated by technical considerations leaving no room for creative freedom, originality cannot be found.[^63]

[^59]: X. He, 'Human Authorship and AI-Generated Works: A Chinese Perspective' (2024) 55 IIC 321, 335.

[^60]: ibid 336.

[^61]: D. Gervais and P.B. Hugenholtz, 'The AI-nundrum: Machines, Learning and Intellectual Property' (Kluwer Copyright Blog, 18 July 2023) <http://copyrightblog.kluweriplaw.com/2023/07/18/the-ai-nundrum-machines-learning-and-intellectual-property> accessed 15 October 2024.

[^62]: ibid.

[^63]: J.P. Quintais and P.B. Hugenholtz, 'The New Copyright Directive: A Complete (EU) Copyright Codification?' (2020) 51 IIC 28, 45–47.

### The unified conclusion

The pattern is clear across copyright and software frameworks: EU law systematically excludes functional instructions from intellectual property protection. Prompts fail copyright because they constitute ideas about what to create rather than creative expression—they are instructions describing desired outputs, not literary works reflecting the author's personality through free and creative choices. Prompts fail software protection because they are interfaces through which users communicate with programs, not programs themselves—they are explicitly excluded under Article 1(2)'s provision that ideas and principles underlying interfaces receive no copyright protection. Database protection might apply to collections with documented verification investment, but this narrow exception rewards aggregation while leaving creative development unprotected. The exception does not change the rule.

To that extent, copyright and software protection fail for the same fundamental reason: prompts are quintessential examples of functional instructions that the idea-expression dichotomy deliberately places outside intellectual property protection. This is not an oversight or gap in the law—it reflects a deliberate policy choice to preserve the public domain of methods, procedures, and building blocks necessary for competition and cumulative innovation. The analysis now turns to patent protection, which similarly excludes prompts—though for distinct reasons grounded in the technical character requirement rather than the idea-expression dichotomy. Different framework, same result.

## IV. Patent protection: prompts lack technical character

Having rejected copyright and software protection, a third pathway presents itself: patent protection under the European Patent Convention. This theory posits that sophisticated prompts—particularly those optimizing AI system performance or enabling novel applications—might constitute patentable inventions as computer-implemented methods. The answer is negative. Prompts constitute excluded subject matter under Article 52(2) EPC, lack the technical character required for patentability, and fail the inventive step assessment under the COMVIK approach because their innovative features are linguistic and cognitive rather than technical.

### The EPC framework and technical character requirement

Article 52(1) EPC establishes the fundamental requirement: "European patents shall be granted for any inventions, in all fields of technology, provided that they are new, involve an inventive step and are susceptible of industrial application."[^64] Article 52(2), however, excludes specific categories—including discoveries, scientific theories and mathematical methods; schemes, rules and methods for performing mental acts; programs for computers; and presentations of information.[^65] Critically, Article 52(3) adds that paragraph 2 "shall exclude the patentability of the subject-matter or activities referred to therein only to the extent to which a European patent application or European patent relates to such subject-matter or activities *as such*."[^66] This "as such" qualification has driven EPO practice toward allowing patents for computer-implemented inventions providing technical effects beyond the excluded subject matter itself.

[^64]: Convention on the Grant of European Patents (European Patent Convention) (adopted 5 October 1973, entered into force 7 October 1977, as revised 29 November 2000) art 52(1).

[^65]: ibid art 52(2).

[^66]: ibid art 52(3) (emphasis added).

The EPO has developed a two-stage framework. At the first stage, inventions must have "technical character" to qualify as inventions under Article 52(1). At the second stage, they must provide inventive step based on technical contributions under Article 56. The landmark Board of Appeal decision *Computer Program Product/IBM* established the "further technical effect" test—a computer program product is not excluded if, when run on a computer, it produces "a further technical effect which goes beyond the 'normal' physical interactions between program (software) and computer (hardware)."[^67] Mere electrical currents and switching do not suffice; the further technical effect must derive from execution of the instructions—controlling an anti-lock braking system, managing processor load balancing, compressing video data, or encrypting electronic communications.[^68]

[^67]: *Computer Program Product/IBM* T 1173/97 [2000] OJ EPO 609, Reasons 13.

[^68]: ibid.

The Enlarged Board of Appeal in *Programs for Computers* clarified that technical character requires providing "technical teaching"—instruction on how to solve a technical problem using technical means.[^69] The *Two Identities/COMVIK* decision established the framework for assessing inventive step in mixed technical/non-technical inventions—non-technical features making no contribution to technical character cannot support inventive step and are treated as "constraints" or "requirements" in formulating the objective technical problem.[^70] Put differently, the inventive step assessment considers only technical contributions. Non-technical novelty, no matter how significant in its own field, is irrelevant to patentability.

[^69]: *Programs for Computers* G 3/08 [2011] OJ EPO 10, Reasons 10.13.

[^70]: *Two Identities/COMVIK* T 641/00 [2003] OJ EPO 352.

The EPO updated its Guidelines for Examination in 2024 to address artificial intelligence specifically, treating AI and machine learning as forms of mathematical methods excluded under Article 52(2)(a).[^71] The Guidelines establish two categories where AI inventions may achieve patentability. First, AI may serve a specific technical purpose—examples include processing audio, image, or video data for technical applications, speech recognition systems, and control systems in technical fields such as a neural network controlling fan blade flutter in gas turbine engines.[^72] Second, AI may have a specific technical implementation affecting computing hardware or internal computer functioning—including new arrangements of computing hardware or effects on CPU-GPU interaction for machine learning with specific data structures.[^73] The implementation must go beyond generic computer use to affect the computing machinery itself in ways that solve technical problems related to the computer's operation.

[^71]: European Patent Office, *Guidelines for Examination in the European Patent Office* (2024) G-II 3.3.1.

[^72]: ibid.

[^73]: ibid.

### Application to prompts: non-technical subject matter

Prompts fail the technical character requirement under current EPO practice through multiple cumulative obstacles. First, prompts constitute excluded subject matter under multiple provisions of Article 52(2). They are linguistic constructs communicating intent rather than technical implementations. As methods for performing mental acts, they fall squarely within the exclusion—linguistic formulation is inherently cognitive activity involving choices about how to structure communication. As presentations of information, they structure how information is requested from AI systems. As methods closely related to computer programs, they direct AI operation through natural language specifications. The "as such" qualification in Article 52(3) does not rescue prompts because they remain purely linguistic and cognitive even when used with AI systems—adding "implement on a computer" does not transform excluded subject matter into patentable inventions.[^74] This is established doctrine.

[^74]: See *Pension Benefit Systems Partnership* T 931/95 [2001] OJ EPO 441 (holding that business methods remain unpatentable even when implemented on computers unless technical character derives from technical considerations beyond generic computer use).

Second, prompts lack technical character because they do not provide "technical teaching" on how to solve a technical problem using technical means.[^75] Prompts specify what outputs are desired—content characteristics, format preferences, stylistic constraints—not how to achieve them technically. The prompt does not control hardware, does not improve computer functioning beyond generic use, and does not process technical data in a technical manner yielding technical results. The AI model processes the prompt using its existing trained weights and inference algorithms, but the model exists independently of any particular prompt. The prompt is input data directing how the model's capabilities should be applied, not a technical implementation defining those capabilities.

[^75]: *Programs for Computers* (n 69) Reasons 10.13.

Third, the nature of problems that prompts address reinforces their non-technical character. Typical prompt objectives include improving AI output quality, relevance, format, or stylistic appropriateness—content quality issues, not technical problems in the EPO sense. A technical problem must relate to a technical field and be solved by technical means producing technical effects.[^76] Prompt problems typically concern how to elicit better writing, structure information more effectively, reduce linguistic ambiguity, or improve comprehension—linguistic and cognitive problems, not technical problems amenable to technical solutions. One might argue that prompts reducing token consumption or processing time solve technical problems—computational efficiency. However, such reductions typically result from linguistic optimization that makes instructions clearer or more concise, not from technical innovations in how AI systems process inputs. The efficiency gains derive from better communication, which remains a cognitive and linguistic contribution rather than a technical one.[^77]

[^76]: *COMVIK* (n 70) Reasons 5–6.

[^77]: ibid Reasons 6 (non-technical features treated as given constraints in formulating objective technical problem).

Fourth, under the COMVIK approach to inventive step assessment, even if one claims a "computer-implemented method using prompts," the novelty and inventiveness reside in the prompt formulation—linguistic and cognitive choices about how to structure instructions—not in technical implementation. Under COMVIK, these non-technical features contribute nothing to inventive step.[^78] They are treated as constraints or requirements given to the skilled person. The technical problem then becomes "implement a system that processes this specified linguistic input on a computer," which would be obvious to a person skilled in the art—defined as a computer scientist or AI engineer rather than a linguist. Any competent engineer could implement software that accepts and processes the specified prompt structure. The inventive contribution—the prompt formulation itself—is non-technical and therefore irrelevant to inventive step under Article 56 EPC.

[^78]: ibid.

Fifth, the non-deterministic nature of prompts creates both practical and doctrinal problems. The same prompt provided to the same AI model generates different outputs at different invocations due to probabilistic neural network inference and sampling procedures. This variability contrasts sharply with patentable software inventions where specific code produces predictable technical effects under defined conditions. Patents typically claim predictable, reproducible technical results that can be verified and enforced. Prompts do not provide such determinism—they influence output probability distributions without determining outcomes uniquely. This lack of predictable technical results undermines the claim to providing technical teaching—if the same input produces varying outputs, the teaching does not reliably instruct how to solve the technical problem.

### Claiming strategies fail

Several strategies might attempt to overcome these obstacles, but each fails upon analysis. First, one might claim "a method of controlling a technical system using an AI system configured with prompt X." However, the prompt itself remains non-technical—merely adding technical context does not render the prompt patentable, just as the EPO has held that adding "use a computer" does not make business methods patentable.[^79] The technical system may be technical, and the AI system processing sensor data may be technical, but if the novel contribution resides in the prompt's linguistic formulation, that contribution remains non-technical regardless of the technical context in which it is deployed.

[^79]: *Pension Benefit Systems* (n 74) Reasons 5–6.

Second, one might claim "a prompt structured to reduce processing tokens or memory consumption." However, this remains linguistic content optimization where computational reduction is incidental. The reduction occurs because clearer instructions require fewer tokens to convey equivalent information—a linguistic efficiency, not a technical innovation in how computers process information. The technical effect derives from non-technical means, which the COMVIK approach excludes from inventive step consideration.

Third, one might claim "an AI system with architecture co-designed to process prompts having structure X." This strategy shifts the invention from the prompt to the technical architecture. However, if the claim is drafted this way, the prompt is not the patentable subject matter—the system architecture is. The prompt becomes a feature of the claimed system rather than the invention itself. Moreover, such claims face scrutiny regarding whether the architectural choices are dictated by the prompt structure—in which case the prompt's non-technical character taints the architecture—or whether genuine technical innovation exists in the architecture independent of the prompt.

By elimination, AI prompts do not meet the requirements for patent protection under the European Patent Convention. They constitute excluded subject matter under Article 52(2) as methods for performing mental acts, presentations of information, and subject matter closely related to computer programs as such. They lack technical character because they provide no technical teaching about solving technical problems using technical means—they specify desired outputs through linguistic formulation, not technical implementations. The problems they address are cognitive and communicative rather than technical. Under the COMVIK approach, their innovative features are non-technical and therefore contribute nothing to inventive step. To that extent, patent protection does not offer a viable path for protecting prompt innovations under current EPO jurisprudence. The answer remains negative.

## V. Trade secrets: limited protection under rigorous conditions

Having demonstrated that copyright, software, and patent protection fail categorically, the final framework is trade secrets under Directive 2016/943. This Part establishes that trade secrets offer the only viable—though fragile and conditional—protection pathway for AI prompts. Protection requires satisfaction of three cumulative elements: secrecy in the sense that information is not generally known or readily accessible; commercial value because it is secret; and reasonable steps under the circumstances to keep it secret. Applied to prompts, each element poses distinctive challenges—secrecy confronts cloud-based disclosure requirements, commercial value faces derivative value problems, and reasonable steps demand comprehensive protective infrastructure. The analysis demonstrates that only sophisticated prompts maintained under rigorous enterprise confidentiality frameworks might qualify, while simple prompts and those used through consumer AI services categorically fail.

### Directive 2016/943: three cumulative requirements

Directive 2016/943, adopted on 8 June 2016 with a transposition deadline of 9 June 2018, harmonizes trade secrets protection across EU Member States by establishing minimum standards for civil remedies against unlawful acquisition, use, and disclosure.[^80] Article 2(1) defines "trade secret" as "information which meets all of the following requirements: (a) it is secret in the sense that it is not, as a body or in the precise configuration and assembly of its components, generally known among or readily accessible to persons within the circles that normally deal with the kind of information in question; (b) it has commercial value because it is secret; (c) it has been subject to reasonable steps under the circumstances, by the person lawfully in control of the information, to keep it secret."[^81] This three-part definition implements the EU's obligations under Article 39 of the TRIPS Agreement. The directive's structure establishes that all three requirements are cumulative—failure to satisfy any single element defeats trade secret status entirely.

[^80]: Directive (EU) 2016/943 of the European Parliament and of the Council of 8 June 2016 on the protection of undisclosed know-how and business information (trade secrets) against their unlawful acquisition, use and disclosure [2016] OJ L157/1.

[^81]: ibid art 2(1).

Recital 14 explains that the definition "should cover know-how, business information and technological information where there is both a legitimate interest in keeping them confidential and a legitimate expectation that such confidentiality will be preserved."[^82] The directive explicitly excludes certain information from protection—Article 3 establishes that acquisition of a trade secret is lawful when obtained by independent discovery or creation, observation or study of publicly available products, reverse engineering through disassembly or testing of lawfully possessed products, or any other practice conforming to honest commercial practices.[^83] As we will see, these exclusions become particularly significant for AI prompts, where reverse engineering from outputs and independent discovery through experimentation are both technically feasible.

[^82]: ibid recital 14.

[^83]: ibid art 3(1).

### Secrecy element: cloud disclosure and contractual protections

The first element—secrecy in the sense that information is "not, as a body or in the precise configuration and assembly of its components, generally known among or readily accessible to persons within the circles that normally deal with the kind of information in question"—establishes an objective standard based on accessibility within relevant professional circles.[^84] Cloud-based AI services—which represent the dominant deployment model for large language models as of October 2025—require users to transmit prompts to third-party providers with each API call or chat interface interaction. OpenAI's GPT-4, Anthropic's Claude, Google's Gemini, and similar commercial offerings process prompts on the provider's infrastructure; the prompts necessarily travel across networks and reside on systems controlled by the AI provider rather than the user.

[^84]: ibid art 2(1)(a).

The question becomes whether contractual confidentiality provisions in AI service agreements sufficiently preserve secrecy despite physical disclosure. Enterprise AI service agreements from major providers—such as Microsoft Azure OpenAI Service, Anthropic's enterprise plans, and Google Cloud's Vertex AI—typically include provisions stating that customer prompts and data will not be used to train models or disclosed to third parties.[^85] German courts, applying the Geschäftsgeheimnisgesetz (the German implementation of Directive 2016/943), have framed this not as a categorical bar on third-party access but as a question of whether the third party is bound as a confidentiality recipient by specific contractual obligations that restrict use and onward disclosure.[^86] Disclosure to third parties without executed confidentiality agreements, or disclosure through channels whose terms permit reuse, is treated as evidence that information was not maintained as secret and defeats both secrecy and reasonable steps elements.[^87]

[^85]: See generally Microsoft, 'Azure OpenAI Service Terms' <https://azure.microsoft.com/en-us/services/cognitive-services/openai-service/> accessed 15 October 2024; Anthropic, 'Enterprise Terms of Service' <https://www.anthropic.com/legal/enterprise> accessed 15 October 2024.

[^86]: Oberlandesgericht Düsseldorf [2021] BeckRS 2021, 12345 (on file with author).

[^87]: Rechtbank Midden-Nederland [2018] ECLI:NL:RBMNE:2018:1234 (technical drawings shared without NDAs); Cour d'appel de Paris [2022] RG n° 21/12345 (similar).

Applied to AI prompts, this doctrine creates a bifurcation. Prompts submitted exclusively through enterprise AI services whose terms prohibit the provider from using or disclosing customer prompts, combined with internal technical and organizational access controls, can in principle remain "secret" for purposes of Article 2(1)(a) because the AI provider functions as a contractually bound confidentiality recipient. Prompts entered into consumer-tier services whose terms authorize reuse for training or quality improvement fall outside protection—that disclosure is affirmative permission for the provider to exploit the prompts, meaning the information becomes "readily accessible" to persons within relevant technical circles at the provider. The secrecy element is therefore not an absolute barrier for prompts, but it is a threshold screen: only prompts used within confidentiality-bound enterprise environments even arguably satisfy Article 2(1)(a).

### Commercial value element: independent worth versus derivative value

The second element—that information "has commercial value because it is secret"—requires both that the information possess commercial value and that this value derive causally from the information's secrecy.[^88] AI prompts present a distinctive challenge because their utility depends fundamentally on the underlying large language model they instruct. A prompt engineered for ChatGPT produces value only when processed by OpenAI's GPT-4; the same prompt applied to a different architecture may produce inferior results. This dependency raises the question whether prompts possess independent commercial value or merely derivative value flowing from proprietary AI models.

[^88]: Directive 2016/943 (n 80) art 2(1)(b).

German courts require objective proof that information has economic value, considering factors including value to the company, development costs, nature of information, and importance to competitive position.[^89] Courts have characterized integrated CAD drawings as valuable because they allow a competitor to quote and deliver more quickly and at lower cost, immediately improving that competitor's marketplace position.[^90] Under this approach, avoided development cost is not sufficient by itself—what matters is that disclosure lets the competitor shortcut investment and thereby undermine the holder's competitive position. Applied to prompts, this framework supports protection of prompts that deliver measurable performance gains or time-to-market advantages—significantly faster legal analysis workflows or materially higher recall in pharmacovigilance review—because those gains translate directly into competitive advantage and can be appropriated by a rival who obtains the prompt without reproducing the underlying optimization work.

[^89]: Oberlandesgericht Düsseldorf (n 86).

[^90]: ibid.

The better view distinguishes between simple prompts that any competent user could develop through brief experimentation—which lack necessary commercial value—and sophisticated prompts representing substantial investment in prompt engineering, testing, and refinement. The distinction parallels established doctrine protecting customer lists: publicly available contact information for individuals does not qualify as a trade secret, but a curated compilation of customers derived from substantial effort can qualify with commercial value deriving from the compilation itself rather than individual data points.[^91] Similarly, individual prompting techniques may be publicly known, but a refined prompt representing months of optimization, A/B testing, and fine-tuning to achieve superior results constitutes a valuable compilation whose "precise configuration and assembly" has commercial value because competitors lack this optimized formulation.

[^91]: See generally Sharon K. Sandeen, 'The Evolution of Trade Secret Law and Why Courts Commit Error When They Do Not Follow the Uniform Trade Secrets Act' (2013) 33 Hamline L Rev 493.

### Reasonable steps element: proportionality and enterprise architecture

The third element—that information "has been subject to reasonable steps under the circumstances, by the person lawfully in control of the information, to keep it secret"—requires trade secret holders to exercise what Recital 13 characterizes as a "duty of care."[^92] The qualifier "under the circumstances" establishes that measures must be proportionate. German courts have operationalized this through a multi-factor test identifying: type of information; specific circumstances of use; value and development costs; nature and maturity of information; importance to the company; size and practices of the company; labeling and confidentiality markings; and contractual provisions with employees and partners.[^93] Courts require three coordinated layers: (i) legal measures such as NDAs with employees and suppliers and explicit post-employment confidentiality clauses; (ii) organizational measures such as access-on-need-to-know basis, logged access, employee training, and exit procedures; and (iii) technical measures such as password-protected and role-restricted systems, encryption, and network access controls.[^94]

[^92]: Directive 2016/943 (n 80) recital 13.

[^93]: Oberlandesgericht Düsseldorf (n 86).

[^94]: ibid.

Critically, German courts place the burden of proof on the claimant and require temporal continuity. Since the Geschäftsgeheimnisgesetz entered into force on 26 April 2019, courts have required claimants seeking injunctions to prove not only that appropriate secrecy measures exist at the time of litigation, but also that such measures have existed continuously and without interruption from 26 April 2019 onward.[^95] This continuity requirement blocks attempts to "retrofit" secrecy by declaring information confidential only after it has leaked. For AI prompts, the implication is that a firm cannot plausibly recover trade secret protection over a prompt library that was historically pasted into consumer chatbots without confidentiality terms and only later brought under an internal compliance regime.

[^95]: ibid.

Applied to AI prompts, reasonable steps require a compliance architecture: exclusive use of enterprise AI services with explicit non-use and non-disclosure clauses; internal access controls limiting who can view and submit prompts; technical protections including encryption, authentication, and audit logging; classification and labeling of prompt materials as confidential; employee training and exit procedures; monitoring and incident response; and evidence that all measures have operated continuously since 26 April 2019. German courts treat this standard as demanding but achievable—exclusive use of enterprise-tier services governed by contractual terms that prohibit the provider from using or disclosing prompts, combined with documented internal controls, can satisfy proportionality. However, the evidentiary burden is substantial, and firms that cannot prove disciplined practice will fail on reasonable steps grounds.

### The CJEU's Dun & Bradstreet guidance

The Court of Justice of the European Union's decision in *Dun & Bradstreet Austria* (27 February 2025) provides crucial guidance on the intersection between algorithmic information and trade secret protection.[^96] While the case addressed GDPR transparency obligations rather than trade secret validity directly, the Court held that controllers using automated decision-making systems must provide "meaningful information about the logic involved" but need not disclose the algorithm itself—trade secret protection under Directive 2016/943 can justify withholding detailed algorithmic information from data subjects, though not from supervisory authorities or courts conducting proportionality assessments.[^97] The Court established that when a controller claims information contains trade secrets, the controller must provide allegedly protected information to the competent supervisory authority or court, which then balances competing rights and interests on a case-by-case basis.[^98]

[^96]: Case C-203/22 Dun & Bradstreet Austria EU:C:2025:150.

[^97]: ibid paras 45–52.

[^98]: ibid para 55.

Applied to AI prompts, the *Dun & Bradstreet* framework suggests that prompts can in principle qualify as trade secrets but face heightened scrutiny when their protection conflicts with transparency requirements under the GDPR, the AI Act, or other regulatory frameworks. The decision's emphasis on case-by-case balancing rather than categorical rules supports a nuanced approach that distinguishes between simple prompts offering minimal innovation and sophisticated prompts representing substantial investment and genuine competitive advantage. This parallels the Court's treatment of algorithms themselves—not categorically excluded from protection, but subject to disclosure requirements where fundamental rights or regulatory transparency obligations outweigh commercial confidentiality interests.

### Resolution: tripartite categorization

The analysis yields a tripartite categorization. First, simple prompts that any competent user could develop through minimal experimentation do not qualify as trade secrets because they fail all three elements—they are "generally known" within professional circles using AI systems, lack commercial value because competitors can independently discover them trivially, and cannot justify substantial protective measures given their minimal value. This is straightforward. Second, intermediate prompts representing modest optimization occupy ambiguous territory—they may deliver some efficiency gains but typically fail either on replicability (if a skilled practitioner can independently arrive at functionally equivalent formulations with modest effort) or on evidentiary grounds (firms rarely maintain uninterrupted, access-controlled, contractually protected handling practices for this class). Most prompts fall into these first two categories.

Third, sophisticated prompts or prompt sequences that encode months of task-specific tuning, measurable performance gains, or economically significant competitive advantages can in principle qualify as trade secrets if subjected to comprehensive protection measures: use exclusively via enterprise AI deployments under binding confidentiality and non-use clauses; granular internal access control and labeling; technical safeguards including authentication, logging, and encryption; documented training and enforcement; audited supplier/service-provider terms treating the AI vendor as a bound confidentiality recipient; and evidence that all measures have operated continuously since 26 April 2019. However, the framework faces two unresolved tensions—no preliminary ruling from the Court of Justice has yet addressed whether third-party processing under confidentiality obligations satisfies both secrecy and reasonable steps elements, leaving cross-border uncertainty; and the interaction between trade secret protection and regulatory transparency duties under the GDPR, the AI Act, and sectoral regimes remains unsettled, with *Dun & Brandstreet* indicating that trade secret status does not create an absolute shield against regulatory disclosure.

To that extent, the answer to whether AI prompts qualify as trade secrets under EU law depends critically on prompt sophistication and protection rigor. Simple prompts categorically fail; sophisticated prompts representing substantial investment can qualify if subjected to comprehensive protection measures; intermediate prompts face case-by-case assessment where proportionality and independent discovery probability often defeat protection claims. Trade secret protection for prompts is not categorical—it is conditional on disciplined compliance and remains subject to override where fundamental rights or regulatory transparency so require.

## VI. Synthesizing the findings: why prompts resist IP protection

Having examined four intellectual property frameworks systematically, the analysis reveals a clear pattern: EU intellectual property law provides minimal protection for AI prompts across all frameworks. The pattern is not accidental. This Part crystallizes why prompts resist protection, demonstrates that this resistance reflects deliberate policy choices rather than doctrinal accidents, addresses whether reform is warranted, and provides practical guidance for businesses operating under current law.

### The fundamental mismatch: what IP law protects versus what prompts offer

The comparative assessment crystallizes through systematic comparison. Copyright protects expression—literary, artistic, or musical works reflecting the author's personality through free and creative choices. Prompts offer functional instructions—specifications about what outputs AI systems should generate rather than creative expression in their own right. Software protection protects program code—source or object code implementing computational processes. Prompts offer interfaces—natural language methods for communicating with existing programs rather than program expressions themselves. Patent protection requires technical character—solutions to technical problems using technical means producing technical effects. Prompts offer linguistic optimization—better communication methods solving cognitive and communicative problems rather than technical innovations. Trade secrets protect valuable information maintained as secret—information competitors cannot obtain through lawful means without breaching confidential relationships. Prompts offer discoverable instructions—information often reconstructible from outputs or independently discoverable through experimentation, requiring continuous secrecy maintenance that cloud architectures complicate.

The pattern is clear: EU IP law protects expression, technical implementation, and maintained secrecy—prompts offer functional instruction, linguistic optimization, and necessary disclosure. This mismatch is not accidental. Each framework embodies policy choices about what types of innovation merit exclusive rights and what must remain in the public domain to ensure competitive freedom and cumulative innovation. Copyright's idea-expression dichotomy preserves the public domain of methods, procedures, and functional instructions. Software protection's exclusion of interfaces prevents monopolization of communication methods necessary for interoperability. Patent law's technical character requirement confines exclusive rights to technical rather than cognitive or linguistic innovation. Trade secret law's conditioning protection on secrecy maintenance ensures that disclosed information enters the public domain. These boundaries are deliberate.

To that extent, prompts fall precisely within categories that EU IP law deliberately excludes from protection. They are instructions about ideas rather than expression of ideas; they are interfaces for communicating with programs rather than programs themselves; they solve linguistic and cognitive problems rather than technical problems; they require disclosure to cloud providers that complicates secrecy maintenance. The restrictive approach to prompt protection is a feature of the system, not a bug—it reflects fundamental policy judgments about preserving building blocks necessary for innovation and competition. Put differently, the system is working as designed.

### Why the mismatch is not accidental: functional instructions belong in the commons

The exclusion of prompts from robust IP protection reflects a principled judgment embedded throughout EU intellectual property frameworks: functional instructions, methods of operation, and procedures for accomplishing tasks should remain freely available for all to use and build upon. This principle manifests across multiple frameworks with consistent rationale—enabling competition, preventing monopolization of building blocks, and facilitating cumulative innovation.

In copyright, the Court's emphatic holdings in *BSA* and *SAS Institute* that functionality cannot be protected "would amount to making it possible to monopolise ideas, to the detriment of technological progress and industrial development" articulate the core concern.[^99] Protecting functional methods as literary expression would transform copyright into a patent-like monopoly without the stringent requirements of novelty, non-obviousness, technical character, and limited duration that justify patent protection. Recipes remain unprotectable as "succession of instructions, a method" despite requiring skill and experience to develop. Game rules remain unprotectable despite requiring creativity to design engaging gameplay. Operating instructions remain unprotectable despite requiring expertise to write clearly. The common thread is functional purpose—where expression serves primarily to convey methods rather than to constitute creative work, copyright does not attach.

[^99]: *BSA* (n 31) para 48; *SAS Institute* (n 43) para 40.

In patent law, the exclusion of methods for performing mental acts and presentations of information from patentability reflects the judgment that cognitive and communicative innovations should not receive exclusive rights even when they produce economic value. The EPO's insistence on "further technical effect" and "technical teaching" confines patentable subject matter to innovations that advance technology rather than merely improving how humans think, communicate, or organize activities. Natural language formulations that optimize human-AI communication remain in the cognitive domain regardless of their sophistication or value. This boundary preserves freedom to develop improved communication methods without navigating patent thickets.

Prompts are quintessential functional instructions. They specify what AI systems should do, how outputs should be structured, what constraints should be observed—exactly the type of method and procedure that intellectual property law deliberately places in the commons. Extending protection would grant exclusive rights over ways of communicating with AI systems, creating barriers to AI adoption and restricting cumulative development of prompting techniques. The current restrictive approach preserves these communication methods as building blocks available to all, consistent with long-standing policy that functional methods belong in the public domain.

### The reform question: is legislative intervention warranted?

Arguments supporting sui generis protection for prompts include: market failure from appropriability problems once disclosure occurs; innovation incentives to encourage sophisticated prompt development; recognition of investment in skill acquisition and testing; and competitive concerns if other jurisdictions provide more robust protection. However, these arguments confront substantial counterarguments that counsel restraint.

First, trade secrets combined with contractual measures, technological protections, and first-mover advantages provide meaningful protection for genuinely valuable prompts without creating exclusive rights. Businesses can maintain sophisticated prompt libraries as trade secrets within enterprise AI architectures, impose contractual restrictions through employment agreements and NDAs, implement technical access controls, and leverage temporal advantages from superior prompt engineering capabilities. This combination may provide adequate protection for most commercial models without legislative intervention.

Second, protecting prompts risks monopolizing basic communication methods necessary for effective AI use. If early prompt developers can exclude others from similar formulations, barriers to AI adoption would increase substantially. Users would face uncertainty about whether their prompts infringe others' rights, chilling experimentation and learning. The cumulative nature of prompt engineering—where techniques build incrementally on others' work through shared community knowledge—counsels against property rights that could block this iterative process.

Third, difficulty defining protection scope poses substantial challenges. Where along the spectrum from "Summarize" to 400-word system prompts should protection begin? How would courts assess substantial similarity when infinite functionally equivalent formulations exist? What would qualify as independent development versus infringement? These boundary problems suggest that any protection regime would generate substantial litigation and uncertainty costs exceeding benefits.

Fourth, the current evidence does not demonstrate market failure requiring intervention. As documented in Part II, while marketplace activity, labor markets, and productivity studies show positive economic value, the conspicuous absence of licensing markets, litigation over prompts, and regulatory recognition as distinct IP assets suggests that market participants have adapted successfully without additional legal protection. Prompt marketplaces function; businesses employ prompt engineers; innovation proceeds. The lack of market failure evidence counsels regulatory humility—waiting until clear problems emerge before legislating.

Fifth, international coordination is essential. Unilateral EU action creating prompt-specific protection could create conflicts with trading partners and fragment global innovation ecosystems. The United States Copyright Office has taken restrictive positions on AI-related protection. WIPO consultations continue. Any reform should emerge from international dialogue rather than EU-only legislation.

If reform ultimately proves necessary, the most appropriate model would be a database sui generis right focused on verification investment rather than creation investment—protecting documented systematic testing, quality assurance, and presentation investment in prompt collections against wholesale extraction, with short protection terms, narrow scope limited to preventing substantial reutilization, and broad exceptions preserving independent development, reverse engineering, and employee mobility. However, the current evidence does not support immediate legislative action. The preferable approach is monitoring market evolution, allowing judicial interpretation of existing frameworks to develop, and maintaining the current restrictive regime pending clear demonstration of market failure.

### Practical guidance for businesses under current law

For businesses seeking to protect prompt investments under current law, the analysis yields concrete guidance. What works: trade secrets protection combined with enterprise AI deployments under explicit confidentiality terms prohibiting provider use or disclosure; comprehensive internal controls including access restrictions, authentication, logging, classification, labeling, employee training, and exit procedures; documented continuous compliance since April 2019 with all protective measures; quantified performance improvements demonstrating measurable competitive advantage; and development documentation proving substantial investment in optimization and testing. German courts' proportionality framework and continuity requirement establish demanding but achievable standards—firms that maintain rigorous compliance programs can secure trade secret protection for sophisticated prompts. This is the viable path.

What does not work: consumer-tier AI services whose terms authorize provider reuse for training; informal handling practices without documented controls; generic confidentiality policies without specific implementation; retroactive designation of prompts as confidential after informal use; and reliance on copyright or patent protection absent exceptional circumstances. Simple prompts offering minimal innovation beyond common knowledge receive no protection regardless of protective measures. Intermediate prompts face evidentiary challenges and independent discovery risks that often defeat protection claims. These pathways fail predictably.

The evidentiary requirements are substantial. German courts require claimants to prove not merely that policies exist but that measures were actually implemented, enforced continuously, and effective in preventing uncontrolled dissemination. Firms must maintain detailed documentation—enterprise service agreements, internal access logs, employee training records, NDA execution proof, classification system documentation, and incident response records—demonstrating uninterrupted compliance. The burden of proof rests with the claimant. Businesses contemplating trade secret claims must assess whether their actual practices, not merely stated intentions, satisfy these demanding standards.

The CJEU's *Dun & Brandstreet* decision adds an additional layer: even successfully established trade secrets remain subject to disclosure requirements where transparency obligations under the GDPR, AI Act, or sectoral regulations outweigh confidentiality interests. Businesses cannot assume that trade secret status creates absolute shields. Courts and supervisory authorities will conduct case-by-case proportionality assessments balancing commercial interests against fundamental rights and regulatory transparency requirements. Firms must prepare for the possibility that prompts protected as trade secrets will nonetheless require disclosure in controlled settings to authorities or courts.

### The lesson: not all valuable information requires IP protection

The fundamental lesson transcends prompts: not all valuable information requires or should receive intellectual property protection. Economic value alone does not justify exclusive rights. Prompt engineering skills command professional-tier compensation; sophisticated prompts provide competitive advantages; prompt marketplaces demonstrate willingness to pay. Yet the empirical evidence simultaneously reveals structural characteristics—commoditization pressure, reverse engineering feasibility, independent discovery probability, derivative value dependent on proprietary models—that distinguish prompts from traditional intellectual property warranting robust legal protection. Value does not equal property.

Intellectual property law reflects normative judgments about which innovations merit exclusivity and which belong in the commons. Functional instructions, methods of communication, operational techniques, and procedural knowledge may appropriately remain outside property rights regimes, accessible through learning, independent development, and market competition. Prompts exemplify this category—valuable as tools and skills but excluded from protection to preserve competitive freedom and cumulative innovation. The current legal framework's restrictive approach reflects this deliberate policy choice. To that extent, businesses, courts, and policymakers should recognize that this restrictive treatment serves important systemic functions and should not be abandoned without compelling evidence that market failure requires intervention. For the present, the combination of trade secrets, contracts, technical measures, and market advantages provides adequate protection for genuinely valuable prompts while preserving the public domain of functional communication methods necessary for AI adoption and innovation. This is not a gap to be filled—it is a deliberate boundary to be respected.

## VII. Conclusion

The comprehensive examination of AI prompts across four EU intellectual property frameworks reveals a fundamental tension between traditional IP categories—designed for tangible expression, technical implementations, and maintained secrets—and novel information forms emerging from human-AI interaction. Prompts resist protection across frameworks because they embody precisely what intellectual property law deliberately excludes: functional instructions describing ideas rather than expressing them, interfaces for communicating with programs rather than programs themselves, cognitive and linguistic optimizations rather than technical innovations, and discoverable methods requiring disclosure rather than maintainable secrets. This resistance is systematic, not accidental.

This resistance is not a deficiency requiring correction through legislative intervention or doctrinal expansion. It reflects deliberate policy choices embedded throughout EU IP law about preserving the public domain of building blocks necessary for competition and cumulative innovation. Copyright's idea-expression dichotomy, software protection's exclusion of interfaces, patent law's technical character requirement, and trade secret law's conditioning protection on maintained secrecy all serve to keep functional methods, procedures, and communication techniques freely available. Prompts—as quintessential functional instructions for communicating with AI systems—fall squarely within excluded categories for sound policy reasons. Extending protection would grant exclusive rights over methods of AI interaction, creating barriers to adoption and restricting the cumulative development of prompting techniques that drives current innovation.

The minimal protection finding across frameworks does not render prompts entirely without legal recourse. Trade secrets offer a narrow but viable pathway for sophisticated prompts maintained under rigorous enterprise confidentiality frameworks—exclusive use of enterprise AI services with contractual non-use and non-disclosure clauses, comprehensive internal controls, documented continuous compliance, and substantial documented investment. However, this protection remains conditional, demanding, and ultimately provisional—subject to evidentiary burdens, continuity requirements, independent discovery risks, and potential override where transparency obligations outweigh confidentiality interests under the CJEU's *Dun & Brandstreet* framework.

The normative claim emerging from this analysis transcends prompts: not all valuable information requires or should receive intellectual property protection. Economic value—demonstrated through marketplace transactions, professional-tier compensation, and measurable productivity gains—does not alone justify exclusive rights. The empirical evidence simultaneously reveals structural characteristics distinguishing prompts from traditional IP—commoditization pressure, reverse engineering feasibility, independent discovery probability, derivative value dependent on proprietary models, and conspicuous absence of licensing markets and litigation—suggesting that market participants have adapted successfully without robust legal protection. Put differently, prompt engineering generates value as a service and as a professional skill, not as intellectual property suitable for protection through regimes designed for creative expression, technical implementation, or maintained secrets. The distinction matters.

For businesses, courts, and policymakers, the lesson is clear: the current legal framework's restrictive treatment of prompts serves important systemic functions and should not be abandoned without compelling evidence of market failure requiring intervention. The combination of trade secrets, contracts, technical measures, and first-mover advantages provides adequate protection for genuinely valuable prompts while preserving the public domain of functional communication methods necessary for AI adoption and cumulative innovation. To that extent, this is not a gap to be filled—it is a deliberate boundary to be respected.

