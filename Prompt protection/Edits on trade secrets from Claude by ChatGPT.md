Section-by-section edits follow. For sections or passages with no change, I indicate the range and say “No change.”

I. Opening vignette + introduction (first two paragraphs of the article)
No change.

II. The three-part test: secrecy, commercial value, and reasonable steps
No change, except to add one clarifying sentence at the end of the final paragraph of this section:

Old: “As we will see, these exclusions and lawful acquisition provisions become particularly significant for AI prompts, where reverse engineering from outputs and independent discovery through experimentation are both technically feasible and increasingly common.”
New: “As we will see, these exclusions and lawful acquisition provisions become particularly significant for AI prompts, where reverse engineering from outputs and independent discovery through experimentation are both technically feasible and increasingly common; however, German courts require defendants to prove that they in fact derived the disputed information through lawful observation or reverse engineering rather than merely asserting that such derivation would have been theoretically possible, which narrows the scope of the reverse-engineering defence in practice.”

III. Secrecy defeated by disclosure to cloud AI providers
Replace the first three paragraphs of this section with the following revised text.

New text for paragraphs 1–3 of this section:
“The first element – secrecy in the sense that information is ‘not, as a body or in the precise configuration and assembly of its components, generally known among or readily accessible to persons within the circles that normally deal with the kind of information in question’ – establishes an objective standard based on accessibility within relevant professional circles rather than requiring absolute secrecy. The Commission's Impact Assessment explained that this formulation allows situations where individual components may be publicly known but their specific combination or configuration remains secret; to that extent, a prompt constructed from publicly available techniques might still qualify if the precise assembly creates something not generally known. German appellate courts have applied this logic to complex technical drawings, holding that even if individual parameters could be measured or inferred from a physical product, the integrated engineering documentation that combines dimensions, tolerances, weld instructions, assembly sequence, and quality control steps can still be ‘secret’ because that compiled configuration is not readily accessible without significant time and cost.”

“Cloud-based AI services – which represent the dominant deployment model for large language models as of October 2025 – require users to transmit prompts to third-party providers with each API call or chat interface interaction. OpenAI's GPT-4, Anthropic's Claude, Google's Gemini, and similar commercial offerings process prompts on the provider's infrastructure; the prompts necessarily travel across networks and reside, at least temporarily, on systems controlled by the AI provider rather than the user. Academic scholarship examining information flows in cloud computing contexts demonstrates that third-party disclosure potentially destroys trade secret status absent express or implied confidentiality agreements establishing duties not to use or disclose the information. German courts, applying the Geschäftsgeheimnisgesetz (the German implementation of Directive 2016/943), have framed this not as a categorical bar on any third-party access but as a question of whether the third party is bound as a confidentiality recipient (a ‘Geheimnisträger’) by specific contractual obligations that restrict use and onward disclosure.”

“The question thus becomes whether contractual confidentiality provisions in AI service agreements sufficiently preserve secrecy despite physical disclosure of prompts to the provider. Enterprise AI service agreements from major providers – such as Microsoft Azure OpenAI Service, Anthropic's enterprise plans, and Google Cloud's Vertex AI – typically include provisions stating that customer prompts and data will not be used to train models or disclosed to third parties. German higher courts have accepted analogous arrangements in traditional manufacturing contexts: disclosure of CAD drawings or production instructions to a supplier under a non-disclosure agreement and access controls did not forfeit trade secret protection, because the supplier was treated as a confidentiality-bound recipient rather than as the public, and access was restricted to what was necessary. By contrast, disclosure to third parties without executed obligations of confidentiality, or disclosure through channels whose terms of service permit reuse of the information (for example, consumer-tier AI interfaces that allow providers to retain and repurpose prompts for training), is treated as evidence that the information was not maintained as secret and typically defeats both the secrecy element and the ‘reasonable steps’ element.”

Then merge with the remainder of the section, but modify the last two paragraphs of the section (“National court decisions…” and “Applied to AI prompts…”) as follows.

Old paragraph starting “National court decisions across Member States…” through “…regardless of other protective measures the holder may have implemented.”
New: “National court decisions across Member States demonstrate strict application of the secrecy requirement in contexts involving uncontrolled disclosure to third parties. Dutch courts have denied protection to technical drawings that were marked confidential but shared with outside firms without NDAs; French courts have reached similar conclusions where drawings were circulated without tailored contractual protections. German courts apply a similar functional test, but with an explicit distinction: disclosure to an external partner or service provider does not itself destroy secrecy if (and only if) that recipient is contractually bound to confidentiality, access is limited to what is necessary, and the information is labelled, access-restricted, and traceably handled. Uncontrolled disclosure, or disclosure under terms that expressly authorise the recipient to reuse or further disseminate the information, remains fatal.”

Old paragraph starting “Applied to AI prompts…” through the end of the section.
New: “Applied to AI prompts, this doctrine creates a bifurcation rather than an absolute bar. Prompts submitted exclusively through enterprise AI services whose terms prohibit the provider from using or disclosing customer prompts, combined with internal technical and organisational access controls, can in principle remain ‘secret’ for purposes of Article 2(1)(a) because the AI provider functions as a contractually bound confidentiality recipient rather than as the general public. Prompts entered into consumer-tier services whose terms authorise reuse for training or quality improvement are different: that disclosure is affirmative permission for the provider to exploit the prompts, meaning the information becomes ‘readily accessible’ to persons within the relevant technical circles at the provider. On the German view, such unprotected disclosure both undercuts secrecy and demonstrates a failure to exercise ‘angemessene Geheimhaltungsmaßnahmen.’ The secrecy element is therefore not an absolute barrier for prompts, but it is a threshold screen: only prompts used within confidentiality-bound enterprise environments and controlled internal processes even arguably satisfy Article 2(1)(a).”

IV. The puzzle of commercial value derived from proprietary models
Revise the last three paragraphs of this section to integrate German nuance on “competitive harm.”

Old paragraph starting “German courts applying the Geschäftsgeheimnisgesetz require objective proof…” through “…avoiding the need to incur those development costs.”
New: “German courts applying the Geschäftsgeheimnisgesetz require objective proof that information has economic value, and they link that proof to concrete competitive leverage. Appellate decisions have considered the information’s value to the company, the documented development costs, the nature and maturity of the information (for example, whether it is a production-ready design rather than a rough sketch), and its importance to the holder’s position in tenders or in negotiations. Courts have characterised integrated CAD drawings as valuable because they allow a competitor to quote and deliver more quickly and at lower cost, immediately improving that competitor’s position in the marketplace. Under this approach, the avoided development cost is not sufficient by itself; what matters is that disclosure lets the competitor shortcut that investment and thereby undermine the holder’s competitive position. Applied to AI prompts, this framework supports protection of prompts that deliver measurable performance gains or time-to-market advantages – for instance, significantly faster legal analysis workflows or materially higher recall in pharmacovigilance review – because those gains translate directly into competitive advantage and can be appropriated by a rival who obtains the prompt without reproducing the underlying optimisation work.”

Old paragraph starting “The causal link – ‘because it is secret’ – requires…” through “…their disclosure provides no competitive advantage.”
New: “The causal link – ‘because it is secret’ – requires that loss of secrecy would realistically erode the holder’s competitive advantage. German courts have framed this in terms of whether a rival who gains access can immediately compete more effectively, not in purely hypothetical terms. In the prompt context, prompts that encode months of task-specific tuning and produce superior, auditable results can satisfy this requirement because a competitor who copies them acquires that advantage instantly. By contrast, generic prompting tricks that any competent practitioner can reproduce with modest experimentation, and that do not materially shift bidding position, cost structure, or output quality, will typically fail the commercial value element. The inquiry focuses on competitive harm, not just aesthetic originality.”

Old paragraph starting “The better view, therefore, distinguishes…” through the end of the section.
New: “The better view, therefore, distinguishes between trivial prompting techniques, which lack protectable commercial value; intermediate prompts that offer incremental efficiency gains that are easily replicable and therefore often fail on competitive harm; and highly refined prompts whose disclosure would allow rivals to appropriate a quantifiable, performance-relevant advantage. German courts’ focus on demonstrable market leverage and saved development time maps most closely to this last category. These courts have already treated complex engineering documentation as protectable for precisely this reason. On that logic, a sophisticated ‘system prompt’ or prompt sequence that materially improves speed, accuracy, or compliance output in a way that affects the firm’s ability to win business is the closest analogue to a production-ready CAD drawing and is therefore the most likely to satisfy Article 2(1)(b).”

V. Reasonable steps in tension with cloud AI's distributed architecture
Replace and expand paragraphs 1–4 of this section to capture German proportionality, layered controls, evidentiary burden, and temporal continuity. Keep the tail of the section (beginning “Put differently, reasonable steps for AI prompts require…”) with revisions noted below.

New text for the first four paragraphs of this section:
“The third element – that information ‘has been subject to reasonable steps under the circumstances, by the person lawfully in control of the information, to keep it secret’ – requires trade secret holders to exercise what Recital 13 characterizes as a ‘duty of care’ with respect to confidentiality. The qualifier ‘under the circumstances’ establishes that measures must be proportionate rather than absolute. German courts have operationalised this proportionality requirement in the Geschäftsgeheimnisgesetz by insisting on layered, actually implemented safeguards that are sensibly calibrated to the economic value and use context of the information. They have rejected both extremes: perfect, military-grade secrecy is not required, but symbolic or purely cosmetic measures are insufficient.”

“German higher courts have articulated this proportionality analysis through a multi-factor test. The Higher Regional Court of Düsseldorf, in litigation over engineering drawings, identified factors including: the type of information; the specific circumstances of its use; the value and development cost; the nature and maturity of the information; the importance of the information to the company; the size and usual practices of the company; labelling and confidentiality markings; and contractual provisions with employees and external partners. Later decisions have treated this catalogue not as soft guidance but as the operative yardstick for whether measures were ‘angemessen.’ On that basis, courts have required three coordinated layers of protection: (i) legal measures such as NDAs with employees and suppliers, explicit post-employment confidentiality clauses, and supplier agreements restricting onward disclosure; (ii) organisational measures such as access-on-a-need-to-know basis, logged access to design repositories, employee training, exit procedures requiring return or deletion of confidential material, and internal classification of sensitive documents; and (iii) technical measures such as password-protected and role-restricted systems, VPN or similar network access controls, building access control, watermarking or confidentiality legends on documents, and the ability to revoke access or wipe devices.”

“Critically, German courts place the burden of proof on the claimant. It is not enough to assert that policies existed. The claimant must show that these measures were actually in force, enforced in practice, and effective in preventing uncontrolled spread. If confidential designs or process documents have already circulated in uncontrolled ways to external firms with no NDAs, courts infer that secrecy measures were not actually adequate. German labour courts and the Federal Court of Justice have extended this logic to employment disputes: an employer seeking injunctive relief against a former employee must prove concrete, consistently applied secrecy measures. Mere internal labelling of material as ‘confidential’ or broad boilerplate in the employment contract is insufficient.”

“A further German nuance with direct consequences for ongoing relief is temporal continuity. Since the GeschGehG entered into force on 26 April 2019, courts have required claimants seeking injunctions to prove not only that appropriate secrecy measures exist at the time of litigation, but also that such measures have existed continuously and without interruption from 26 April 2019 onward. This continuity requirement blocks attempts to ‘retrofit’ secrecy by declaring information confidential only after it has already leaked. For AI prompts, the implication is that a firm cannot plausibly recover trade secret protection over a prompt library that was historically pasted into consumer chatbots without confidentiality terms and only later brought under an internal compliance regime; German courts would likely find that uninterrupted “angemessene Geheimhaltungsmaßnahmen” were not in place.”

Now revise the paragraph beginning “The legal analytics firm in the opening vignette…” to align with the above:

Old: “The legal analytics firm in the opening vignette maintained NDAs, restricted internal access, and encrypted its prompt library – satisfying the legal and organizational prongs – but necessarily transmitted prompts to OpenAI's servers thousands of times daily through API calls. The pharmaceutical company's scientists used consumer ChatGPT accounts without confidentiality protections, clearly failing the reasonable steps test by disclosing prompts to a third party without contractual safeguards. The automotive manufacturer stored prompts in encrypted files accessible to only three senior engineers but still transmitted prompts to Anthropic's servers with each API call – potentially satisfying reasonable steps if, and only if, the manufacturer used Anthropic's enterprise service with contractual confidentiality protections.”
New: “The legal analytics firm in the opening vignette maintained NDAs, restricted internal access, and encrypted its prompt library – satisfying, on paper, the legal and organisational prongs – but necessarily transmitted prompts to OpenAI's servers thousands of times daily through API calls. Under the German proportionality model, that disclosure does not automatically defeat protection if (and only if) the firm used an enterprise-tier service governed by contractual terms that prohibit the provider from using or disclosing prompts and if the firm can show audited, access-controlled submission workflows. The pharmaceutical company's scientists, by contrast, used consumer ChatGPT accounts without confidentiality protections and allowed outputs to reveal the prompt structure to observers. That fact pattern would almost certainly fail the German ‘reasonable steps’ analysis, because it demonstrates uncontrolled disclosure, lack of binding confidentiality on the recipient, and absence of enforcement in practice. The automotive manufacturer stored prompts in encrypted files limited to three senior engineers and used them only via an enterprise deployment with contractual non-use and non-disclosure obligations; if those facts can be proven and if access logging, labelling, and employee training were in place continuously since April 2019, German courts would likely treat those measures as ‘angemessen.’”

Now revise the last two paragraphs of this section.

Old paragraph starting “The decisive question, then, is whether use of enterprise AI services…” and old paragraph starting “Put differently, reasonable steps for AI prompts require…”
New combined text:
“The decisive question, then, is not whether cloud use alone defeats protection, but whether the company can prove a proportionate, uninterrupted, and actually enforced confidentiality programme that treats the AI provider as a contractually bound confidentiality recipient rather than as the public. German courts already accept this structure in supplier relationships for technical drawings. They will ask: Were there binding contractual prohibitions on use and onward disclosure by the external recipient. Were prompts internally access-controlled, labelled, and logged. Were employees trained and monitored to avoid unprotected channels. Were these controls in place continuously, not retrofitted after the fact. These are factual questions, not hypotheticals.”

“Put differently, reasonable steps for AI prompts require a compliance architecture, not just an NDA: exclusive use of enterprise AI services with explicit non-use and non-disclosure clauses; internal access controls limiting who can view and submit the prompts; technical protections including encryption, authentication, and audit logging; classification and labelling of prompt materials as confidential; employee training and exit procedures; monitoring and incident response; and evidence that all of these measures have operated continuously since 26 April 2019. German courts treat this standard as demanding but achievable. It is also unforgiving: if a company cannot prove this level of discipline in practice, especially where employees have historically pasted the same prompts into consumer chatbots with broad training rights, ‘reasonable steps’ will likely be deemed unsatisfied.”

VI. Counterarguments: why prompts likely fail trade secret protection
Revise the “reverse engineering” discussion to reflect the German evidentiary nuance, and add a short paragraph on temporal continuity and retroactive secrecy.

Replace the first two paragraphs of this section with the following:

New text for first two paragraphs of Section VI:
“Three principal arguments challenge whether AI prompts can or should qualify as trade secrets under Directive 2016/943, each rooted in fundamental characteristics of AI systems and trade secret doctrine. First, prompts may be insufficiently secret because they are too easily reverse-engineered from AI outputs, failing Article 2(1)(a)’s requirement that information be ‘not readily accessible.’ Second, prompts may lack the independent commercial value Article 2(1)(b) requires because their value derives primarily from underlying proprietary AI models rather than the prompts themselves. Third, reasonable steps may be structurally impossible for cloud-based AI prompts, defeating Article 2(1)(c), because the fundamental architecture requires disclosure to third parties in ways that traditional trade secret doctrine did not anticipate.”

“The reverse engineering challenge rests on recent technical research demonstrating that effective prompts can sometimes be reconstructed from observing only a small number of AI outputs. On a superficial reading this appears analogous to a competitor lawfully inspecting a physical product and recreating an engineering drawing, which German law recognises as permissible reverse engineering. German courts, however, do not treat ‘it could have been reverse-engineered’ as enough. They require the alleged acquirer to prove that it in fact derived the contested information solely through lawful inspection or testing of a lawfully obtained product, without relying on leaked confidential material. This evidentiary burden narrows the defence. Applied to AI prompts, a rival would need to show that it actually recovered the operative prompt sequence only from publicly available outputs or other lawful observation, not merely that such recovery might have been possible in theory. That requirement weakens, but does not eliminate, the reverse-engineering objection to prompt secrecy.”

Keep the remainder of Section VI unchanged, except add one new paragraph before the final paragraph of this section:

New insertion before “These three challenges…”:
“A further structural objection arises from temporal continuity. German courts require claimants seeking injunctive relief to prove uninterrupted reasonable secrecy measures from the date the Geschäftsgeheimnisgesetz entered into force on 26 April 2019. For AI prompts, that continuity requirement is especially difficult. Many firms experimented with powerful LLMs via consumer interfaces lacking confidentiality clauses, circulated prompts informally among teams, and only later introduced enterprise controls. Under the German approach, that historical laxity is not cured by later lockdown. Information that was not handled as a trade secret in practice cannot usually be retroactively elevated to trade secret status for purposes of injunctive relief. This weakens claims that prompt libraries assembled under informal early-stage practices should now be treated as enforceable trade secrets.”

VII. Resolution: limited protection for sophisticated prompts under enterprise frameworks
Revise three parts: add explicit “Geheimnisträger” logic, emphasise evidentiary burden, and reflect that the German test is now embedded at appellate and supreme court level.

Edit paragraph beginning “The arguments against trade secret protection…” through “…beyond categorically excluded from protection, but subject to disclosure requirements…” as follows.

Old: “The arguments against trade secret protection for AI prompts carry substantial force, but they prove too much – if accepted fully, they would also eliminate protection for other categories of information that Directive 2016/943 was clearly intended to protect. Software source code can be reverse-engineered from compiled binaries through decompilation and analysis, yet courts routinely recognize source code as protectable trade secrets; customer lists can be independently discovered through market research, yet compilations of customer information qualify as trade secrets when they represent substantial investment; business methods must be disclosed to employees and sometimes partners to be implemented, yet they remain protectable subject to reasonable confidentiality measures. The question is not whether AI prompts present distinctive challenges – they plainly do – but whether these challenges render protection impossible or merely demanding.

The Court of Justice of the European Union's decision in Case C-203/22, Dun \u0026 Bradstreet Austria, decided on 27 February 2025, provides crucial guidance on the intersection between algorithmic information and trade secret protection, though the case addressed GDPR transparency obligations rather than trade secret validity directly. The CJEU held that controllers using automated decision-making systems must provide 'meaningful information about the logic involved' but need not disclose the algorithm itself; trade secret protection under Directive 2016/943 can justify withholding detailed algorithmic information from data subjects, though not from supervisory authorities or courts conducting proportionality assessments. The Court established that when a controller claims information contains trade secrets, the controller must provide allegedly protected information to the competent supervisory authority or court, which then balances competing rights and interests on a case-by-case basis – Austrian law creating a blanket exemption for trade secrets was impermissible. The decision thus acknowledges that algorithmic information including the logical instructions that control AI system behavior can qualify as trade secrets while emphasizing that protection is not absolute and must yield to competing fundamental rights and transparency obligations where proportionality requires.”
New: “The arguments against trade secret protection for AI prompts carry force, but they prove too much. If accepted fully, they would also eliminate protection for other categories of technical information that Directive 2016/943 was clearly intended to protect. German courts have already extended protection to production-ready engineering drawings even where individual parameters can be measured from a finished product, on the basis that the integrated, production-ready specification is economically valuable, competitively sensitive, and the product of significant investment. The same courts have also held that disclosure to external partners under strict NDAs and controlled access does not forfeit protection, because those partners function as confidentiality-bound recipients rather than as the public. This approach, which has now been endorsed both by higher regional courts and by the Federal Court of Justice, treats suppliers and service providers – and by analogy well-governed enterprise AI platforms – as permissible ‘Geheimnisträger,’ provided their contractual obligations, technical controls, and limited access can be proven.”

“The Court of Justice of the European Union's decision in Case C-203/22, Dun & Bradstreet Austria (27 February 2025), provides additional guidance at EU level on the treatment of algorithmic logic. While that case addressed GDPR transparency rather than trade secret validity directly, the Court accepted that detailed algorithmic logic and configuration instructions may constitute protectable trade secrets under Directive 2016/943. At the same time, the Court held that such protection is not absolute: controllers must still give data subjects ‘meaningful information about the logic involved,’ and supervisory authorities and courts must be able to review the full information. The Court rejected categorical statutory shields and required case-by-case proportionality. The reasoning implies that structured AI control instructions – a role often played by sophisticated ‘system prompts’ – can in principle qualify as trade secrets, but that their protection can be overridden by fundamental rights constraints where proportionality so requires.”

Now edit the subsection that begins “The resolution must therefore distinguish among prompt categories.” Keep its structure but incorporate evidentiary burden and continuity.

Old: “The resolution must therefore distinguish among prompt categories. First, simple prompts… Second, intermediate prompts… Third, sophisticated prompts…”
New: “The resolution must therefore distinguish among prompt categories. First, simple prompts that any competent user could develop through minimal experimentation – basic formatting instructions, common prompting techniques, straightforward queries – do not qualify as trade secrets because they fail all three elements: they are ‘generally known’ within professional circles using AI systems, they provide no defensible competitive leverage, and no court would view extensive secrecy infrastructure as proportionate for such material.

Second, intermediate prompts that reflect modest optimisation or domain-specific structuring occupy an unstable position. They may deliver some efficiency gains and thus arguably have commercial value, but two features typically defeat them. The first is replicability: if a skilled practitioner in the same domain can independently arrive at a functionally equivalent formulation with modest effort, the value does not derive in a meaningful way from secrecy. The second is evidentiary: firms rarely maintain uninterrupted, access-controlled, contractually protected handling practices for this class of prompt. Under German doctrine, and in particular under the post-April-2019 continuity requirement, inability to prove consistent enforcement, training, labelling, and access logging will usually defeat claims to injunctive relief.

Third, sophisticated prompts or prompt sequences that encode months of task-specific tuning, measurable performance gains, compliance-relevant behaviour, or other economically significant competitive advantages can in principle qualify as trade secrets. For this category, the German proportionality framework indicates what must be shown: use exclusively (or nearly exclusively) via enterprise AI deployments under binding confidentiality and non-use clauses; granular internal access control and labelling; technical safeguards (authentication, logging, encryption); documented training and enforcement; audited supplier / service-provider terms that treat the AI vendor as a bound confidentiality recipient; and evidence that all these measures have operated continuously and without interruption since 26 April 2019. Absent that evidentiary showing, protection will fail not on theory but on proof.”

Now update the final paragraph of the section to reflect “unforgiving but not impossible.”

Old final paragraph starting “However, the framework faces two unresolved tensions…” through the end of the section.
New: “However, the framework faces two unresolved tensions. First, no preliminary ruling from the Court of Justice has yet addressed whether third-party processing of a secret under confidentiality obligations – the ordinary case for modern AI prompts – satisfies both Article 2(1)(a)’s secrecy element and Article 2(1)(c)’s ‘reasonable steps’ element. German higher courts have effectively answered yes if (and only if) the third party is contractually bound, access is technically restricted and monitored, and the holder can prove continuous enforcement since April 2019. Dutch and French courts have signalled more scepticism toward claims that rely heavily on informal or after-the-fact confidentiality. Cross-border uncertainty therefore remains. Second, the interaction between trade secret protection and regulatory transparency duties under the GDPR, the AI Act, and sectoral regimes remains unsettled. Dun & Bradstreet makes clear that trade secret status does not create an absolute shield against regulatory disclosure: courts and supervisory authorities can compel access and then balance interests. In practical terms, firms treating sophisticated prompts as trade secrets must assume both a heavy evidentiary burden to prove uninterrupted, proportionate protection and the possibility that those prompts will still need to be disclosed to regulators or courts in a controlled setting. Trade secret protection for prompts under EU law is therefore not categorical; it is conditional on disciplined compliance and it remains subject to override where fundamental rights or regulatory transparency so require.”
