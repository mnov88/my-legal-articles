|                                                                                                                                                                                                                                             |                                                                                                             |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  |                                                                                                                                                                                                                                                                   |
| ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ----------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| Claim from the outline (summarising what the draft claims)                                                                                                                                                                                  | Evidence that the draft actually makes this claim                                                           | External verification (key sources & citations)                                                                                                                                                                                                                                                                                                                                                                                                                                                  | Credibility of external sources & notes                                                                                                                                                                                                                           |
| Student adoption is nearâ€‘universal & growing: 86â€“92% of students use AI.Â  The outline says the practice report shows surveys (e.g., HEPI, DEC) reporting 92% of UK undergraduates using AI and 86% of students in 16 countries use AI. | The practice report cites survey data (TableÂ 1) summarising multiple surveys.                              | HEPIâ€™s 2025 Student Generative AI Survey reports that 92Â % of UK students used at least one AI tool, up from 66Â % the previous year .Â  The DigitalÂ EducationÂ Councilâ€™s global survey (16Â countries) found 86Â % of students regularly use AI in their studies .Â  Another blog citing the same survey notes 24Â % daily use and 54Â % weekly use .                                                                                                                                     | HEPI is an independent UK policy institute and the survey was conducted with polling firm YouthSight; DECâ€™s survey covered 3,800 students in 16Â countries; both are credible. The daily/weekly usage numbers come from DEC and a university blog quoting it .  |
| Students use AI mainly to â€œsave timeâ€ (51Â %) and â€œimprove qualityâ€ (50Â %).                                                                                                                                                        | Report TableÂ 1 summarises HEPI survey results.                                                             | HEPIâ€™s report notes that the main reasons students use AI are saving time (51Â %) and improving work quality (50Â %) .                                                                                                                                                                                                                                                                                                                                                                         | The HEPI survey is primary research; numbers are directly reported and therefore credible.                                                                                                                                                                        |
| Students feel unprepared: 58Â % say they lack AI skills and 48Â % do not feel ready for an AIâ€‘enabled workforce.                                                                                                                          | Draft cites DEC survey.                                                                                     | The DEC Global AI Student Survey reports that 58Â % of students felt they lacked sufficient AI knowledge and skills and 48Â % felt inadequately prepared for an AIâ€‘enabled workplace .                                                                                                                                                                                                                                                                                                         | DECâ€™s survey covered 3,800 students across 16 countries and is public. Credible, though details are not peerâ€‘reviewed.                                                                                                                                        |
| 80Â % of students believe their universityâ€™s AI integration does not meet expectations.                                                                                                                                                   | Draft cites DEC survey.                                                                                     | The DEC article notes that 80Â % of students said AI in universities â€œare not fully meeting expectationsâ€ .                                                                                                                                                                                                                                                                                                                                                                                  | Same DEC survey. Reliable for perception data but not peerâ€‘reviewed.                                                                                                                                                                                            |
| Studentsâ€™ AI use for assessments jumped from 53Â % to 88Â % in one year.                                                                                                                                                                  | Report highlights this as evidence of rapid adoption.                                                       | HEPI key findings show that the proportion of students using generative AI for assessments rose from 53Â % in 2024 to 88Â % in 2025 .                                                                                                                                                                                                                                                                                                                                                            | HEPI survey credible; indicates rapid yearâ€‘overâ€‘year increase.                                                                                                                                                                                                |
| Faculty adoption is much lower: 61Â % of faculty have used AI but 88Â % of those do so â€œminimallyâ€.                                                                                                                                     | Draft cites the 2025 Global AI Faculty Survey.                                                              | The Campbell University metaâ€‘summary of recent surveys notes that the DEC 2025 Global AI Faculty Survey found 61Â % of faculty had used AI in teaching, but 88Â % of those reported minimal use .                                                                                                                                                                                                                                                                                              | Campbell University summary aggregates multiple surveys; DEC survey covers 1,681 faculty from 28 countries. Credible but not peerâ€‘reviewed.                                                                                                                     |
| Only 17Â % of faculty rate their AI literacy as advanced or expert; 40Â % say they are just beginning.                                                                                                                                      | Draft cites the same survey.                                                                                | The Campbell University summary reports that 40Â % of faculty felt they were just beginning their AI literacy journey and only 17Â % were at an advanced or expert level .                                                                                                                                                                                                                                                                                                                       | The DEC survey is credible for perceptions, but methodology details are not fully available.                                                                                                                                                                      |
| 59Â % of higherâ€‘education leaders think recent graduates are unprepared for workplaces using AI.                                                                                                                                          | Draft cites AAC&U/Elon University survey.                                                                   | Campbellâ€™s summary notes that in an AAC&U and Elon University survey, 59Â % of leaders believed that last springâ€™s graduates were not prepared for work in companies where AI tools are important .                                                                                                                                                                                                                                                                                          | AAC&U and Elon survey details are not provided in full; however, this aligns with widely reported concerns.                                                                                                                                                       |
| 39Â % of institutions have AIâ€‘use policies (up from 23Â %), indicating slow institutional response.                                                                                                                                       | Draft cites an EDUCAUSE statistic.                                                                          | The Anara â€œAI in Higher Education Statisticsâ€ report cites EDUCAUSE data: 39Â % of institutions had AIâ€‘related acceptableâ€‘use policies in 2025, up from 23Â % the previous year .                                                                                                                                                                                                                                                                                                        | EDUCAUSE is a trusted higherâ€‘education IT association; the figure is credible, though context (sample, methodology) is not detailed.                                                                                                                            |
| AIâ€‘generated lesson plans are moderateâ€‘toâ€‘low quality and rarely promote higherâ€‘order thinking.                                                                                                                                     | Draft summarises TableÂ 2, Use CaseÂ 1.                                                                     | A peerâ€‘reviewed study in CITE Journal evaluated 310 AIâ€‘generated lesson plans for eighthâ€‘grade civics. Nearly half of all learning activities were coded at the â€œrememberâ€ level, and the majority of plans were moderate to low quality, with few opportunities for analysis or creation .                                                                                                                                                                                            | This is a scholarly article; credible evidence that AI lesson plans often fail to engage higherâ€‘order thinking.                                                                                                                                                 |
| AIâ€‘generated assessments lack empirical validation.                                                                                                                                                                                       | Draft claims current research has not evaluated the quality/fairness of AIâ€‘generated quizzes and rubrics. | Emerging research contradicts a blanket statement that there is â€œno evidence.â€Â  A 2025 study in BMCÂ MedicalÂ Education generated 220 singleâ€‘bestâ€‘answer (SBA) questions with GPTâ€‘4 and found that 69Â % were fit for inclusion after expert review and that AIâ€‘generated questions performed comparably to humanâ€‘authored items .Â  Another study (field trial) reported that AIâ€‘generated exam questions performed comparably to expertâ€‘created questions after screening . | These studies show that AIâ€‘generated assessments can be valid if qualityâ€‘controlled, so the draftâ€™s claim is overstated. However, the body of evidence is still small; more validation is needed.                                                           |
| AI tutoring / chatbots deliver very large learning gains (HedgesÂ g â‰ˆÂ 1.02).                                                                                                                                                             | Draft cites Use CaseÂ 6.                                                                                    | A 2025 metaâ€‘analysis on AI in education reported a significant overall effect size (gÂ =Â 0.86) and found that chatbots and generative AI produced the largest effect (gÂ =Â 1.02, 95Â %Â CIÂ 0.45â€“1.59) .                                                                                                                                                                                                                                                                                   | The metaâ€‘analysis follows PRISMA guidelines and synthesizes multiple studies; effect sizes are credible.                                                                                                                                                        |
| Students trust AI feedback less when they know itâ€™s AIâ€‘generated (â€œcredibility crisisâ€).                                                                                                                                            | Draft references a study by Lee &Â Moore (2024).                                                            | An arXiv study comparing human, AI and coâ€‘produced feedback found that students preferred AI feedback when the source was blinded but showed a strong bias against AI when the source was disclosed; only AI feedback suffered a decline in perceived genuineness .                                                                                                                                                                                                                            | This is a preprint (not yet peerâ€‘reviewed) but provides experimental evidence of bias. It cautions that studentsâ€™ perceptions may reduce the impact of AI feedback.                                                                                           |
| AI can both enhance and harm critical thinking; frequency of use is unrelated to critical thinking skills, but using AI for reflective thinking improves criticalâ€‘thinking development.                                                   | Draft summarises PartÂ III.1.                                                                               | A systematic review of 19Â studies concluded that ChatGPT can enhance studentsâ€™ critical thinking but overâ€‘reliance can reduce motivation for selfâ€‘reflection and critical evaluation .Â  An MDPI study (XuÂ etÂ al.,Â 2025) found that usage frequency of AI was unrelated to criticalâ€‘thinking disposition, but using AI for reflective thinking was positively associated with criticalâ€‘thinking skills .                                                                           | The systematic review is peerâ€‘reviewed and synthesizes multiple studies; the MDPI article is a peerâ€‘reviewed empirical study. Both are credible.                                                                                                              |
| Students using large language models (LLMs) for research focus on a narrower set of ideas than those using traditional search; analyses become more biased and superficial.                                                                 | Draft cites this to explain cognitive harm.                                                                 | DukeÂ Universityâ€™s AI ethics toolkit summarizes research noting that in one study students using LLMs focused on a narrower set of ideas and produced more biased, superficial analyses compared with those using traditional search .                                                                                                                                                                                                                                                         | This is a blog summarizing research; it does not cite the original study by name. It is not a peerâ€‘reviewed source, but Duke Learning Innovation is a reputable academic center. Without the primary study, this evidence is suggestive rather than definitive. |
| AI systems can serve as metacognitive scaffolds: students use AI to plan, monitor and evaluate their learning; structured reflection requirements in AIâ€‘enhanced practice exams improve selfâ€‘regulated learning.                        | Draft cites PartÂ III.2 and PartÂ III.2.                                                                    | A ScientificÂ Reports study analysed 834 reflective journals and found that students used AI as a metacognitive scaffold, externalizing planning and monitoring strategies .Â  An AIâ€‘enhanced practice exam system required students to explain their reasoning and rate confidence before receiving feedback; this design increased textbook engagement, confidence and recall, suggesting structured reflection may be more impactful than sophisticated AI feedback .                       | The journal article and conference paper are peerâ€‘reviewed. They provide credible evidence that AI can support metacognition when tasks explicitly require reflection.                                                                                          |
| AIâ€‘enhanced socialâ€‘emotional learning (SEL) frameworks boost engagement and emotional wellâ€‘being; students view AI as a nonâ€‘judgmental safety net.                                                                                  | Draft cites PartÂ III.3.                                                                                    | A 2025 study in the European Journal of Education surveyed 816 Chinese EFL students; it found that an AIâ€‘enhanced SEL framework significantly boosted student engagement and emotional wellâ€‘being, improving emotional regulation and focus .Â  Qualitative reports also note that students describe AI tutors as a â€œsafety netâ€ that reduces anxiety .                                                                                                                                  | The SEL study is peerâ€‘reviewed; qualitative insights are from a separate study. Both support the claim.                                                                                                                                                         |
| There is a proposed â€œpersonalisation without isolationâ€ model: AI handles individual practice so class time can focus on social learning; however, this model lacks empirical validation.                                               | Draft identifies this as an unmet research need (GapÂ 1).                                                   | A Times of India article describes the â€œpersonalisation without isolationâ€ approach, where AI adjusts practice and teachers orchestrate discussion .Â  The article is journalistic and does not present empirical evaluation. No peerâ€‘reviewed studies implementing this model were found.                                                                                                                                                                                                 | The lack of empirical studies supports the draftâ€™s claim that this socialâ€‘learning model remains unvalidated.                                                                                                                                                 |
| The sensory dimension of AIâ€‘generated content (e.g., multisensory materials) is underâ€‘researched in higher education.                                                                                                                   | Draft notes this as GapÂ 4.                                                                                 | Searches reveal few empirical studies on AI generating multisensory educational content for higher education. Existing works focus on Kâ€‘12 tools (e.g., AI sensory activities generators) or theoretical proposals; no peerâ€‘reviewed studies specifically evaluating sensoryâ€‘rich AIâ€‘generated materials in higher education were found.                                                                                                                                                 | Absence of evidence in scholarly databases supports the claim that this dimension is a research gap.                                                                                                                                                              |
| Research gaps include (1) validation of socialâ€‘learning models, (2) quality/fairness of AIâ€‘generated assessments, (3) longitudinal effects of AI use, (4) sensory dimension, and (5) equity and algorithmic bias.                       | Draft summarises PartÂ IV.                                                                                  | Evidence gathered supports these gaps: there are few empirical studies on social models, AIâ€‘generated assessment quality is only beginning to be tested , most studies are shortâ€‘term, the sensory dimension is underâ€‘researched, and equity/bias concerns are noted in several surveys.                                                                                                                                                                                                   | This synthesis is reasonable; it aligns with our literature scan.                                                                                                                                                                                                 |
| MIT preprint â€œYourÂ Brain on ChatGPTâ€ suggests ChatGPT leads to cognitive harm: LLM users show the weakest neural connectivity, produce homogeneous writing and struggle to recall their own AIâ€‘assisted prose.                       | Draft cites PartÂ I as evidence of cognitive harm.                                                          | The MIT Media Lab preprint YourÂ BrainÂ onÂ ChatGPT reports that participants using LLM assistance exhibited the weakest neural coupling compared with searchâ€‘engine and brainâ€‘only groups; their essays were more homogeneous (fewer unique ideas) and participants struggled to recall text they had just written .Â  The preprint authors caution that the results are preliminary and not yet peerâ€‘reviewed .                                                                          | The study is a preprint, so its findings should be treated cautiously. It provides suggestive evidence but has not undergone peer review; sample size (54Â participants) is limited.                                                                              |
| Shortâ€‘term gains, longâ€‘term gaps: GenAI and search tools improve immediate performance on lowerâ€‘order tasks but not retention, and do not enhance higherâ€‘order tasks.                                                               | Draft cites PartÂ I for longâ€‘term retention concerns.                                                     | A quasiâ€‘experimental study (Shortâ€‘TermÂ Gains, Longâ€‘TermÂ Gaps) compared ChatGPT, Google search and eâ€‘textbook groups. ChatGPT and Google groups outperformed the control on immediate lowerâ€‘order tasks but their advantage disappeared over time; retention scores converged and control participants had the highest retention . For higherâ€‘order tasks, no significant differences were observed .                                                                               | This study is published via Stanfordâ€™s SCALE Initiative repository and on arXiv; it provides experimental evidence but may still be under review. Credible for suggesting shortâ€‘term vs. longâ€‘term differences.                                             |
| AIâ€‘generated assessment items lack quality/fairness research.                                                                                                                                                                             | Draft states there is little validation.                                                                    | As noted above, recent studies show AIâ€‘generated exam questions can be valid after quality control . Another 2024 field study found AIâ€‘generated questions performed comparably to expertâ€‘written ones (not shown above, but reported in practice report).                                                                                                                                                                                                                                 | Evidence now exists, so the draftâ€™s blanket claim is outdated; however, the body of evidence is still small and limited to specific domains (e.g., medicine).                                                                                                   |