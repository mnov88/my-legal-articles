
# Prompts, instruction, and EU intellectual property law

## I. Introduction

Consider three prompts. First: "Summarise." Second: "Write a formal business letter declining a job offer, emphasising gratitude for the opportunity while explaining that the decision follows acceptance of a role better aligned with long-term goals in environmental policy." Third: a 400-word system prompt that dictates tone, vocabulary constraints, citation formats, rhetorical strategies, prohibited topics, factual accuracy standards, and iterative refinement protocols.

The question this Article asks is whether any of these – ranging from the trivial to the elaborate – receive protection under European intellectual property law. The answer matters because the intuition that prompts feel valuable has hardened into commerce. Prompt marketplaces advertise six-figure catalogues, employers recruit "prompt engineers" on par with senior developers, and productivity consultancies quantify the gains that tailored prompts unlock. Yet the doctrinal position remains opaque: are prompts creative expression, technical implementations, curated databases, or secrets of enterprise practice? Put differently, do existing EU frameworks protect the language that coaxes large language models into useful behaviour?

Three further considerations elevate the stakes. First, the EU's AI Act will soon impose transparency and documentation obligations on high-risk systems, forcing firms to map the prompts that drive automated decisions. Disclosure obligations sharpen the question whether those prompts enjoy any legal shield. Second, regulators and courts will confront prompt disputes before long: when a start-up alleges that a departing engineer copied its carefully tuned system prompt, which body of law supplies the remedy? Third, the policy debate is heating up. Advocates for stronger protection argue that without exclusivity, firms will underinvest in prompt research. Skeptics worry that granting property rights over language will chill experimentation and entrench incumbents. Resolving these tensions requires a granular understanding of how existing frameworks operate.

The analysis must therefore move beyond slogans about "AI inputs" and interrogate doctrine in its full detail. The Article adopts the method that EU courts themselves employ: proceed by elimination. Start with the economic landscape to determine whether protection would address a real incentive problem. Apply the harmonised originality test and the Software Directive to assess whether prompts qualify as works or programs. Examine patent law's technical-character filter and the EPC's treatment of computer-implemented inventions. Evaluate trade secret law's tripartite test in light of cloud architectures and reverse-engineering risks. Then, synthesise the findings to understand whether any gap merits reform. The objective is not to dismiss protection out of hand, but to map precisely where and why existing law resists it.

This Article proceeds by elimination. Part II assembles the empirical case for treating prompts as candidate assets, drawing on observed marketplace transactions, labour-market valuation, measured productivity gains, and equally revealing institutional silences. Part III demonstrates that copyright and the Software Directive converge on the same conclusion: prompts are methods of operation rather than protected expression. Part IV shows why patents fail, notwithstanding claims that prompting strategies alter the technical operation of AI systems. Part V turns to trade secrets, the only framework that plausibly protects sophisticated prompts, and explains the narrow conditions under which secrecy can be preserved. Part VI crystallises the doctrinal pattern, interrogates the policy logic behind the mismatch, and considers whether narrow reform is warranted. Part VII concludes that prompts remain largely unprotected – and that this outcome reflects deliberate design choices rather than a regulatory oversight.

Two themes run throughout. First, EU IP law prioritises preserving the public domain of functional language so that innovation can compound. Second, where protection exists, it rewards process discipline and secrecy rather than textual ownership. Understanding this allocation clarifies why calls for prompt-specific rights misread the legal framework: the law already channels incentives toward responsible use and continual improvement. The analysis that follows unpacks these themes in detail.

The discussion adopts the EU's doctrinal vocabulary – originality, technical effect, reasonable steps – so that conclusions map directly onto legal practice. Each Part traces the relevant case law, policy rationales, and empirical evidence, ensuring that the resulting account can guide litigators, regulators, and businesses confronting prompt disputes.

## II. Economic rationales for protection

Economic rationales supply the first filter. If prompts lack observable value, doctrinal debate risks abstraction untethered from commercial practice. Four strands of evidence illuminate the incentives landscape: marketplace transactions, labour-market signals, measured productivity gains, and conspicuous institutional absences. Each strand supports the intuition that prompts matter economically while simultaneously exposing the fragility of their value proposition.

### Marketplace transactions

Prompt marketplaces prove that at least some users will pay for well-structured inputs. PromptBase, launched in June 2022, reports more than 370,000 registered users trading over 220,000 prompts, typically priced between €1.99 and €4.99 with the platform retaining a 20 percent commission.[^1] The catalogue includes Midjourney, DALL·E, and ChatGPT prompts; reviews and repeat sales demonstrate that buyers perceive reliability gains worth paying for. Other platforms take divergent approaches. ChatX pays contributors 39 Canadian dollars for each prompt it accepts, illustrating supply-side competition for reusable instructions.[^2] PromptHero eschews direct sales in favour of ad-supported repositories with millions of publicly viewable prompts, undercutting price points while expanding discoverability. PromptScoop advertises sellers claiming monthly earnings exceeding €30,000, although such figures lack independent verification.[^3]

However, these same facts reveal structural fragility. PromptBase caps new sellers at €4.99 per prompt until they establish sales records, signalling both quality control and limited willingness to pay. The platform withholds payouts until sellers accumulate €30, illustrating thin margins and commoditised revenue patterns. Once a prompt is sold, nothing prevents a purchaser from reposting it elsewhere or redistributing it freely; the marginal cost of copying is effectively zero. Marketplaces themselves warn users that identical prompts may generate divergent outputs, acknowledging that reproducibility is neither guaranteed nor enforceable. To that extent, the marketplace strand demonstrates minimum transactional value while simultaneously demonstrating rapid erosion of exclusivity.

This pattern replicates across the broader ecosystem. FlowGPT combines public repositories with community rating systems, treating prompts as discoverability tools rather than protectable commodities. Midjourney-focused communities publish prompt "recipes" that blend textual instructions with parameter settings, and these resources spread virally within hours. Sellers attempting exclusivity resort to private Discord servers and subscription newsletters, yet even those models rely on social norms rather than legal barriers. Morgan Stanley's deployment of GPT-4 illustrates the dynamic: the bank invested heavily in prompt design to synthesise 100,000 research reports, but rather than monetising prompts directly it protected value by embedding them within a closed wealth-management platform accessible only to employees bound by confidentiality.[^46] Market participants therefore monetise prompts indirectly – by wrapping them in services, interfaces, and consultancy – because the underlying strings do not sustain defensible scarcity.

Put differently, the commoditisation of prompts resembles the trajectory of search engine optimisation keywords in the early 2000s. Techniques that initially commanded consulting fees quickly circulated through online forums, diminishing the value of individual tips while increasing the premium on expertise capable of continually discovering new tactics. The data emerging from prompt marketplaces exhibits the same learning curve: early entrants may extract rents, but the window narrows as communities reverse engineer successful prompts and incorporate them into shared libraries. The economic signal is therefore double-edged. There is demonstrable willingness to pay for temporary advantages, yet the market structure lacks the excludability typically associated with intellectual property assets.

Marketplaces also reveal a geographic pattern. European sellers dominate categories tied to EU regulatory compliance – GDPR breach notifications, DSA transparency reports, AI Act conformity documentation – suggesting that domain expertise, rather than creative expression, drives value. Sellers frequently bundle prompts with supporting checklists, legal templates, or live workshops. These bundles illustrate how monetisation gravitates toward services that contextualise prompts rather than toward the text itself. Even when a seller offers "lifetime access" to a prompt library, the perceived value lies in promised updates and community support, not in the static prompt strings. Such business models resemble software-as-a-service subscriptions, reinforcing that recurring revenue depends on continual adaptation rather than on exclusive control over language.

Enterprise adoption follows the same pattern. Banks, insurers, and consultancies invest in "prompt operations" teams that maintain libraries tailored to internal knowledge bases. Morgan Stanley's wealth-management deployment, for example, integrates prompts with proprietary research databases, access controls, and audit trails.[^46] The prompts have value only in conjunction with these systems; outside the enterprise environment, they offer little advantage. Similar reports from consultancy firms describe prompts embedded in customer relationship management tools, where value derives from integration with workflows and compliance scripts. These examples confirm that prompts function as components of larger organisational systems rather than as freestanding intellectual property assets.

### Labour-market signals

Where individual prompts command low prices, labour markets value the expertise required to craft them. Glassdoor data from August 2025 places the average annual base salary for prompt engineers in the United States at €114,000 (US$123,803), with the interquartile range spanning €89,000 to €148,000.[^4] Coursera, analysing similar data in February 2025, reported median compensation exceeding €125,000 with total packages approaching €180,000 once bonuses and equity are included.[^5] ZipRecruiter lists lower averages – approximately €58,000 (US$62,977) – but still records upper decile offers above €90,000.[^6] Outlier roles confirm employer willingness to pay a premium. Anthropic advertised a "Prompt Engineer and Librarian" position in San Francisco offering up to €307,000 (US$335,000) annually, while Klarity sought prompt-focused machine-learning engineers at €210,000 (US$230,000).[^7]

This compensation gradient reveals two dynamics. First, firms regard prompt engineering as a scarcity skill that warrants investment comparable to senior software architecture. Second, the value attaches to human capital rather than to discrete prompt strings: the same employer rarely purchases prompts outright but instead hires staff to produce them continuously, adapt them to new models, and guard against drift. The labour market therefore evidences economic value while implying that the defensible asset is know-how, not text.

Consider Albert Phelps, profiled by the World Economic Forum as a full-time prompt engineer at Accenture. His job is not to deliver a static library of prompts but to translate shifting client objectives into bespoke instructions, monitor model responses, and fine-tune prompts to reduce token consumption – because, as he explains, "tokens equal cost" in inference billing.[^47] The firm's willingness to dedicate a specialist to this function underscores that the economic value lies in continuous optimisation. Anthropic's vacancy likewise bundled prompt engineering with knowledge management, signalling that employers expect practitioners to curate institutional memory, document prompt experiments, and educate colleagues. In-house counsel have begun revising employment contracts to clarify that prompt libraries belong to the company while skills remain portable – a legal move unnecessary if prompts themselves enjoyed robust protection.

The labour market also reveals regional disparities that illuminate nascent professionalisation. European job postings emphasise hybrid skill sets – data governance, compliance, and multilingual communication – reflecting the EU's regulatory environment. U.S. postings, by contrast, highlight creative writing and product design. Yet both markets converge on a core expectation: prompt engineers must understand the underlying models sufficiently to diagnose failure modes and craft remedial instructions. This expectation functions as a barrier to entry that sustains high salaries even as individual prompts diffuse quickly. To that extent, labour markets reinforce the conclusion drawn from marketplace evidence: economic value concentrates in the capability to generate and regenerate prompts, not in ownership of prompt texts.

Training providers have responded accordingly. Universities offer micro-credentials in prompt design, and commercial platforms such as PromptHero bundle courses on linguistics, ethics, and model evaluation.[^3] Professional associations organise "prompt clinics" where practitioners critique each other's work, emphasising process discipline. These developments mirror the evolution of compliance and cybersecurity professions: skills become institutionalised, yet the artefacts those professionals produce remain unprotected by IP law. The labour market therefore signals long-term demand for prompt expertise while simultaneously normalising the view that prompts themselves are consumables rather than assets.

### Productivity studies

Empirical productivity studies sharpen this picture. McKinsey's 2023 research on generative AI estimated annual global value gains between €2.4 trillion and €4.1 trillion, grounded in measured improvements across 63 use cases.[^8] In controlled experiments, professionals using structured prompts saw 1.5x to 2.5x productivity improvements over counterparts lacking prompt training, particularly in customer operations, marketing content, and software engineering.[^9] Follow-up studies found that developers trained in conversational prompting produced refactored code faster and reported higher task satisfaction, suggesting cognitive as well as temporal benefits.[^10] Academic surveys echo these findings: regression analysis across 243 users linked structured prompts with higher task efficiency, while experiments in software tasks recorded performance gains of roughly 16 to 18 percentage points when human-crafted conversational prompts replaced automated zero-shot instructions.[^11]

Put differently, prompt quality materially affects output quality and speed. Yet even here, attribution is complex. Productivity gains result from the integrated system – model architecture, user interface, workflow integration, and human oversight – rather than from prompts alone. The data therefore substantiates investment rationales while resisting transformation of prompt strings into discrete protectable assets.

The corporate anecdotes within these studies reinforce the quantitative picture. McKinsey documents a European insurer whose claims teams reduced processing time by 65 percent after instituting prompt playbooks that standardised how adjusters queried policy databases; without such playbooks, early pilots produced inconsistent outcomes and regulator-facing errors.[^48] A global software vendor used iterative prompt testing to cut release-note drafting from two days to two hours, with engineers reporting that structured prompts prevented hallucinated feature descriptions. In both cases, the gains depended on tightly managed prompts coupled with domain-specific guardrails and human review. Prompts therefore operate as levers within socio-technical systems rather than as standalone innovations.

At the same time, the studies expose diminishing returns when prompts escape those systems. Productivity improvements plateaued once teams internalised core prompting patterns; further gains required complementary investments in data integration, workflow redesign, and change management. McKinsey notes that organisations lacking governance frameworks often abandon pilots because prompt variations introduced compliance risk or brand inconsistency. These observations are economically salient: they explain why firms invest in prompt engineering capability yet hesitate to treat prompt texts as monetisable assets. Value accrues when prompts are embedded in processes, documented, and audited – circumstances more conducive to trade secret protection than to property rights in the text itself.

Equally important, these studies rely on self-reported or observational data rather than controlled experiments isolating the marginal contribution of prompt wording. When consultants attribute a 2x productivity increase to prompt playbooks, the measurement includes complementary factors such as employee training, dataset curation, and workflow automation. No study has demonstrated that transferring a prompt to a competitor produces the same gains absent those complements. The evidence therefore supports a nuanced claim: prompts are necessary catalysts within a larger system, but they are not sufficient drivers of value. This nuance undermines arguments for property rights premised on the assumption that copying a prompt equates to copying the value it generates.

### Conspicuous absences

The final strand is silence. If prompts possessed value comparable to traditional IP, adjacent indicators would surface. They do not. Despite three years of intense AI deployment, there are no reported licensing markets in which firms pay recurring fees for prompt portfolios. AI-related licensing has exploded elsewhere – OpenAI, for example, has concluded agreements with major publishers to license training corpora – yet none of these transactions concerns prompts themselves.[^12] Litigation provides similar negative evidence. Bloomberg Law's database tracks dozens of EU and US lawsuits concerning AI training data, copyright infringement, and model outputs. None concern prompt ownership, misappropriation, or contractual allocation of prompt rights. Insurers have not introduced prompt-specific coverage, nor have auditors developed valuation standards for prompt libraries in corporate transactions. Even the AI Act, the EU's flagship regulation, is silent on prompt economics despite cataloguing compliance costs across the AI lifecycle.[^13]

These absences matter. They suggest that sophisticated market actors do not treat prompts as autonomous assets worth litigating, insuring, licensing, or regulating. The economic picture is therefore bifurcated. Prompts enable measurable productivity gains and justify human capital investment, but the text of the prompt rarely enjoys defensible scarcity. This tension frames the doctrinal analysis that follows.

The absence of litigation is particularly revealing when contrasted with adjacent disputes. Trade secret claims over source code, customer lists, and machine-learning features populate national dockets; copyright suits over training corpora proliferate. If prompts truly underpinned durable competitive advantage, disgruntled employees carrying prompt libraries to competitors would have triggered injunction requests. Instead, the few reported disputes involve contractual confidentiality breaches in consultancy engagements, and even those settle quietly without precedent-setting judgments. The market appears to rely on contractual arrangements precisely because proprietary rights are uncertain and, in any event, would be difficult to enforce against independent development.

Regulatory silence reinforces the point. The AI Act's annexes classify risk levels, impose transparency requirements, and specify documentation obligations, yet they do not recognise prompts as a distinct asset category. During trilogue negotiations, industry stakeholders raised concerns about training data provenance, model evaluation, and human oversight, but no delegation proposed prompt protection. The conspicuous absence of prompt-specific rules in a regulation otherwise attentive to economic incentives indicates that policymakers do not perceive a market failure requiring intervention. Moreover, academic and technical communities invest in reverse-engineering research – including prompt extraction attacks that reconstruct hidden instructions from outputs – without encountering legal threats, suggesting that firms anticipate such analysis as part of the competitive landscape.[^39]

### Reverse engineering feasibility

The technical feasibility of reverse engineering underscores the fragility of prompt exclusivity. Prompt extraction attacks exploit the fact that large language models encode system prompts in their conversational context. By issuing carefully crafted queries, adversaries can coax the model into revealing its hidden instructions or infer them statistically from output variations. Researchers have demonstrated that even when providers implement guardrails, attackers can approximate prompts by analysing token probabilities across repeated interactions. Separate work on "prompt leakage" shows that output text often embeds stylistic fingerprints and canonical phrases traceable to specific prompt templates. Put differently, the output betrays the input. These techniques are lawful under Directive 2016/943 when conducted on publicly accessible systems; they fall within Article 3(1)(b)'s allowance for observation and study of products made available to the public. As a result, any prompt deployed in a consumer-facing service should be assumed discoverable regardless of contractual restrictions.

Financial reporting practice corroborates these absences. International Accounting Standard 38 prohibits recognising internally generated intangible assets such as internally developed know-how unless they meet stringent identifiability and control tests.[^59] Companies therefore cannot capitalise prompt libraries on their balance sheets, even when they believe those libraries provide competitive advantage. M&A disclosures likewise omit prompt valuations; due diligence reports focus on data assets, model performance, and contractual rights, not on proprietary prompts. The absence of accounting recognition both reflects and reinforces the perception that prompts lack the separable, enforceable qualities characteristic of intellectual property assets.

## III. Copyright and software protection: converging failures

Copyright and software protection furnish the paradigmatic route to exclusive rights over expression and code. EU law has harmonised the originality test across work categories and established a specific regime for computer programs. Both pathways converge on the same conclusion: prompts fall on the unprotectable side of the idea–expression boundary.

### The harmonised originality test

The Court of Justice has made originality the universal condition for copyright protection. Article 1(3) of Directive 2009/24/EC states that computer programs are protected when they are the author's own intellectual creation; *Infopaq* extended that formula to all subject matter.[^14] The Court's case law extracts three cumulative requirements. First, the work must reflect the author's personality – it must bear the imprint of free and creative choices.[^15] Second, those choices must not be dictated by technical function, rules, or constraints that leave no room for creative freedom.[^16] Third, only expression is protected; ideas, procedures, and methods of operation remain free for all.[^17]

These principles recur across *Painer* (photographic choices), *Brompton* (functional constraints), *Football Dataco* (skill and labour insufficient), and *Cofemel* (harmonised standard across categories).[^18] *Infopaq* itself illustrates the mechanics: even an eleven-word extract can be protectable, but only if the choice, sequence, and combination of words express creativity rather than convey bare ideas.[^19]

Crucially, the Court treats originality as a binary threshold rather than a sliding scale. A work either reflects free and creative choices or it does not; the quantity of effort expended is irrelevant. *Football Dataco* rejected the "sweat of the brow" doctrine by holding that substantial labour cannot compensate for lack of creative freedom. *Cofemel* went further, prohibiting Member States from applying lower originality standards to functional works like clothing designs. This harmonisation ensures that prompts cannot rely on national doctrines that once granted protection to utilitarian texts based on industrious collection. EU law demands evidence of personal intellectual creation regardless of the work's utilitarian purpose.

### Applying originality to prompts

Simple prompts such as "Summarise" fail immediately. Words in isolation are not protected; functionality dictates the choice.[^20] The intermediate prompt – a 33-word instruction about declining a job offer – offers more nuance but reaches the same result. The author selects tone, subject matter, and explanatory content. Yet those choices respond directly to the desired output: professional politeness, gratitude, and justification. They are communicative necessities rather than expressive flourishes. The prompt conveys the idea of the letter the user wants rather than the user's creative embodiment of that idea. Under *Football Dataco*, such functionally dictated choices do not express the author's personality.[^21]

Simple prompts also fail the fixation requirement implicit in originality. They often consist of single words or short phrases generated ad hoc in conversational interfaces. Even if a user writes "Summarise crisply with bullet points," the expression is inseparable from the function: the user chooses words purely to elicit summarisation. There is no room for self-expression because any deviation – "abridge" instead of "summarise" – risks miscommunication. Courts have repeatedly held that such dictated language lacks the personal stamp that copyright protects. The jurisprudence on headlines, slogans, and titles – uniformly denied protection absent creative flourish – provides an apt analogy.

Complex system prompts raise the strongest claim. They may stretch hundreds of words, stipulate stylistic registers, require Chicago footnotes, prohibit hallucinations, and script iterative verification. Even so, three barriers remain decisive. First, prompts are instructions about what to produce. They occupy the same analytical position as recipes, operating manuals, and game rules – forms of expression that courts routinely classify as unprotectable methods of operation.[^22] Protecting the prompt would effectively monopolise the idea it describes, contravening *BSA* and *SAS Institute*, both of which reject copyright protection for functionality and programming interfaces.[^23]

Second, prompts are functionally constrained. Optimal phrasing is dictated by model responsiveness. Prompt engineers iterate not to express personality but to elicit consistent behaviour. The same is true of technical writing and user manuals, yet courts only protect such texts when they "distinctly exceed" average formulation through creative embellishment.[^24] Most prompts seek precision, not literary flourish; their vocabulary is chosen to minimise ambiguity, not to display aesthetic judgment.

Third, even elaborate prompts present merger risks. Where only a handful of phrasings reliably induce the desired behaviour, protecting those phrasings would leave no room for alternative expression. EU doctrine does not name the merger doctrine explicitly, but *BSA*'s warning against monopolising functionality captures the point: when idea and expression converge, protection fails.[^25]

Moreover, the iterative nature of prompting undermines claims of fixed authorship. System prompts are rarely static; teams adjust them in response to model updates, regulatory feedback, and user complaints. This continuous evolution resembles the drafting of operating procedures rather than the creation of literary works. Copyright presupposes a completed act of authorship, whereas prompts exist in a state of perpetual revision. Even if one version contained creative flourishes, later revisions driven by compliance or accuracy concerns would strip away expressive elements, leaving only functional instructions. Courts would struggle to identify the "work" whose originality is assessed.

The outcome is that prompts, as instructions to an AI system, remain unprotectable ideas or methods under harmonised copyright law.

Two further considerations reinforce this conclusion. The idea–expression dichotomy, rooted in TRIPS Article 9(2) and the WIPO Copyright Treaty, reflects a constitutional policy choice: copyright protects the author's intellectual creation as manifested in expression, not the method of achieving a result. *Levola Hengelo* reiterated that only expressions meeting the originality standard qualify as works; flavours, fragrances, and other sensory experiences fall outside protection precisely because they cannot be described with objective precision.[^22] Prompts – essentially linguistic methods for guiding computation – sit on the same side of the divide as recipes and programming commands. Extending protection would blur the boundary between expression and method of operation, granting copyright monopolies over functional language.

Moreover, exceptional cases that might satisfy originality prove the rule. A novelist could embed a short story within a prompt that doubles as instruction and literary expression. Copyright would protect the narrative portion, but infringement would require copying the expressive passages, not merely adopting the functional elements. Courts have long distinguished between protectable creative prose in technical manuals and unprotectable instructional content. Applying the same logic, copyright might shield an author's poetic description embedded within a prompt, yet competitors would remain free to construct functionally identical prompts using different language. This asymmetry confirms that copyright can protect expression adjacent to prompts but cannot reach the prompt qua instruction.

Nor do moral rights alter the analysis. Moral rights in EU law attach to works that satisfy the originality threshold; they protect attribution and integrity, not functional control.[^61] Because prompts fail to qualify as works, no moral rights arise. Even if a complex prompt were deemed a work, moral rights would prevent mutilation or false attribution of the prompt text, not unauthorised use of the underlying instruction. Moral rights therefore provide no workaround for those seeking to control prompt usage.

### Software Directive analysis

Could prompts instead be protected as computer programs or preparatory design material under the Software Directive? Article 1(1) extends protection to "computer programs" and their preparatory design material. CJEU case law, however, construes both categories narrowly.

In *BSA*, the Court held that graphical user interfaces fall outside protection because they merely enable the user to operate the program; they are not themselves expressions of the program.[^26] *SAS Institute* excluded programming languages and data file formats, confirming that functionality, languages, and interfaces are ideas and principles outside copyright.[^27] The recent *Sony* judgment reaffirmed that even variable values loaded into RAM during execution constitute unprotected data rather than program expression.[^28]

Prompts fail on each axis. They are inputs to existing programs, not source or object code implementing functionality. They function as interfaces between user and model, explicitly excluded by Article 1(2). They describe what functionality to invoke rather than prescribing how to implement it. Equating prompts with programming languages underscores the point: if Python syntax is unprotectable, natural-language equivalents cannot be elevated to protected code.

Nor can prompts be rescued by invoking Article 4's protection for preparatory design material when the "nature of the preparatory work is such that a computer program can result from it at a later stage." The CJEU has consistently required a determinate causal chain between the preparatory artefact and the eventual program expression. GUIs failed because they were merely the "means by which" users access program functionality.[^26] Programming languages failed because they are methods for describing functionality rather than embodiments of it.[^27] The *Sony* court rejected protection for RAM-resident values because data manipulated during execution does not constitute the programmer's expression.[^28] Prompts share each disqualifying feature: they mediate between user and code, they specify functionality, and they consist of transient data processed during execution. Protecting them would collapse the carefully maintained line between expression and the tools used to invoke expression.

Article 6 of the Software Directive, which permits decompilation to achieve interoperability, further illustrates the policy against monopolising interfaces.[^64] The provision allows lawful users to observe, study, or test program functions to identify elements necessary for interoperability. Prompts are precisely such elements: they describe how to interact with the program. If prompts were protectable, the interoperability exception would be undermined because users could not lawfully experiment with instructions needed to ensure compatibility. The legislative design therefore treats prompts as part of the unprotected interface domain that interoperability must keep open.

Preparatory design material fares no better. Recital 7 and academic commentary explain that preparatory work must be so detailed that a computer program can result from it with minimal additional creative choices.[^29] Flow charts, pseudocode, and architecture diagrams qualify because they determine control structures. Prompts, by contrast, do not lead to program implementation; they instruct a fully implemented model. Their probabilistic outcomes – the same prompt rarely yields identical outputs – highlight the absence of deterministic design work. As Sampaio observes, the non-reproducibility of AI outputs undercuts any analogy with code specifications.[^30]

Even if one framed prompts as "instruction sequences" triggering reproduction of the model's behaviour, the Software Directive still resists protection. In *UsedSoft*, the Court allowed resale of software licences on the basis that exhaustion applied to software distributed by download, emphasising the functional nature of programs and the need to keep interfaces open.[^52] Protecting prompts as preparatory material would invert that logic by granting exclusivity over the very instructions that exhaustion keeps free. Similarly, in *Nintendo v PC Box*, the Court focused on technological protection measures securing video game software, distinguishing between code and interfaces.[^53] That reasoning underscores that protection targets program expression, not the textual commands users input. Prompts thus fall outside the Directive's protective core whether analysed as programs, interfaces, or design material.

### Database protection nuance

A residual argument invokes the Database Directive's sui generis right. If a firm curates a library of prompts, could the collection qualify as a database? The answer is a narrow "perhaps." Article 7 protects databases when there is substantial investment in obtaining, verifying, or presenting existing materials. The CJEU's *BHB* line of cases, however, draws a sharp line: investment in creating data does not count; only obtaining or verifying pre-existing data does.[^31] Applied to prompts, investment in writing them is creation, not obtaining. Only if a firm documents substantial effort in verifying prompt effectiveness or presenting a structured catalogue might the database right arise. Even then, protection covers extraction of substantial portions, not individual prompts, and retains exceptions for lawful users extracting insubstantial parts. The perverse incentive is clear: investing in prompt quality gains no protection, while investing in cataloguing prompts for retrieval potentially does.[^32]

Courts have emphasised this distinction even when it appears counter-intuitive. In *Fixtures Marketing*, the CJEU denied database protection to football fixture lists because compiling match schedules constituted creation.[^31] By contrast, databases derived from collecting existing horse-racing data qualified because they required gathering and verifying pre-existing information. Prompt libraries resemble fixture lists rather than horse-racing data: the compiler devises the content. Verification efforts – benchmarking prompts across models, logging performance metrics, and curating metadata about effective use cases – might constitute the kind of investment recognised in *BHB*. Yet such protection would extend only to the database structure; individual prompts would remain unprotected and freely usable once accessed lawfully. Database law thus offers, at most, a shield against wholesale extraction of verified prompt catalogues, not a sword conferring control over the prompts themselves.

The structure of Directive 96/9/EC confirms this narrow outcome. Article 7(5) restricts the sui generis right to preventing extraction and reutilisation of substantial parts of a database. Article 8 preserves lawful users' rights to extract insubstantial parts for any purpose.[^56] Applied to prompts, a competitor could lawfully acquire a prompt from a protected database through legitimate access and then reuse it, provided the extraction does not constitute a substantial part of the database. The right therefore guards against mass scraping of prompt repositories but not against the copying of individual prompts. Because most prompt value lies in a handful of high-performing instructions rather than in the catalogue as a whole, the database right offers little practical leverage.

Moreover, database protection expires after fifteen years, renewable only when substantial new investment is made in obtaining, verifying, or presenting the contents. Prompt libraries evolve constantly, but the relevant investment often lies in creating new prompts – an activity excluded from protection. Firms would need to document verification efforts meticulously to sustain renewal claims. Given these constraints, few prompt holders are likely to pursue database rights; the cost of evidence-gathering may exceed the limited benefit of preventing bulk copying. The legal framework thus nudges firms back toward trade secrets if they seek exclusivity.

### Scholarly consensus

Academic commentary mirrors the doctrinal conclusion. Professor He warns that recognising prompt originality risks abandoning the author-work relationship by protecting instructions divorced from expressive output.[^33] Gervais and Hugenholtz caution that transferring originality from prompts to AI outputs would "get dangerously close to owning the underlying idea," contravening international copyright principles.[^34] Quintais and Hugenholtz emphasise that EU copyright's flexibility suffices: when subject matter is dictated by technical considerations leaving no creative freedom, protection fails.[^35] To that extent, scholarly analysis reinforces the legal outcome: prompts do not satisfy the originality standard, and software law confirms rather than displaces that conclusion.

Counterarguments rely on analogies to instruction manuals and compilations. Proponents note that courts have protected complex manuals, architectural plans, and technical diagrams when they display creative arrangement. However, those cases involve narrative explanations, visual design, or aesthetic decisions beyond bare instruction. Prompts, by contrast, succeed when they suppress individual voice in favour of unambiguous directives. Another counterargument invokes collaborative prompting sessions where multiple users iteratively refine wording. Yet collaborative authorship does not relax the originality requirement; it merely multiplies the authors whose free and creative choices must be shown. Without evidence that the final wording reflects expressive judgment, the collaboration label adds nothing. Simply put, prompts fail not because they are short but because they aim to be transparent interfaces between human intent and machine execution.

A final argument posits that prompts should inherit originality from the outputs they help generate: if an AI system produces an original work, the prompt must embody the creative choices that caused it. EU law rejects this causation theory. Originality attaches to the work itself, not to the process that generated it. *Infopaq* protects the excerpt because its words, as fixed, express the author's choices. It does not protect the journalist's research notes or editorial instructions. By analogy, even if an AI output qualifies as a work, any copyright would vest in the human contributions embodied in the output, not in the prompt that triggered it. The prompt remains a method of operation – the means by which expression is produced – and therefore falls outside protection.[^23]

## IV. Patent protection: linguistic innovation lacks technical character

Patent law might appear attractive precisely because it protects functionality. Yet the European Patent Convention erects hurdles that prompts cannot surmount. Article 52(2) excludes schemes for performing mental acts, methods for doing business, programs for computers, and presentations of information. Article 52(3) qualifies the exclusion with the familiar "as such" formula, enabling patents for computer-implemented inventions that deliver further technical effects. Board of Appeal jurisprudence – *IBM* on further technical effect, *G 3/08* on technical teaching, and *COMVIK* on inventive step – determines how those provisions apply.[^36]

Prompts confront three obstacles. First, they fall squarely within the exclusions: they are linguistic instructions (methods for performing mental acts) that present information to a computer. Merely running them on hardware does not change their character, as *Pension Benefit Systems* established for business methods.[^37] Second, they provide no technical teaching. A prompt instructing a model to adopt a formal tone or to summarise concisely does not solve a technical problem using technical means; it leaves the model's architecture unchanged and relies on existing computational processes. Third, under *COMVIK*, non-technical features cannot support inventive step. Even if a prompt yields better output, its novelty lies in linguistic framing. When the claim is drafted as "a computer-implemented method using prompt X," the non-technical requirement (use prompt X) becomes part of the problem specification, and the remaining technical implementation is obvious.

Attempts to tether prompts to technical character fail. Claiming reduced token usage reframes linguistic efficiency as technical effect, but the reduction arises from communication clarity rather than from innovations in computer functioning. Embedding prompts in control systems merely shifts focus to the surrounding software; any genuine innovation lies in architecture, not in the prompt. The probabilistic nature of AI outputs compounds enforcement problems: patents require reproducible technical effects, yet identical prompts can yield divergent outputs depending on sampling parameters. Patent protection therefore remains unavailable.

The EPO's 2024 Guidelines for Examination reinforce this assessment. Part G-II, 3.3 emphasises that "schemes, rules and methods for performing mental acts" remain excluded even when implemented by technical means unless the claim as a whole produces a further technical effect beyond the normal interaction of hardware and software.[^49] The AI-specific section recognises two safe harbours for computer-implemented inventions: contributions that improve the functioning of a computer or network itself, and contributions that control a technical process external to the computer. Prompt innovation fits neither. Optimising wording to elicit clearer responses does not improve the computer; it merely adapts human communication. Steering an AI assistant that provides legal advice or marketing copy does not control a technical process external to the computer; it controls content generation. Without a demonstrable technical effect, the exclusions apply "as such."

Case law applying these safe harbours confirms the narrow aperture. In *T 1227/05* (Circuit Simulation), the Board accepted patentability because the simulation method reduced the number of required experiments on a circuit – a physical technical system. By contrast, in *T 619/02*, the Board rejected claims where the contribution lay in presenting information to the user, even though the method improved decision-making. Prompts resemble the latter: they influence human cognition or model behaviour but do not modify the operation of a technical system. No matter how artful the prompt, it lacks the kind of verifiable, technical improvement that qualifies under *T 1227/05*.

The Enlarged Board's opinion in *G 1/19* on simulation inventions underscores this boundary. The Board allowed patentability when a simulation contributes to the design of a technical system, but cautioned that purely cognitive effects remain non-technical.[^57] Prompts do not design technical systems; they guide conversational behaviour. Even when prompts are used within simulations, their contribution is the communication of requirements, not the technical modelling itself. Thus the jurisprudence on simulations, which some commentators invoke to support prompt patents, in fact bolsters the conclusion that linguistic instructions fall outside technical character.

Inventive step analysis under the COMVIK approach closes the remaining door. The Board routinely formulates the objective technical problem by incorporating non-technical features as constraints, asking what technical implementation would be obvious to the skilled person given those constraints. If a claim recites "receive prompt P and generate response R," the linguistic structure of P is a non-technical constraint. The skilled computer scientist would implement a generic parser or inference pipeline to process any given string. No inventive step arises because the ingenuity lies in crafting P – an activity outside the technical domain. By contrast, if the claim introduced a new sampling algorithm that guaranteed deterministic adherence to prompt constraints, the invention would lie in the algorithm, not in the prompt. Patent protection, therefore, incentivises algorithmic advances, not communication strategies.

Applicants have attempted to reframe prompts as "training data" or "configuration files" to sidestep these hurdles. The Guidelines address both analogies. Training data can contribute to technical character only when it is functionally linked to a technical purpose – for example, by improving image recognition accuracy through specific sensor characteristics. Prompt text lacks such linkage; it merely directs the model's behaviour in natural language. Configuration files may be patentable when they define control parameters for hardware, but prompts do not fix external parameters – they request behaviour. EPO examining divisions therefore routinely treat prompts as non-technical features to be ignored in the inventive-step analysis, leaving nothing inventive once the non-technical requirement is stripped away.

Applicants sometimes propose hybrid claims that combine prompts with bespoke model architectures, arguing that the prompt-architecture pair yields a technical effect. The EPO will dissect such claims. If the architecture delivers a further technical effect independent of the prompt – for instance, by reducing latency through novel caching – the claim may succeed, but the patent will protect the architecture, not the prompt. If the architecture merely ensures the model follows the prompt more faithfully, the contribution remains linguistic. Similarly, claims to "prompt compilation systems" that store, rank, and deploy prompts falter because the inventive contribution lies in selecting prompts based on qualitative criteria – a non-technical activity – while the technical implementation reduces to generic database management.

Board of Appeal decisions on data structures reinforce this conclusion. In *T 1784/06*, the Board held that a data structure describing a chemical compound lacked technical character because it conveyed information content without affecting a technical process. In *T 1194/97*, the Board refused protection for record carriers defined by information that had purely cognitive content. Prompts operate at the same level: they shape the information communicated to a system but do not alter the technical functioning of the system. Unless the claim integrates prompts into a technical mechanism – which would shift the inventive concept away from the prompt – the Board will disregard the prompt when assessing inventive step. The jurisprudence thus systematically filters out attempts to dress linguistic innovations in technical clothing.

## V. Trade secrets: a narrow and fragile refuge

Trade secret law offers the only plausible shelter for prompt investments. Directive (EU) 2016/943 protects information that is secret, has commercial value because it is secret, and has been subject to reasonable steps to keep it secret. Applying this tripartite test to prompts reveals both possibilities and structural fragility. The analysis proceeds in five steps: secrecy, commercial value, reasonable steps, counterarguments, and resolution.

### Secrecy under cloud architectures

Secrecy demands that information not be generally known or readily accessible within the relevant circles. Prompts encounter two disclosure vectors: transmission to AI providers and leakage through outputs. Cloud providers process prompts on infrastructure they control; unless contractual safeguards bind them, disclosure may destroy secrecy. Enterprise agreements for services such as Microsoft Azure OpenAI, Anthropic's enterprise tier, and Google Vertex AI typically include covenants not to use prompts for training or to disclose them to third parties. German courts applying the Geschäftsgeheimnisgesetz treat such recipients as confidentiality holders (*Geheimnisträger*) when NDAs, access restrictions, and labelling are in place.[^38] By contrast, consumer-tier interfaces often reserve rights to reuse prompts for service improvement. Using those services constitutes voluntary disclosure to actors squarely within the "circles that normally deal with" prompt information – engineers at the provider. On the German proportionality analysis, such disclosure defeats secrecy and evidences failure to adopt adequate measures.

Reverse engineering introduces a second risk. Recent technical research demonstrates that prompts can be reconstructed, wholly or partially, from observable outputs, particularly when systems expose conversation histories or when statistical techniques infer latent instructions.[^39] If prompts are readily ascertainable through legitimate observation, they fail the secrecy element. The analysis must therefore distinguish between prompts used in closed enterprise deployments with limited output exposure and prompts deployed publicly where users or competitors can infer their structure.

Cloud architecture compounds these risks through logging and telemetry. Providers typically retain prompt data in audit logs for security monitoring and abuse detection. Unless service-level agreements explicitly limit retention and access, engineers, trust-and-safety teams, or subcontractors may review prompts during incident response. German courts have held that disclosures to subcontractors without tailored NDAs destroy secrecy, even when the prime contractor promises confidentiality. Firms relying on enterprise AI services must therefore map the entire processing chain, ensuring that every entity with potential prompt access is contractually bound and technically restricted. Encryption in transit and at rest, segregation of tenant data, and deletion commitments become relevant not merely for data protection compliance but for maintaining trade secret status.

Dutch and French courts provide cautionary examples. In the Netherlands, the District Court of Midden-Nederland refused trade secret protection for technical drawings shared with suppliers absent explicit contractual controls, emphasising that mere confidentiality legends do not suffice. The Paris Court of Appeal similarly denied protection where a company distributed process instructions to partners without rigorous access restrictions. These decisions pre-date widespread AI adoption but translate directly: sharing prompts with marketing agencies, contractors, or integrators without bespoke confidentiality undertakings jeopardises secrecy even if internal policies prohibit onward disclosure. The lesson is straightforward – trade secret status follows actual practice, not aspirational policy.[^51]

### Commercial value because of secrecy

The second element requires both commercial value and a causal link between value and secrecy. Prompt marketplaces, professional salaries, and productivity gains demonstrate baseline value. Yet the question is whether secrecy preserves a competitive advantage. For simple prompts, the answer is no; competitors can derive equivalent instructions quickly. For sophisticated prompts – those reducing hallucinations, harmonising brand voice across thousands of documents, or unlocking proprietary data retrieval – secrecy can preserve an advantage by preventing free-riding on costly experimentation. German courts assess whether disclosure would appreciably damage the holder's competitive position.[^40] Evidence of systematic A/B testing, performance metrics, and integration into revenue-generating workflows supports the causal link.

Documented customer impact strengthens this argument. Marketing agencies that maintain confidential prompt playbooks ensure that clients receive consistent brand voice across campaigns; if competitors gained access, they could replicate the agency's differentiated tone without investing in experimentation. Financial institutions use prompts to encode regulatory compliance rules into automated drafting assistants; disclosure would allow rivals to shortcut the compliance knowledge embedded in those prompts. In litigation, parties have quantified prompt development costs in the seven figures, reflecting salaries, human-in-the-loop evaluation, and integration with proprietary data lakes. Such evidence aligns with German jurisprudence requiring proof that secrecy enables measurable competitive leverage.

Nevertheless, courts scrutinise whether value inheres in the prompt or in the underlying model. A prompt that performs well only because it accesses a proprietary fine-tuned model may fail the causal test: the advantage flows from the model, not the prompt. Businesses must therefore demonstrate that prompt secrecy, not merely model access, produces the advantage. Documentation showing that alternative prompts underperform on the same model, or that disclosure enabled a competitor to match performance quickly, will prove decisive. Absent such evidence, the commercial value element collapses into a general claim that the organisation uses AI effectively – a proposition insufficient for trade secret protection.

Consider a pharmaceutical company that develops prompts to triage research literature. If the company can show that its prompts reduce review time by 60 percent, that the prompts embed proprietary ontologies, and that competitors replicating the prompts could avoid costly experimentation, the commercial value element strengthens considerably. By contrast, a marketing agency claiming trade secret protection over a generic "brand voice" prompt without metrics or documentation is likely to fail. The Directive's emphasis on demonstrable harm – economic loss, undermined market position, or weakened strategic advantage – requires evidence tied to the prompt's secrecy. Firms must therefore quantify the benefits of secrecy, not merely assert them.

### Reasonable steps to maintain secrecy

Reasonable steps constitute the directive's most demanding limb. German jurisprudence supplies a nine-factor proportionality framework assessing legal, organisational, and technical measures. Three layers emerge. Legally, firms must execute NDAs with employees and partners, incorporate confidentiality clauses into enterprise AI agreements, and align with Article 28 GDPR processor obligations where personal data is processed.[^41] Organisationally, they must implement role-based access controls, maintain prompt inventories with classification markings, log access, and train staff on permissible use – especially banning consumer-tier AI services for sensitive prompts. Technically, they must encrypt prompt repositories, enforce multi-factor authentication, deploy data loss prevention tools, and monitor exfiltration.[^42]

A temporal dimension compounds the burden. German courts require continuity: measures must exist before misappropriation, not retroactively. Documentation must evidence consistent application. The EUIPO's trade secret litigation trends highlight that courts scrutinise whether protective measures operate in practice, not merely on paper. Using consumer AI services after adopting stricter policies undermines claims that reasonable steps were taken.

The nine-factor framework, articulated by the Higher Regional Court of Munich and increasingly adopted elsewhere, asks whether protective measures are appropriate to the value of the secret, proportionate to the risk, technically feasible, legally compliant, and continuously audited. For prompts, this means creating detailed prompt registers, version-controlling updates, recording which employees access each prompt, and conducting periodic penetration tests on collaboration platforms. Companies must evidence that these measures predate the disputed disclosure – a point underscored by German courts insisting that safeguards be in place since at least April 2019, when the Geschäftsgeheimnisgesetz entered into force. Policies adopted after the fact, or lacking documented enforcement, fail the test.

In practice, courts have examined granular indicators such as whether prompts were marked confidential, whether access was limited to named employees, whether external consultants signed tailored NDAs, whether logs captured exports from prompt repositories, and whether incident response protocols were tested. They also consider whether the firm monitored compliance, disciplined breaches, and updated controls following audits. For multinational groups, evidence that subsidiaries applied equivalent safeguards matters; a single weak link can undermine the "reasonable steps" showing. Prompt holders should therefore treat the nine factors as an operational checklist embedded in corporate governance, not as abstract legal doctrine.

Cross-border deployments add complexity. A European firm using a U.S.-hosted AI service must ensure that confidentiality obligations extend through subcontracting chains governed by foreign law. Courts consider whether firms audited providers, negotiated data localisation options, and assessed export-control implications. The "reasonable steps" inquiry thus evolves into a holistic governance assessment. Prompt secrecy is plausible only for organisations willing to invest in compliance-grade controls comparable to those used for source code, chemical formulas, or algorithmic trading strategies.

Recent jurisprudence adds an external check. In *Dun & Bradstreet Austria*, the CJEU held that controllers may withhold algorithmic logic on trade secret grounds only subject to proportionality review by authorities and courts.[^43] Applied to prompts, this means secrecy claims cannot defeat GDPR or AI Act transparency obligations automatically; firms must be prepared to disclose prompts to regulators under protective orders. Trade secret status therefore coexists with potential compelled disclosure.

### Regulatory intersections

The AI Act will intensify this balancing exercise. High-risk system providers must maintain technical documentation, including descriptions of prompts if those prompts form part of the system's instructions. Recital 106 recognises that intellectual property interests must be respected but insists that trade secrets cannot justify withholding information from competent authorities. Providers must therefore design compliance playbooks that allow disclosure under confidentiality while preserving protection against competitors. This may involve creating redacted versions of prompts for regulatory submission, backed by affidavits explaining why public disclosure would cause harm. The GDPR's transparency obligations add another layer: data subjects may request "meaningful information about the logic involved" in automated decisions. Firms must articulate how prompts influence outputs without revealing the full text. *Dun & Bradstreet* instructs authorities to mediate these tensions, but the operational burden falls on firms to maintain granular documentation that can be shared selectively.

### Case study: analytics prompts in litigation

The dynamics become concrete when mapped onto the litigation scenario sketched in the introduction to this Part. A legal analytics firm spends €2.3 million developing prompts that extract structured insights from court decisions. When a competitor's outputs begin to mirror its own, the firm sues for trade secret misappropriation. To prevail, it must demonstrate that the prompts were used exclusively within an enterprise deployment (satisfying secrecy), that the prompts' secrecy drove commercial value (evidenced by increased sales and efficiency), and that comprehensive controls were in place (documented NDAs, access logs, and incident response). The defendant can rebut by showing independent development or by pointing to prompt extraction research suggesting that the prompts were ascertainable from the plaintiff's public outputs. The case illustrates how trade secret litigation will hinge on factual proof rather than doctrinal novelty: courts will examine contracts, logs, and technical safeguards, not abstract claims about prompt creativity.

### Counterarguments

Four counterarguments test the limits of trade secret protection. First, reverse engineering: if competitors can deduce prompts from outputs, trade secret status evaporates. The response is factual – sophisticated prompts embedded in internal workflows may resist reconstruction, especially where outputs are internal and models apply additional safeguards. Second, independent development: trade secrets confer no exclusivity against independent discovery. Given that prompt engineering relies on experimentation accessible to any skilled user, rivals may legitimately arrive at similar prompts. This limits the scope of protection to misappropriation, not market exclusivity.

Third, structural impossibility: some argue that because prompts must be disclosed to AI providers, secrecy cannot be maintained. *Dun & Bradstreet* undercuts that absolutist view by recognising algorithmic logic as protectable trade secrets, subject to balancing. Contractually bound providers can serve as confidentiality recipients. Fourth, evidentiary burdens: proving reasonable steps requires meticulous documentation. Firms lacking comprehensive governance will struggle to establish trade secret status even for valuable prompts.

These counterarguments expose the thin line prompt holders must walk. Reverse engineering is increasingly practical: researchers have demonstrated extraction attacks that recover system prompts from black-box APIs by analysing output perturbations, while prompt-injection exploits can coerce models into revealing hidden instructions.[^39] Firms cannot rely on legal claims to stop such analysis; they must harden systems technically. Independent development likewise looms large because prompt engineering builds on shared best practices – "chain-of-thought," "tree of thought," "role prompting" – disseminated through academic papers and community forums. Courts will be sceptical of claims that a competitor's similar prompt must have been stolen when public resources teach analogous techniques.

Independent development also interacts with labour mobility. Employees trained in prompt engineering carry their skills to new employers. Directive 2016/943 expressly safeguards employee mobility and the use of experience and skills honestly acquired.[^41] Plaintiffs must therefore show that departing employees misappropriated tangible prompt artefacts or confidential documentation, not merely that they remembered effective prompting techniques. This requirement substantially limits litigation prospects: companies cannot prevent skilled employees from applying what they have learned, even if that knowledge enables competitors to build similar prompts. The policy favouring labour mobility thus acts as an implicit cap on the reach of prompt trade secrets.

### Resolution

The resolution is therefore categorical. Simple prompts never qualify. Intermediate prompts – domain-specific templates with modest experimentation – rarely qualify because the cost of comprehensive protection outweighs their value and because independent development is likely. Sophisticated prompts – multi-layered instruction sets integrated into proprietary systems, supported by performance data, and confined to enterprise deployments under strict controls – can qualify, but only alongside exhaustive legal, organisational, and technical measures. Even then, protection is fragile: compelled disclosure to regulators remains possible, reverse engineering is a constant risk, and independent discovery undermines practical exclusivity. Trade secret law offers a narrow refuge rather than a comprehensive solution.

To operationalise this, firms should tier their prompt inventories. Category A prompts – simple "summarise" or "rephrase" instructions – can be treated as non-confidential. Category B prompts – tailored templates for recurring tasks – warrant limited controls, such as access restriction to specific teams and logging. Category C prompts – mission-critical system prompts embedding compliance rules, safety filters, or domain-specific heuristics – demand the full panoply of trade secret measures. This tripartite model mirrors German case law distinguishing trivial, regular, and high-value secrets. It also aligns with resource allocation: only Category C prompts justify the expense of enterprise AI contracts, technical hardening, and continuous audits.

Ultimately, trade secrets protect process, not text. Organisations must invest in governance frameworks that document prompt development lifecycles, capture experimental evidence, and demonstrate enforcement. Failing that, courts will view prompt claims as attempts to backdoor quasi-copyright protection into functional language, a manoeuvre Directive 2016/943 does not support. The fragility of protection should inform commercial strategy: rely on secrecy where feasible, but expect leakage and plan for rapid iteration.

Remedies likewise shape incentives. Even when misappropriation is proven, Directive 2016/943 limits monetary relief to compensation for actual prejudice suffered.[^63] Courts may order injunctions, delivery up, or destruction of infringing materials, but they cannot grant monopoly-style damages for hypothetical licence fees. This remedial structure confirms that trade secret protection is defensive: it prevents unfair competition but does not create positive rights to exclude the world. Prompt developers must therefore combine legal controls with rapid innovation cycles, accepting that litigation offers only partial relief.

## VI. Comparative analysis and path forward

### Crystallising the doctrinal pattern

Synthesising the preceding parts reveals a consistent structure. EU intellectual property law protects creative expression, technical implementation, and information kept secret through sustained effort. Prompts provide functional instruction, linguistic optimisation, and often require disclosure. Table 1 summarises the mismatch:

| Framework | Legal requirement | Prompt characteristics | Outcome |
|-----------|-------------------|------------------------|---------|
| Copyright/Software | Author's own intellectual creation; expression not functionality | Functional instructions; vocabulary dictated by output optimisation | Fails originality; idea–expression boundary blocks protection |
| Patent | Technical character; further technical effect; inventive step rooted in technical features | Linguistic framing; no technical teaching; probabilistic outcomes | Excluded subject matter; no inventive step |
| Database | Substantial investment in obtaining/verifying/presenting data | Investment lies in creating prompts; verification/presentation possible | Only curated libraries with documented verification may qualify |
| Trade secrets | Secrecy, commercial value because secret, reasonable steps | Disclosure to providers; value tied to know-how; governance burdens | Narrow protection for enterprise-grade prompt systems |

The pattern is clear: where EU law protects expression, prompts offer instructions; where it protects technical effects, prompts offer linguistic strategies; where it protects secrecy, prompts require disclosure. To that extent, doctrinal failure is not aberrational but endemic.

This synthesis also reveals why litigants will struggle to forum-shop. A claimant seeking copyright protection must persuade a court that prompts exhibit free and creative choices despite functional dictates – a tall order under *Infopaq*. Pivoting to software law triggers the *SAS Institute* barrier against protecting programming interfaces. Turning to patents runs into the EPC exclusions. Resorting to trade secrets shifts the inquiry from substance to process, demanding proof of governance rather than originality. Each framework rejects prompts for different reasons, yet the reasoning converges on a common intuition: prompts are interfaces. Interfaces exist to enable others to act. EU IP law has consistently resisted granting exclusivity over interfaces, from plug shapes to APIs, because doing so would impede interoperability and cumulative innovation.

The table also highlights how the same factual predicate produces divergent doctrinal responses. Consider a company that documents exhaustive experimentation to craft a prompt reducing hallucinations. Copyright dismisses the claim because the language remains functional. Patent law dismisses it because the improvement lacks technical character. Trade secret law, however, rewards the same experimentation if the firm can maintain secrecy. This asymmetry reflects deliberate policy: copyright and patent law serve public dissemination goals and therefore avoid granting rights over methods of operation; trade secret law serves investment-in-secrecy goals and therefore tolerates exclusivity where secrecy persists. Businesses must decide which goal they pursue – dissemination or secrecy – because EU law does not offer hybrid protection.

### Why the mismatch is deliberate

This mismatch is not accidental. EU IP law embodies a policy choice to exclude functional instructions, methods, and ideas from exclusive rights. The InfoSoc and Software Directives enshrine the idea–expression dichotomy to preserve the public domain of methods of operation. Patent law's technical-character requirement keeps non-technical innovations outside monopolies. Trade secret law conditions protection on secrecy precisely to encourage investment in information that remains within the holder's control. Prompts epitomise the excluded category: they are methods for communicating with machines. Granting exclusivity would risk monopolising building blocks of digital communication, undermining interoperability and cumulative innovation – the very concerns the CJEU highlighted in *SAS Institute* and *BSA*.[^44]

The legislative history confirms the intent. During debates on the Software Directive, the Commission rejected proposals to protect user interfaces because doing so would entrench dominant software vendors. The same reasoning underlies the Database Directive's distinction between obtaining and creating data: the legislature sought to reward investment in compilation while leaving generative creativity to copyright. Patent reform discussions at the EPO likewise emphasise that purely linguistic innovations belong outside the patent system to avoid crowding out experimentation. Prompts combine all three excluded characteristics – interface, creative method, and linguistic instruction – making their exclusion the predictable outcome of deliberate design choices.

Economically, this design preserves competitive neutrality. If prompts were protectable, incumbents with large prompt libraries could erect barriers to entry by claiming exclusive rights over communication patterns. Start-ups experimenting with alternative phrasings would face infringement risk, slowing the iterative cycle that currently drives prompt innovation. By refusing protection, EU law channels competition toward service quality, model fine-tuning, and governance – areas where consumers benefit from diversity. The policy choice therefore aligns with the EU's broader objective of promoting interoperability and preventing lock-in in digital markets.

Normatively, the exclusion of prompts respects freedom of expression. Prompts are linguistic instructions; granting exclusive rights over their phrasing would constrain how users communicate with machines. The CJEU has repeatedly stressed that copyright and patent rights must balance with fundamental freedoms, including the Charter's guarantee of freedom of expression.[^58] Keeping prompts outside proprietary control ensures that individuals can experiment with language, remix prompting techniques, and share best practices without fear of infringement. The public domain of functional language – from recipes to programming syntax – remains intact.

### The reform question

Should the EU legislate nonetheless? The empirical record counsels caution. Marketplaces exist but reveal commoditised pricing; labour markets reward skill, not textual assets; productivity gains are real but arise from integrated systems; licensing, litigation, and regulation remain silent. This does not evince systemic market failure. Trade secret law, contracts, and technical safeguards enable firms to protect the small subset of prompts that deliver durable competitive advantage. First-mover advantage and ongoing iteration further blunt free-riding.

If reform were pursued, the least disruptive model would mirror the sui generis database right but focus on documented verification investment. Protection would extend only to preventing wholesale extraction of curated prompt repositories whose value lies in tested performance metrics, not to individual prompts or to independent development. Duration would be short – five to ten years – and exceptions for reverse engineering, employee mobility, and public-interest uses would be mandatory. Even so, current evidence does not establish that innovation will stall without such a regime. The safer course is to allow case law to mature, particularly on trade secrets and any emerging copyright disputes, before constructing new rights.

Creating a new right without clear evidence of underinvestment risks unintended consequences. Prompt engineering thrives on cumulative experimentation; researchers publish prompting techniques, and communities iterate publicly. A property right could chill this exchange, pushing innovation into proprietary silos and disadvantaging smaller actors. Enforcement would also be complex: determining whether one prompt is substantially similar to another requires qualitative judgment ill-suited to rapid litigation, inviting strategic claims and forum shopping. The EU has already confronted similar problems with the database right, which critics argue has delivered limited economic benefit while spawning litigation over trivial extraction. Replicating that experience for prompts would be imprudent absent compelling data.

Comparative experience offers little support for new rights. Neither the United States nor China has enacted prompt-specific protection despite robust debate on AI regulation. The U.S. Copyright Office has reiterated that prompts lack sufficient human authorship to ground registration.[^50] Chinese scholarship – including Professor He's analysis[^33] – warns against expanding copyright to cover prompts. Jurisdictions experimenting with sui generis data rights, such as the United Kingdom's database right, have not reported transformative benefits. The absence of international movement suggests that unilateral EU action would create friction without clear competitive gain.

A more promising avenue is soft law. Industry consortia could develop certification schemes for prompt governance, enabling firms to signal that they maintain trade secret-compliant controls. Regulators could encourage disclosure of prompt governance practices within AI Act conformity assessments, enhancing transparency without conferring exclusivity. These tools address the real concern – responsible prompt management – while avoiding the pitfalls of new property rights. Reform, if it comes, should emerge incrementally from such governance experiments rather than from sweeping statutory innovation.

### Practical guidance for businesses

Absent reform, firms must navigate the existing landscape pragmatically. Trade secrets and contracts offer workable protection only when prompts remain within enterprise AI services featuring confidentiality covenants, combined with rigorous governance. Consumer-grade interfaces, informal sharing, and absent documentation destroy secrecy and weaken evidentiary positions. Firms should document prompt development costs, maintain performance logs, and adopt incident response plans – practices that German courts recognise when assessing reasonable steps.[^45] Conversely, firms relying on ad hoc prompting, lacking access controls, or tolerating shadow AI usage should not expect legal remedies.

Practical compliance therefore entails three pillars. First, contractual architecture: negotiate enterprise agreements that prohibit prompt reuse, ensure data segregation, and provide audit rights. Second, organisational discipline: maintain centralised prompt repositories with approval workflows, require employees to certify compliance, and log every prompt deployment to establish continuity. Third, technical safeguards: implement input and output monitoring to detect prompt leakage, use watermarking or canary phrases to identify unauthorised disclosure, and deploy intrusion detection tuned to prompt exfiltration attempts. Regulators and courts will expect this triad, especially in high-risk sectors subject to the AI Act's governance requirements.

Firms should also prepare evidentiary packages in advance. When a dispute arises, courts will request documentation showing who created a prompt, how it was tested, which controls protected it, and how quickly the firm reacted to suspected leakage. Maintaining "prompt dossiers" – compilations of design notes, testing logs, access histories, and contractual undertakings – enables rapid response. These dossiers mirror the documentation already required for software export controls and pharmaceutical manufacturing, illustrating that prompt governance can borrow from established compliance disciplines. Companies that treat prompt engineering as a regulated process rather than an ad hoc creative exercise will be best positioned to defend their interests.

Embedding these practices requires organisational champions. Many firms establish cross-functional "prompt councils" involving legal, compliance, security, and product teams. The council approves new prompts, reviews incident reports, and coordinates responses to regulatory enquiries. Integrating prompt governance into existing risk management frameworks (ISO 27001, SOC 2, or GDPR accountability programmes) reduces duplication and ensures that prompt controls benefit from mature auditing procedures. As regulators scrutinise AI deployments, such institutional structures will become critical evidence that firms acted diligently.

### Conclusion of the comparative analysis

The doctrinal synthesis yields a practical insight: prompts receive minimal protection because EU IP law is engineered to shield expression, technical innovation, and controlled secrecy – categories prompts rarely satisfy. Rather than a gap awaiting legislation, the framework reflects a deliberate commitment to keeping functional instructions in the commons. Businesses must therefore align their strategies with this reality: invest in people, processes, and systems rather than in expectations of proprietary rights over words supplied to machines.

The comparative perspective also reframes expectations about future disputes. Instead of seeking property rights over prompts, firms should anticipate conflicts over misrepresentation (when vendors overstate exclusivity), over compliance (when prompt leakage triggers regulatory scrutiny), and over contractual allocation of responsibilities (when enterprise customers demand evidence of secrecy controls). EU law channels prompt-related incentives into governance rather than exclusivity. Recognising this channel helps firms allocate resources efficiently and prepares policymakers to evaluate whether any future intervention would disturb a finely balanced system.

This framing also clarifies the evidentiary posture regulators will adopt. Competition authorities assessing AI markets will examine whether dominant firms abuse contractual leverage to restrict prompt experimentation, not whether they own prompt IP. Data protection authorities will examine whether prompts encode discriminatory logic, not whether they are protected as works. Consumer protection agencies will scrutinise whether vendors mislead customers about "proprietary prompts". These inquiries align with existing regulatory competencies, suggesting that prompt disputes will be resolved through established doctrines rather than through new rights. The comparative analysis thus maps a coherent governance ecosystem in which prompts remain open, innovation continues, and accountability operates through transparency and contractual discipline.

### International outlook

The EU's restraint mirrors global practice. In the United States, prompt disputes are handled through contract and trade secret law; courts have not recognised stand-alone prompt rights. Chinese policy debates focus on regulating AI outputs and training data, not on prompt protection, reflecting similar concerns about maintaining open innovation spaces.[^33] The United Kingdom's post-Brexit IP review likewise emphasised protecting data and algorithms while leaving prompts in the public domain.[^60] This convergence reduces the risk that EU firms will face competitive disadvantages abroad. It also means that any EU experiment with prompt-specific rights would create cross-border friction, as enforcement would be difficult outside the Union. Coordination through WIPO or OECD forums could revisit the issue if empirical evidence shifts, but for now, the international landscape supports the EU's choice to rely on existing doctrines.

### Future research agenda

Several empirical gaps remain. First, comprehensive data on prompt marketplace revenues, resale behaviour, and enforcement actions would illuminate whether commoditisation persists or whether niches emerge where exclusivity could be justified. Second, case studies of enterprise prompt governance – including incident reports and regulator feedback – would help refine the "reasonable steps" analysis. Third, technical research on prompt leakage and extraction should be integrated with legal analysis to determine when reverse engineering becomes so trivial that secrecy claims collapse. Addressing these questions requires collaboration among lawyers, economists, and computer scientists.

Policy-makers should also monitor how AI models evolve. If future architectures internalise prompts (e.g., through learned system instructions) or if providers restrict user prompting in favour of API-based configuration, the economic landscape could shift. Such developments might reduce the relevance of prompt text while increasing the importance of configuration metadata, prompting a fresh examination of database and software protection. Until then, the evidence supports cautious observation rather than legislative intervention.

## VII. Conclusion

Prompts illuminate a recurring tension in EU intellectual property law. They demand investment, confer competitive advantages, and yet resist classification as protectable works, inventions, or databases. Copyright and software law exclude them as functional instructions. Patent law excludes them for lack of technical character. Trade secrets protect them only when secrecy is obsessively maintained and only against misappropriation, not independent discovery. This restrictive outcome is a feature, not a bug. EU law deliberately reserves exclusive rights for creative expression, technical innovation, and confidential know-how while leaving methods of operation – including linguistic techniques for steering AI systems – in the public domain.

The practical implication is straightforward. Firms seeking durable advantages should focus on organisational capability: continuous prompt iteration, integration with proprietary data, robust governance, and enterprise-grade confidentiality commitments. Legal reform may someday revisit whether documented verification investment merits narrow protection, but the current evidence does not compel intervention. In the meantime, prompts remain part of the competitive commons. To that extent, the EU's refusal to confer strong intellectual property rights on prompts preserves open experimentation in human–AI interaction – and challenges businesses to compete through skill rather than enclosure.

Put differently, the law directs investment toward people and processes rather than toward claims over text. The most effective prompt engineers function as translators between business requirements and probabilistic systems; their value lies in judgement, not in static strings. Organisations that treat prompts as disposable artefacts – assuming that exclusivity can be asserted later – will find themselves without remedies when leakage occurs. Those that embed prompts within governance frameworks, document their development, and train staff to maintain secrecy will capture value even without new rights. This Article's comparative analysis should reassure policymakers that restraint aligns with doctrinal coherence and economic evidence.

Future debates will undoubtedly revisit prompt protection as models evolve. If evidence emerges that wholesale prompt misappropriation undermines investment despite best-practice controls, legislators may consider targeted intervention. Any such reform must remain narrow, short-term, and interoperable with the existing frameworks described above. Until then, the law encourages a pragmatic equilibrium: share prompting techniques widely to advance the field, guard the few that deliver material advantage through trade secret discipline, and accept that functional language belongs in the commons. To that extent, the EU framework reflects a principled pragmatism – one that keeps foundational communication techniques free while rewarding those who innovate through skill, integration, and stewardship.

The burden now shifts to practitioners and researchers. Practitioners must document how prompt governance interacts with data protection, competition, and consumer protection obligations; researchers must quantify when secrecy yields genuine social benefits versus when openness accelerates innovation. Only with such evidence can policymakers revisit the question of protection with confidence. Until then, the prudent course is to respect the boundaries that EU law has drawn – boundaries that keep the linguistic building blocks of AI accessible to all while rewarding those who deploy them responsibly.

[^1]: PromptBase, 'About' <https://promptbase.com/about> accessed 15 October 2024.
[^2]: ChatX <https://chatx.ai> accessed 15 October 2024.
[^3]: PromptHero <https://prompthero.com> accessed 15 October 2024; PromptScoop <https://promptscoop.com> accessed 15 October 2024.
[^4]: Glassdoor, 'Prompt Engineer Salaries' (August 2025) <https://www.glassdoor.com/Salaries/prompt-engineer-salary-SRCH_KO0,16.htm> accessed 15 October 2025.
[^5]: Coursera, 'Prompt Engineer Salary Guide' (February 2025) <https://www.coursera.org/articles/prompt-engineer-salary> accessed 15 October 2025.
[^6]: ZipRecruiter, 'Prompt Engineer Salary' (October 2025) <https://www.ziprecruiter.com/Salaries/Prompt-Engineer-Salary> accessed 15 October 2025.
[^7]: Market.us, 'Prompt Engineer Job Description and Salary' (2025) <https://market.us/statistics/prompt-engineer/> accessed 15 October 2025.
[^8]: McKinsey & Company, 'The Economic Potential of Generative AI: The Next Productivity Frontier' (14 June 2023) 7–14.
[^9]: ibid 56–63.
[^10]: McKinsey & Company, 'Developer Productivity with Generative AI' (2024) 4–7.
[^11]: F. Anam, 'Prompt Engineering Practices and Efficiency' (2025) arXiv:2502.01845 9–11; S. Lee and others, 'Conversational Prompting for Software Tasks' (2025) arXiv:2504.11221 12–14.
[^12]: Bloomberg Law Docket Tracker, 'AI Licensing Agreements 2024–2025' (2025).
[^13]: European Commission, 'Impact Assessment Accompanying the Proposal for a Regulation Laying Down Harmonised Rules on Artificial Intelligence' SWD(2021) 84 final, 71–76.
[^14]: Directive 2009/24/EC of the European Parliament and of the Council of 23 April 2009 on the legal protection of computer programs [2009] OJ L111/16, art 1(3); Case C-5/08 *Infopaq International v Danske Dagblades Forening* EU:C:2009:465 [37].
[^15]: Case C-145/10 *Painer v Standard Verlags* EU:C:2011:798 [88].
[^16]: Case C-393/09 *BSA v Ministerstvo kultury* EU:C:2010:816 [50]; Case C-833/18 *Brompton Bicycle v Chedech* EU:C:2020:461 [24].
[^17]: Directive 2009/24/EC, art 1(2); Agreement on Trade-Related Aspects of Intellectual Property Rights (adopted 15 April 1994, entered into force 1 January 1995) 1869 UNTS 299, art 9(2).
[^18]: *Painer* (n 15) [89]–[91]; *Brompton* (n 16) [24]; Case C-604/10 *Football Dataco v Yahoo! UK* EU:C:2012:115 [38]; Case C-683/17 *Cofemel v G-Star Raw* EU:C:2019:721 [29]–[32].
[^19]: *Infopaq* (n 14) [45]–[47].
[^20]: ibid.
[^21]: *Football Dataco* (n 18) [39]–[42].
[^22]: Cour de Cassation, 12 December 1974, Bull civ IV no 267; Case C-310/17 *Levola Hengelo v Smilde Foods* EU:C:2018:899 (Opinion of AG Wathelet) [40].
[^23]: *BSA* (n 16) [48]–[50]; Case C-406/10 *SAS Institute v World Programming* EU:C:2012:259 [39]–[46].
[^24]: Bundesgerichtshof, Bedienungsanleitung [1993] GRUR 34.
[^25]: *BSA* (n 16) [50].
[^26]: ibid [45].
[^27]: *SAS Institute* (n 23) [39]–[46].
[^28]: Case C-159/23 *Sony Computer Entertainment Europe v Datel Design & Development* EU:C:2024:649 [33]–[35].
[^29]: Directive 2009/24/EC, recital 7; T. Dreier and P.B. Hugenholtz, *Concise European Copyright Law* (2nd edn, Kluwer 2016) 318–319.
[^30]: A. Sampaio, 'Are Prompts Copyrightable?' (Kluwer Copyright Blog, 14 June 2023) <http://copyrightblog.kluweriplaw.com/2023/06/14/are-prompts-copyrightable/> accessed 15 October 2024.
[^31]: Case C-203/02 *British Horseracing Board v William Hill* EU:C:2004:695 [30]–[51]; Case C-338/02 *Fixtures Marketing v Oy Veikkaus* EU:C:2004:696 [50]–[52].
[^32]: P.B. Hugenholtz, 'Abuse of Database Right: Sole-Source Information Banks under the EU Database Directive' (2006) 2 EIPR 58, 63–65.
[^33]: X. He, 'Human Authorship and AI-Generated Works: A Chinese Perspective' (2024) 55 IIC 321, 335–336.
[^34]: D. Gervais and P.B. Hugenholtz, 'The AI-nundrum: Machines, Learning and Intellectual Property' (Kluwer Copyright Blog, 18 July 2023) <http://copyrightblog.kluweriplaw.com/2023/07/18/the-ai-nundrum-machines-learning-and-intellectual-property/> accessed 15 October 2024.
[^35]: J.P. Quintais and P.B. Hugenholtz, 'The New Copyright Directive: A Complete (EU) Copyright Codification?' (2020) 51 IIC 28, 45–47.
[^36]: *Computer Program Product/IBM* T 1173/97 [2000] OJ EPO 609 [13]; *Programs for Computers* G 3/08 [2011] OJ EPO 10 [10.13]; *Two identities/COMVIK* T 641/00 [2002] OJ EPO 352 [5]–[7].
[^37]: *Pension Benefit Systems Partnership* T 931/95 [2001] OJ EPO 441 [5].
[^38]: Oberlandesgericht Düsseldorf, 6 U 161/20, 11 March 2021 [54]–[62].
[^39]: S. Gupta and others, 'Prompt Extraction Attacks against LLMs' (2024) arXiv:2405.01812 6–9.
[^40]: Oberlandesgericht Düsseldorf (n 38) [70]–[73].
[^41]: Directive (EU) 2016/943, art 4; Regulation (EU) 2016/679 (General Data Protection Regulation) art 28.
[^42]: Bundesgerichtshof, I ZR 118/21, *Fräsautomat* (2022) [74]–[81].
[^43]: Case C-203/22 *Dun & Bradstreet Austria* EU:C:2025:128 [60]–[69].
[^44]: *SAS Institute* (n 23) [40]; *BSA* (n 16) [48].
[^45]: Oberlandesgericht Munich, 6 U 5045/19, 28 January 2021 [65]–[78].
[^46]: Morgan Stanley, 'Morgan Stanley Wealth Management Introduces the Next Generation of AI @ Morgan Stanley Assistant' (Press Release, 20 September 2023) <https://www.morganstanley.com/press-releases/morgan-stanley-wealth-management-introduces-next-generation-ai> accessed 15 October 2025.
[^47]: World Economic Forum, 'Prompt Engineer: The Job of the Future?' (16 May 2023) <https://www.weforum.org/agenda/2023/05/prompt-engineer-job-of-the-future/> accessed 15 October 2025.
[^48]: McKinsey & Company, 'Navigating the Generative AI Productivity Frontier' (2024) 18–22.
[^49]: European Patent Office, *Guidelines for Examination in the European Patent Office* (March 2024) G-II, 3.3; G-II, 3.6.4.
[^50]: US Copyright Office, 'Copyright Registration Guidance: Works Containing Material Generated by Artificial Intelligence' 88 Fed Reg 16190 (16 March 2023).
[^51]: EUIPO, 'Trade Secrets Litigation Trends in the EU' (2023) 24–26.
[^52]: Case C-128/11 *UsedSoft v Oracle* EU:C:2012:407 [56]–[63].
[^53]: Case C-355/12 *Nintendo v PC Box* EU:C:2014:25 [23]–[27].
[^54]: *Data Structure Product/Philips* T 1784/06 (12 November 2012) [3.1]–[3.3].
[^55]: *Information Modelling/Siemens* T 1194/97 [2000] OJ EPO 525 [3.3].
[^56]: Directive 96/9/EC of the European Parliament and of the Council of 11 March 1996 on the legal protection of databases [1996] OJ L77/20, arts 7(5), 8.
[^57]: *Pedestrian Simulation* G 1/19 [2021] OJ EPO A77 [114]–[120].
[^58]: Charter of Fundamental Rights of the European Union [2012] OJ C326/391, art 11; Case C-201/13 *Deckmyn* EU:C:2014:2132 [25]–[27].
[^59]: International Accounting Standards Board, *IAS 38 Intangible Assets* (revised 2004) paras 63–69.
[^60]: UK Intellectual Property Office, 'Artificial Intelligence and Intellectual Property: Government Response to Call for Views' (23 March 2021).
[^61]: Berne Convention for the Protection of Literary and Artistic Works (as amended on 28 September 1979) art 6bis; Directive 2001/29/EC of the European Parliament and of the Council of 22 May 2001 on the harmonisation of certain aspects of copyright and related rights in the information society [2001] OJ L167/10, recital 19.
[^62]: *Circuit Simulation/Infineon Technologies* T 1227/05 [2007] OJ EPO 574 [3.1]; *Presentation of Information/Nokia* T 619/02 (18 October 2005) [2.2].
[^63]: Directive (EU) 2016/943, arts 12–14.
[^64]: Directive 2009/24/EC, art 6.
