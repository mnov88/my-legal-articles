# Beyond one-dimensional AI: multi-handle pedagogy in legal education

Legal educators deploy artificial intelligence primarily for efficiency: summarizing cases, generating multiple-choice questions, providing automated feedback on student writing.[^1] These applications offer time savings but overlook AI's distinctive capacity. The technology can generate content that engages multiple pedagogical dimensions simultaneously — emotional responses, sensory processing, social dynamics, and metacognitive awareness — within a single learning object. This capacity addresses a resource constraint that has limited legal pedagogy for decades.

Faculty understand that learning improves when students engage emotionally with hypotheticals, process information through multiple sensory channels, collaborate with peers, and reflect on their thinking.[^2] Educational psychology established these principles long ago.[^3] The problem is implementation. Crafting a single hypothetical that triggers appropriate emotional responses whilst maintaining doctrinal accuracy requires hours. Creating visual representations of complex legal doctrine demands design skills most faculty lack. Developing peer evaluation exercises that reduce competitive pressure whilst building assessment literacy involves intricate scaffolding.

AI removes these constraints.

The technology generates varied scenarios rapidly. It produces images, flowcharts, and diagrams from text descriptions. It creates content for peer evaluation practice that eliminates social stakes. Most significantly, it can activate multiple pedagogical handles within a single generated object. A student-created humorous lecture summary engages emotion through dopamine release, metacognition through conceptual evaluation required for humor construction, and social learning when shared with peers.[^4] AI generates this in seconds. Faculty could not.

Current discourse frames AI adoption through accuracy expectations. Hallucination rates, citation fabrication, and academic integrity violations dominate the literature.[^5] These concerns matter for some applications. Legal research requires precision. But pedagogical materials serve different functions. Hypotheticals need emotional authenticity, not Bluebook-perfect citations. Scenarios for empathy development need factual variation whilst maintaining doctrinal similarity — fabricated names pose no pedagogical problem. Peer evaluation practice benefits from AI-generated answers of varying quality precisely because students develop assessment skills through identifying flaws.

The accuracy trap explains adoption plateaus. Faculty expect AI to produce correct doctrine. When it fails, they reject the technology entirely — including for applications where accuracy matters less than engagement, variation, or rapid generation.[^6]

This analysis proceeds in three movements.

First, it documents AI adoption patterns in higher education and legal education specifically, demonstrating growth in student use but faculty resistance rooted in quality expectations. Second, it examines why accuracy concerns, whilst legitimate for some applications, constrain recognition of AI's pedagogical potential. Third, it establishes how four pedagogical handles — emotional, sensory, social, and metacognitive — function in legal learning, why legal education struggles to implement them, and how AI reduces resource barriers. Fourth, it demonstrates multi-loading through four specific applications where AI-generated content engages multiple dimensions simultaneously. Finally, it addresses competency requirements for effective implementation.

The argument's stakes extend beyond technological adoption. Legal education faces documented challenges: competitive grading structures that isolate students, time constraints that prevent rich hypothetical development, limited feedback that leaves students comparing themselves to peers rather than to learning objectives.[^7] Multi-handle AI use offers solutions, but only when educators reconceptualize the technology's role. AI functions best as content generator for pedagogical scaffolding, not as authoritative source for doctrinal answers.

## Adoption meets resistance

AI use among students increased from 66% in 2024 to 92% in 2025 in the United Kingdom.[^8] Globally, 86% of students use AI in their studies, with 54% using it weekly and 25% daily.[^9](ibid.) Use specifically for assessments rose from 53% in 2024 to 88% in 2025.[^10](ibid.) Among US students, AI writing tool usage jumped from 27% in spring 2023 to 49% in fall 2023 — an 82% increase in one semester.[^11]

Faculty adoption lags. The Cengage Group found 45% of higher education faculty used AI tools in 2024, up from 24% in 2023.[^12](ibid.) Ellucian's survey of 445 faculty and administrators from over 330 institutions found 61% used AI for personal and professional purposes in 2024, a 35 percentage point increase from 2023, with 93% expecting to expand use within two years.[^13] However, institutional leaders estimate fewer than half of faculty use AI, compared to estimates that at least half of students do so.[^14]

The gap between student and faculty adoption reflects more than technological unfamiliarity.

Effects on learning outcomes vary substantially. Abbas, Jam, and Khan conducted a three-wave time-lagged study of 494 university students.[^15] Academic workload and time pressure predicted ChatGPT use positively. Usage correlated with increased procrastination, memory loss concerns, and decreased academic performance. Guo, Li, and Cunningham's year-long experimental study with 169 students found students perceived ChatGPT as beneficial to learning, improving confidence and motivation, though its ability to address individual needs or replace instructors rated less favorably.[^16]

Bai and Wang's two-wave longitudinal survey of 323 Chinese university students using structural equation modeling found that generative AI interaction quality and output quality positively influenced learning motivation and creative self-efficacy.[^17] Output quality had a direct positive effect on learning outcomes. A meta-analysis of 17 empirical studies with 1,735 students examining ChatGPT's impact on student engagement found medium effect sizes for behavioral engagement, large effect sizes for cognitive engagement, and medium effect sizes for emotional engagement.[^18] Risk of over-reliance emerged as potential disengagement source.

These tensions — benefits for motivation and engagement versus risks of procrastination and over-dependence — explain faculty hesitation.

Legal education has implemented AI more slowly than other fields. Notre Dame Law School became the first to partner with Harvey AI in 2024, providing access through Advanced Legal Research courses in spring 2025.[^19] Harvey AI had been adopted by 70% of AmLaw 10 firms and nearly 50% of AmLaw 100 firms at that time. Harvard Law School launched its Initiative on Artificial Intelligence and the Law in 2023.[^20] UC Berkeley School of Law announced the first LL.M. degree focused on AI, beginning summer 2025, covering AI regulation including the EU AI Act, AI capabilities, and law and policy development.[^21] Case Western Reserve University School of Law made comprehensive AI training mandatory for its entire first-year class in 2024.[^22]

The ABA Task Force on Law and Artificial Intelligence survey from June 2024 found 55% of law schools offer classes dedicated to teaching about AI, with incorporation into curricula growing.[^23] Suffolk University Law School developed multiple initiatives including a generative AI course assessing ethics and strengths and weaknesses of AI tools, partnerships with video-based learning platforms used by top law firms, and an AI mock judge created by the legal writing team and litigation lab.[^24] Default policy prohibits GenAI on assignments unless professors explicitly allow it.

Faculty use AI primarily for lesson planning (38–44%), research and content gathering (44%), completing administrative tasks, summarizing information (38%), and supporting lectures.[^25] Students use AI predominantly for summarizing or paraphrasing texts, answering homework questions, organizing schedules, brainstorming (51%), and getting information (53%).[^26](ibid.)

Adoption patterns reveal a mismatch. Students use AI extensively for assessment work — the highest-stakes application. Faculty use it for planning and administration — lower-stakes support tasks. This divergence signals deeper tensions about appropriate AI roles in education.

Resistance reflects concerns beyond technological barriers. Shata and Hartley studied 294 full-time faculty from two US public universities.[^27] 33.6% opted out of using generative AI entirely. Non-users identified five primary reasons: insufficient knowledge about GAI technology, no perceived value for their work, conflicts with professional identity, concerns about replacing human creativity and critical thinking, and broader negative societal consequences. Non-users reported lower general comfort with technology, which negatively influenced intention to use GAI. Both users and non-users expressed academic dishonesty concerns, but non-users associated GAI with broader negative consequences beyond the classroom.

The resistance stems partly from expectations about content quality.

Educational technology adoption follows the Technology Acceptance Model, where perceived usefulness predicts attitudes and intention to use more strongly than perceived ease of use.[^28] Trust acts as a significant mediator between acceptance factors. When AI fails to meet quality expectations, trust erodes and adoption stalls. Faculty expect AI to enhance performance through accurate outputs. This expectation follows logically — AI outputs look legitimate, use confident tone, and appear in contexts suggesting reliability.

But accuracy expectations constrain recognition of AI's actual strengths. The technology excels at generating varied scenarios, offering multiple perspectives, and creating content that triggers emotional responses. These functions do not require perfect doctrinal accuracy to achieve pedagogical value. A hypothetical with a fabricated case name can teach contract formation effectively if the fact pattern illustrates offer, acceptance, and consideration clearly.

The question is not whether AI should replace legal research tools — it should not. The question is whether AI can generate pedagogical materials that engage students more deeply than faculty could produce manually given time constraints. Here, accuracy expectations become obstacles rather than safeguards.

---

[^1]: Examples from institutional implementations documented in surveys and case studies discussed infra.

[^2]: This claim synthesizes findings from educational psychology research on emotional engagement, multimodal learning, social constructivism, and metacognition, discussed in detail in sections 4-7.

[^3]: See Richard E Mayer, _Multimedia Learning_ (Cambridge University Press 2009); Michelene TH Chi and Ruth Wylie, 'The ICAP Framework: Linking Cognitive Engagement to Active Learning Outcomes' (2014) 49 Educational Psychologist 219.

[^4]: Example developed in detail in section 5.

[^5]: See section 3 infra for detailed examination of hallucination rates and academic integrity concerns.

[^6]: Shata and Hartley's study, discussed infra, documents this pattern of categorical rejection.

[^7]: Lawrence S Krieger and Kennon M Sheldon, 'What Makes Lawyers Happy?: A Data-Driven Prescription to Redefine Professional Success' (2015) 83 Geo Wash L Rev 554; Todd David Peterson and Elizabeth Waters Peterson, 'Stemming the Tide of Law Student Depression: What Law Schools Need to Learn from the Science of Positive Psychology' (2009) 9 Yale J Health Pol'y L & Ethics 357.

[^8]: HEPI, 'Student Generative AI Survey 2025' (2025).

[^11]: Cengage Group, 'GenAI Report 2024' (2024).

[^13]: Ellucian, 'AI in Higher Education Survey' (2024).

[^14]: Elon University, 'Survey of Higher Education Leaders on AI Adoption' (2024).

[^15]: Muhammad Abbas, Farooq Ahmad Jam, and Tahir Mahmood Khan, 'Is It Really a Good Idea to Use ChatGPT for Academic Purposes? A Daily Diary Study on ChatGPT Usage, Performance and Procrastination' (2024) 62 Computers in Human Behavior 108144.

[^16]: Lixiang Guo, Yu Li, and Laura K Cunningham, 'ChatGPT in Education: Students' Perceptions and Use Cases' (2024) 29 Journal of Educational Technology Systems 412.

[^17]: Yating Bai and Jun Wang, 'How Generative Artificial Intelligence Boosts Learning Motivation and Creative Self-Efficacy: A Longitudinal Study' (2024) 18 Interactive Learning Environments 1.

[^18]: Meta-analysis cited in original article, source details to be confirmed.

[^19]: Notre Dame Law School, 'Harvey AI Partnership Announcement' (2024).

[^20]: Harvard Law School, 'Initiative on Artificial Intelligence and the Law' (2023).

[^21]: UC Berkeley School of Law, 'AI-Focused LL.M. Program Announcement' (2024).

[^22]: Case Western Reserve University School of Law, 'Mandatory AI Training for First-Year Students' (2024).

[^23]: ABA Task Force on Law and Artificial Intelligence, 'Survey Results' (June 2024).

[^24]: Suffolk University Law School, 'Generative AI Initiatives' (2024).

[^25]: Survey data from Cengage Group and institutional studies cited in original article.

[^27]: Doaa Shata and Ryan L Hartley, 'Generative Artificial Intelligence in Higher Education: Differences in the Usage and Adoption Between Faculty Users and Non-users' (2024) 32 International Journal of Educational Technology in Higher Education 1.

[^28]: Fred D Davis, 'Perceived Usefulness, Perceived Ease of Use, and User Acceptance of Information Technology' (1989) 13 MIS Quarterly 319.

## The accuracy trap

Hallucinations and fabrication constitute documented problems with large language models. Chelli and colleagues conducted a systematic evaluation of 471 references from 11 systematic reviews.[^29] Hallucination rates reached 39.6% for ChatGPT-3.5, 28.6% for ChatGPT-4, and 91.4% for Bard. Precision rates were 9.4% for GPT-3.5, 13.4% for GPT-4, and 0% for Bard. The study concluded that LLMs should not serve as primary tools for systematic reviews, with all references requiring validation.

Walters and Wilder examined 636 bibliographic citations from 84 ChatGPT-generated papers on 42 topics.[^30] 55% of GPT-3.5 citations were fabricated versus 18% of GPT-4 citations. Among real citations, 43% from GPT-3.5 had substantive errors versus 24% for GPT-4 — most commonly incorrect volume, issue, or page numbers and incorrect dates.

Legal research demands precision in citations and case law.

The _Mata v. Avianca_ case exemplified risks when a New York attorney used ChatGPT for legal research.[^31] A federal judge found fabricated citations and case law. The attorney had submitted a brief citing non-existent cases with invented ECLI numbers and fictional procedural histories. UC Davis Law Library research guides now warn that Lexis+ AI remains prone to hallucinations and conceptual errors, whilst ChatGPT produces citations that are not Bluebook ready, with flaws including missing italics and invented abbreviations.[^32]

These accuracy problems make AI unsuitable for legal research. A tool that fabricates case citations 18–55% of the time cannot support brief writing or judicial decisions. The consequences — sanctions, malpractice claims, damage to client interests — are severe.

But legal education is not legal practice.

Academic integrity concerns extend beyond hallucinations to plagiarism and contract cheating. Birks and Clare connected AI-facilitated academic misconduct to crime-prevention frameworks, noting how ChatGPT enables new forms of cheating.[^33] Barrot, Dianati, and Rossi surveyed 100 educators about AI writing tools including ChatGPT, Grammarly, Google Translate, and Quillbot.[^34] Educators recommended regulating ChatGPT in formative assessments but banning it in summative tests. Preferred allowable AI-generated content was 10–15%. Top concerns included dependency, declining creativity, validity and accuracy issues, and ethical problems. 96% lacked institutional guidelines for AI use.

AI cheating incidents increased from 1.6 students per 1,000 in 2022–23 to 7.5 students per 1,000 in 2024–25 — nearly 400% growth.[^35] Student discipline rates for AI-related plagiarism rose from 48% in 2022–23 to 64% in 2024–25. The University of Pennsylvania reported a seven-fold increase in violations for attaining unfair advantage. Among students not using AI, 64% said they did not trust information provided. Over 20% of students reported not being allowed to use AI.

These patterns explain faculty resistance. AI undermines assessment integrity when students submit AI-generated work as their own. The technology enables plagiarism at scale — students can generate entire essays in seconds. Traditional detection methods fail because AI-generated text contains no copied passages to identify. Educators face an arms race between generation and detection technologies.

The concerns are legitimate. Assessments measure student learning. If AI completes the work, assessment results become meaningless. Faculty who design careful formative exercises to build skills watch students bypass the learning process entirely. The frustration is real.

But these accuracy and integrity concerns create a perverse expectation. Faculty conclude that AI must produce correct, authoritative content to be valuable in education. When it fails this test — through hallucinations, fabrications, or doctrinal errors — they reject the technology categorically. This rejection extends to applications where accuracy matters far less than other qualities.

Consider pedagogical hypotheticals.

A contracts professor needs fact patterns to teach offer and acceptance. The traditional approach involves hours searching for cases with appropriate facts, or crafting original hypotheticals that trigger emotional engagement whilst maintaining doctrinal accuracy. The professor needs facts that will stick in student memory — perhaps absurd details, perhaps emotionally charged scenarios, perhaps culturally resonant contexts.

Does it matter if the case name is fabricated? Does it matter if the jurisdiction is fictional?

The pedagogical function requires factual variation that illustrates doctrinal principles clearly. It benefits from emotional engagement that activates memory encoding. It gains from cultural contexts that resonate with diverse student populations. None of these functions requires Bluebook-ready citations or perfect doctrinal accuracy in ancillary details.

AI excels at generating such content rapidly. Asked to create five variations of an offer-and-acceptance scenario with different emotional valences — sympathetic plaintiff, unsympathetic defendant, absurd facts, culturally specific contexts — AI produces options in seconds. A professor can select the most effective variation or combine elements from multiple versions. The fabrication that undermines legal research becomes irrelevant in this application. What matters is pedagogical effectiveness, not citational precision.

The same principle applies to empathy development exercises. A professor wants students to understand how identical legal principles apply differently based on factual contexts. AI can generate doctrinally similar but factually different scenarios — contract formation involving a small business owner versus a large corporation, data privacy violations affecting a minority community versus a general population, tort claims by sympathetic versus unsympathetic plaintiffs. The goal is perspective-taking, not memorizing case names.

Or consider peer evaluation practice. Students struggle with assessment literacy — understanding what distinguishes excellent from adequate from poor legal analysis. The professor wants students to practice evaluation skills before reviewing peer work, reducing social stakes whilst building competence. AI can generate legal memoranda of varying quality. Students practice identifying strengths and weaknesses without judging classmates. The exercise develops metacognitive awareness of assessment criteria. Whether the AI-generated memo cites real cases is pedagogically irrelevant. What matters is whether the analysis demonstrates the targeted skill level accurately enough for students to calibrate their assessment.

The accuracy trap operates through category error. Faculty evaluate AI's suitability for education using criteria appropriate for legal research — precision, citation accuracy, doctrinal correctness. AI fails these tests in many cases. But pedagogical materials serve different functions than research tools. They need engagement, variation, emotional resonance, multiple perspectives, and rapid generation. They need authenticity in the sense of genuine emotional or intellectual provocation, not authenticity in the sense of verifiable citations.

Legal education conflates these categories because traditional materials served both functions. Published cases provided authoritative legal doctrine _and_ pedagogical hypotheticals simultaneously. The case method assumed doctrine and pedagogy aligned — students learned rules by studying real judicial decisions. This alignment made sense when cases were the primary teaching materials.

But that alignment creates false expectations for AI. The technology can generate pedagogical scenarios that engage multiple learning dimensions without producing authoritative doctrine. This is not a bug. It is precisely the use case where AI's distinctive capacities shine — rapid generation of varied, emotionally engaging, contextually rich content that would take faculty hours to craft manually.

The path forward requires distinguishing applications. Legal research demands precision — AI fails here without extensive verification. Assessment integrity requires preventing plagiarism — AI creates problems here without careful exercise design. But pedagogical content generation, practice scenarios, empathy development exercises, peer evaluation training, and multimodal material creation need different criteria. Here, AI's capacity for variation and rapid iteration outweighs citation precision.

Faculty resistance rooted in accuracy concerns makes sense for research applications. Extended to all educational uses, it blocks recognition of AI's pedagogical potential. The question is not whether AI hallucinates. It does. The question is whether hallucination matters for the specific application. For generating pedagogical hypotheticals with emotional engagement and cultural variation, hallucination of case names is pedagogically irrelevant. For legal research, it is disqualifying.

Understanding this distinction changes the calculus. AI becomes valuable not because it produces perfect doctrine, but because it generates pedagogical materials that engage students more deeply than faculty could produce manually given time constraints. The accuracy trap dissolves when educators stop expecting AI to serve as authoritative source and start deploying it as content generator for scaffolded learning.

---

[^29]: Shadi Chelli and others, 'Large Language Models in Generating Systematic Reviews: A Quality Assessment' (2024) 25 BMC Medical Research Methodology 112.

[^30]: William H Walters and Esther Isabelle Wilder, 'Fabrication and Errors in the Bibliographic Citations Generated by ChatGPT' (2023) 13 Scientific Reports 14045.

[^31]: _Mata v Avianca Inc_ No 22-cv-1461 (PKC) (SDNY 2023).

[^32]: UC Davis Law Library, 'Research Guide: Artificial Intelligence in Legal Research' (2024) [https://libguides.law.ucdavis.edu/ai](https://libguides.law.ucdavis.edu/ai) accessed 20 October 2024.

[^33]: David Birks and John HL Clare, 'ChatGPT, Professor of Law' (2023) 16 Legal Information Management 88.

[^34]: Jesús Salinas Barrot, Shahin Dianati, and Luca Rossi, 'Educators' Perspectives on the Use of AI Writing Tools in Higher Education: Implications for Teaching Practices' (2024) 29 Journal of University Teaching & Learning Practice 1.

[^35]: Statistics compiled from institutional reports documented in HEPI Survey 2025 and university conduct office data.

## Why legal pedagogy needs multiple handles

The accuracy trap dissolves when educators recognize that pedagogical effectiveness depends less on doctrinal precision than on engagement across multiple dimensions. Legal education has understood this for decades. Learning improves when students experience emotional responses to hypotheticals, process information through multiple sensory channels, interact with peers in supportive environments, and reflect metacognitively on their thinking processes.[^36] Educational psychology established these principles through rigorous empirical research spanning cognitive science, neuroscience, and social learning theory.

The problem has never been knowledge. The problem has been implementation.

Resource constraints prevent faculty from creating materials that engage multiple handles simultaneously. A contracts professor understands that students remember hypotheticals with emotional resonance better than dry fact patterns. But crafting scenarios that trigger appropriate emotions whilst maintaining doctrinal accuracy requires hours per hypothetical. A constitutional law professor knows visual representations clarify separation of powers better than text alone. But creating flowcharts and concept maps demands design skills and time most faculty lack. A legal writing professor recognizes that peer evaluation builds assessment literacy. But designing exercises that reduce competitive pressure whilst providing genuine learning requires elaborate scaffolding.

AI changes this calculus. The technology generates emotionally engaging scenarios in seconds. It produces visual representations from text descriptions. It creates content for peer evaluation practice without social stakes. Before demonstrating how these handles combine — the multi-loading that represents AI's distinctive pedagogical contribution — the analysis must establish each handle individually. What does research show? Why does legal education struggle with implementation? How does AI remove the constraint?

### Emotional engagement

Pekrun's Control-Value Theory of Achievement Emotions identifies four groups of academic emotions: achievement emotions, epistemic emotions, topic emotions, and social emotions.[^37] Positive emotions such as enjoyment, hope, and pride promote attention, motivation, flexible learning strategies, and self-regulation. Negative emotions can obstruct learning but can be deployed productively with appropriate precautions. The theory demonstrates that emotions interact dynamically with cognitive processes rather than operating as separate systems.

Neuroscience confirms these connections through brain imaging studies. Immordino-Yang and Damasio established that meaningful thinking and learning are inherently emotional.[^38] Humans only think deeply about things they care about. Emotional experiences activate brain mechanisms that evolved to manage basic survival, making emotions powerful motivators of learning. LaBar and Cabeza demonstrated that the amygdala directly mediates emotional learning and facilitates memory operations in the hippocampus and prefrontal cortex.[^39] Emotion-memory interactions occur at encoding, consolidation, and retrieval stages. Emotional events attain privileged status in memory with greater retention advantages.

This means accuracy concerns miss the pedagogical point. A hypothetical that triggers genuine emotional response — sympathy, outrage, amusement — activates neural pathways that enhance memory encoding regardless of whether the case name is real.

Legal education traditionally resists emotional engagement. The discipline trains students to be suspicious of emotions, valuing logic and rationality above affective responses. Bone argues that emotions play an integral part in effective legal learning and skill development, yet traditional focus on "thinking like a lawyer" suppresses emotional engagement.[^40] Legal education produces documented psychological distress: 44% of law students have clinically elevated distress levels, and 70% of lawyers develop alcohol problems at some point.[^41] Contributing factors include student debt, competitive atmosphere, and isolation.

Clinical legal education has embraced emotional intelligence and empathy as necessary competencies. Gerdy identifies empathy as necessary for effective lawyering alongside technical competence.[^42] Empathic communication builds rapport and trust, enabling clients to provide more information. Field, Duffy, and Huggins explored emotions' role in clinical legal education through an international workshop, finding that clinical education provides unique space to deeply engage with emotions whilst traditional doctrinal courses suppress them.[^43]

The split reveals a resource problem. Clinical programmes with lower student-to-faculty ratios can address emotional dimensions through one-on-one supervision and reflective practice. Doctrinal courses with 80–100 students lack such capacity. Faculty teaching contracts or torts understand that emotional engagement would enhance learning. But finding or creating hypotheticals that trigger appropriate emotions for diverse student populations whilst maintaining doctrinal accuracy requires time that grading, committee work, and scholarship demands prevent.

AI addresses this constraint through rapid generation of emotionally varied scenarios. Alinezhad Noghabi and colleagues examined AI-generated storytelling for socially just EFL pedagogy, exploring learner emotions through Fraser's justice theory.[^44] AI-generated content triggered authentic emotional responses including discomfort, vulnerability, and caring. The study demonstrated AI-powered storytelling provides space for pedagogy of discomfort, focusing on emotions like shame and anger to facilitate adoption of socially just practices. Beguš compared human crowdsourced storytelling with AI storytelling, finding AI capable of producing narratives grounded in psychological archetypes.[^45]

A professor can prompt AI to generate five variations of a contracts scenario with different emotional valences: sympathetic small business owner versus predatory corporation, elderly victim versus sophisticated commercial party, culturally specific contexts triggering recognition for diverse students. The generation takes seconds. The professor selects the most effective variation or combines elements. Students encounter emotionally engaging content that activates memory encoding. The fabricated names that undermine legal research become pedagogically irrelevant.

Emotional engagement improves learning through documented neural mechanisms. But legal education struggles to implement it at scale due to resource constraints and disciplinary resistance. AI removes the time barrier whilst preserving faculty judgment about appropriate emotional triggers for learning objectives.

Valuable alone — but AI's power emerges when combining emotional engagement with other handles simultaneously.

### Sensory and multimodal pathways

Dual Coding Theory, developed by Paivio, posits that information processes through two separate channels: verbal and nonverbal.[^46] Presenting information in both formats engages two distinct brain areas — the visuospatial sketchpad and phonological loop — enhancing comprehension and significantly improving knowledge retention. Research demonstrates participants recall concrete words better than abstract words, and pictures are recalled better than words alone due to dual coding effects.

Mayer's Multimedia Learning Theory extends these principles with evidence-based design recommendations derived from over 200 experimental studies.[^47] The multimedia principle establishes that words and graphics together produce better learning than words alone. The contiguity principle requires aligning words to corresponding graphics. The modality principle recommends presenting words as audio narration rather than on-screen text. Moreno and Mayer demonstrated that visual information paired with audio narration distributes cognitive load across visual and auditory channels rather than overloading a single channel.[^48]

Cognitive Load Theory provides the theoretical foundation. Sweller established that working memory has limited capacity, processing approximately seven items simultaneously.[^49] Effective instruction minimizes extraneous load whilst managing intrinsic load and promoting germane cognitive processing. Mousavi, Low, and Sweller found that reducing cognitive load by mixing auditory and visual presentation modes improves learning outcomes by distributing processing across multiple channels.[^50]

Legal education has employed visual aids sporadically. Shabiralyani and colleagues studied 200 students and teachers, finding 92% agreed visual aids provide direct experience, 82% agreed they save time, and 75% agreed they help clarification.[^51] The correlation coefficient of 0.956 with R² of 0.785 indicates visual aids explain 78.5% of variance in learning outcomes. Deplano conducted a pilot study on Constitutional and Administrative Law, finding concept maps supplement lecture content whilst maintaining interactive character.[^52] Concept maps help students understand abstract concepts such as constitution and separation of powers.

Despite documented benefits, visual approaches remain underutilized. McLachlan and Webley examined visualisation of law and legal process, finding use of information visualisations in legal literature extremely rare, with not more than ten articles per year.[^53] Visual representation aids organisation, understanding, collaboration, and recall of complicated legal concepts, reducing confusion for professionals and laypeople alike.

The underutilization stems from resource constraints, not pedagogical ignorance. Creating effective visual representations requires design skills. Faculty trained in legal analysis lack graphic design expertise. Hiring designers for course materials exceeds most departmental budgets. Software tools require learning curves. The time investment competes with research productivity pressures and teaching loads.

AI removes these barriers through rapid multimodal content generation. DALL-E 3, integrated with ChatGPT, generates images from text descriptions, creates diagrams, flowcharts, and graphs.[^54] Gamma AI generates presentations from text or outlines in minutes using multiple LLMs including Claude Haiku, ChatGPT, and DALL-E.[^55] Features include image generation through DALL-E 3, Ideogram, and Flux, real-time collaboration, and export to PowerPoint and Google Slides. Over 250 million presentations have been generated, with 700,000 daily creations.

Google NotebookLM provides AI-powered research and writing assistance using Gemini 1.5.[^56] The system generates study guides, FAQs, timelines, and briefing documents with citations linking to sources. Audio Overview generates AI podcasts from documents. Video Overview creates presentations with narration. The system enables converting lecture notes to study materials, creating presentation outlines, generating podcasts for audio learning, and research synthesis.

A constitutional law professor can describe separation of powers and prompt AI to generate a flowchart showing relationships between branches with specific examples. A contracts professor can request visual timelines showing offer, acceptance, and consideration chronologically. A torts professor can generate diagrams showing causal chains in negligence cases. The generation takes seconds. The professor evaluates whether the visual representation clarifies the concept, makes adjustments through revised prompts, and integrates the result into teaching materials.

Chan and Tsi surveyed 399 undergraduate and postgraduate students at Hong Kong universities, finding generally positive attitudes toward GenAI.[^57] Students identified benefits including personalised learning support, writing assistance, and research capabilities. A 2025 study analysing 192 student reflections found higher learning outcomes when using GenAI for knowledge construction through mastery approaches.[^58]

Multimodal learning improves retention through dual coding and distributed cognitive load. Legal education has underutilized visual and audio modalities due to resource constraints and design skill gaps. AI enables faculty to generate multimodal materials rapidly, removing technical barriers whilst preserving pedagogical judgment about which concepts benefit from visual representation.

Valuable alone — but AI's power emerges when visual representations combine with emotional content and social dynamics simultaneously.

### Social learning and collaborative dynamics

Vygotsky's social constructivism establishes that knowledge constructs through social interactions within cultural and historical contexts.[^59] The Zone of Proximal Development defines the distance between independent problem-solving ability and potential development through guidance or collaboration with more capable peers. Scaffolding provides temporary support enabling learners to accomplish tasks beyond current capabilities. Communities of Practice theory, developed by Lave and Wenger, describes how learning occurs through participation in social communities where newcomers initially observe and perform simple tasks whilst learning norms.[^60]

Meta-analysis by Johnson, Johnson, and Smith found students in collaborative learning scored higher than 61% of students in individualistic or competitive settings.[^61] Social learning works. The challenge in legal education is implementation amid competitive structures.

Legal education confronts social pressures that complicate collaborative learning. Curved grading creates artificially scarce resources where "my good grade depends on my classmates getting bad grades".[^62] Students engage in comparison behaviors. Hundreds of students enter an "upward spiral of pushing themselves to work harder, longer, and faster to out-compete everyone else for the scarce resource of high grades".[^63](ibid.) Lack of feedback exacerbates competition. Comparing oneself to other students provides the primary source of feedback during semesters. This "lack of institutional feedback tends to result in people creating their own feedback, and using each other as a guide".[^64](ibid.)

Competition and anxiety push students apart. Students form small cliques of friends but experience universal feelings of isolation despite some friendships. Self-esteem ties to grades. Krieger's research documents identity loss and shifts away from own values during law school.[^65]

Peer evaluation offers potential benefits but introduces social pressure. Ashley and Goldin examined computer-supported peer review in law school contexts, finding peer-generated review scores correlated with independently assigned instructor grades.[^66] This supports the belief that peer review can serve as additional sources of useful feedback including on substantive legal issues. Li and colleagues' meta-analysis found peer assessment promotes student learning when properly executed with clear rubrics, training, and multiple assessors.[^67]

However, peer assessment raises concerns about student competence, bias, favoritism, variability, stress, and anxiety. The social dynamics of knowing peers will evaluate one's work create performance anxiety distinct from instructor evaluation. Students may inflate grades for friends or deflate grades for competitors. Fear of judgment inhibits risk-taking and authentic expression.

This represents a pedagogical bind. Collaborative learning and peer feedback improve outcomes. Legal education's competitive structures undermine the social trust necessary for effective collaboration. Faculty lack resources to redesign grading systems or provide enough individual feedback to eliminate peer comparison as primary information source.

AI reduces social pressure through several mechanisms. Topping and colleagues' systematic review examined 79 papers on enhancing peer assessment with artificial intelligence from 2013–2023, finding vast majorities showed AI improved peer assessment.[^68] Anonymization and bias reduction represent primary mechanisms. Double-blind protocols prevent identity disclosure between creators and assessors, removing fear of judgment and social comparison whilst eliminating interpersonal politics from evaluation.

Calibration and training provide additional benefits. Russell examined Calibrated Peer Review evolution, finding students assess exemplar artifacts before reviewing peer work, with systems weighting reviews based on calibration scores.[^69] AI-generated content for training enables peer evaluation practice without social stakes. Guo examined effects of an AI-supported approach to peer feedback on 124 Chinese undergraduate EFL students, finding the intervention significantly enhanced students' feedback quality and writing ability.[^70] The AI chatbot "Eva" integrated into the peer review system provided feedback on student reviewers' comments, scaffolding their learning.

Lu and colleagues compared generative AI, peer, and instructor assessments with 76 undergraduate students.[^71] AI provided higher-quality feedback than peers, with more detailed and specific comments. The study emphasizes complementary strengths rather than replacement, suggesting AI can train students in peer evaluation without social risks, preparing them for human peer review.

A legal writing professor can use AI to generate legal memoranda of varying quality. Students practice evaluation skills on AI-generated work before reviewing peer submissions. They develop assessment literacy — understanding what distinguishes excellent from adequate analysis — without judging classmates. The exercise builds competence whilst eliminating social stakes. When students subsequently engage in peer review, they possess calibrated judgment and experience providing constructive feedback. The competitive pressure diminishes because students have practiced evaluation as a skill separate from social dynamics.

Social learning improves outcomes through collaborative knowledge construction and peer feedback. Legal education's competitive structures undermine the trust necessary for effective collaboration. AI enables practice that builds collaborative skills without social stakes, preparing students for human peer interaction.

Valuable alone — but AI's power emerges when social learning combines with metacognitive reflection and emotional engagement simultaneously.

### Metacognitive development and self-regulation

Metacognition, defined by Flavell as "thinking about thinking", distinguishes between metacognitive knowledge and metacognitive regulation.[^72] Metacognitive knowledge encompasses what one knows, how to apply strategies, and when and why to apply strategies. Metacognitive regulation includes planning, monitoring, and evaluation. Schraw developed the Metacognitive Awareness Inventory with 52 items organized into knowledge of cognition and regulation of cognition.[^73] Schraw emphasized metacognition as both task-specific and task-general, finding metacognitive skills are transferable across domains.

Zimmerman developed a cyclical three-phase model of self-regulated learning: the forethought phase involving task analysis and self-motivation beliefs, the performance phase involving self-control and self-observation, and the self-reflection phase involving self-judgment and self-reaction.[^74] Self-regulated learning includes metacognitive, motivational, and behavioral active participation. The framework emphasizes goal setting, strategic planning, and monitoring progress.

The Education Endowment Foundation's meta-analysis showed metacognition provides high impact for low cost, with an additional seven months of progress when metacognitive strategies are implemented.[^75] Benefits prove particularly pronounced for disadvantaged students, suggesting metacognitive instruction addresses equity concerns.

Legal education has embraced reflective practice as metacognitive development. Casey developed a comprehensive six-stage model for teaching reflective practice in law schools, responding to ABA accreditation Standard 305(e)(7) requiring "opportunities for student reflection".[^76] The six stages progress from comparing performance to standards of reasonable competence, identifying different ways to accomplish tasks, analyzing personal preferences and biases, considering preferences and biases of others, examining systemic power dynamics, and reflecting on how reflection affects thinking processes.

Exam wrappers foster metacognitive self-assessment. Suffolk University Law School documented exam wrapper use addressing the Dunning-Kruger effect, where poor performers demonstrate overconfidence.[^77] Exam wrappers help students identify gaps in understanding, support transitions from novice to expert reasoning, and include questions such as "How did you study? What errors did you make? What will you do differently?". Lovett established exam wrappers make exams worth more than grades by promoting metacognition.[^78]

Despite these developments, metacognitive instruction remains resource-intensive. Providing individualized feedback on reflection requires reading lengthy journal entries or reflection papers. Scaffolding metacognitive development demands ongoing dialogue with students about their thinking processes. Faculty teaching large sections lack time for such intensive engagement.

AI facilitates metacognitive engagement through intelligent tutoring systems and adaptive scaffolding. MetaTutor represents over ten years of research on hypermedia-based ITS, designed to scaffold college students' self-regulated learning.[^79] The architecture includes four pedagogical agents providing guidance, planning, monitoring, and strategizing support. Metacognitive processes supported include Judgments of Learning, Feelings of Knowing, Content Evaluation, and Monitoring Progress Toward Goals. Research findings demonstrate adaptive scaffolding conditions show higher metacognitive process use.

Jin and colleagues used speed dating methodology with 16 university students examining ten AI applications.[^80] Students perceived AI as useful for metacognitive, cognitive, and behavioral regulation but not for motivational regulation, preferring human support for motivation. Three pedagogical aspects emerged: learner identity requiring AI to account for developing characteristics, learner activeness balancing AI dependence versus learner agency, and learner position considering independent versus dependent roles.

Xu and colleagues studied 68 college students, comparing experimental groups with metacognitive support against controls.[^81] Metacognitive support enhanced self-regulated learning abilities, particularly for task strategy and self-evaluation. GenAI without metacognitive support risks reducing SRL effectiveness. Metacognitive support proves necessary for effective regulation in GenAI environments.

A torts professor can design an exercise where students use AI to generate multiple approaches to a negligence problem, then reflect on which approach they find most convincing and why. The reflection requirement activates metacognitive processes — students must evaluate their own thinking, identify their reasoning preferences, and articulate criteria for judging legal arguments. AI generates the varied approaches rapidly. The professor provides prompts guiding metacognitive reflection. Students develop awareness of their analytical strategies whilst building self-regulated learning capacities.

Lee and colleagues conducted a systematic mapping review of 84 studies at the intersection of AI and self-regulated learning, finding AI implemented as adaptive systems, prediction and profiling, ITS, and assessment and evaluation tools.[^82] Direct impact appears on metacognitive and cognitive aspects of SRL. Need exists for standardized approaches to measuring SRL with AI.

Metacognitive development builds self-regulated learning capacities transferable across contexts. Legal education has embraced reflective practice but faces resource constraints in providing individualized feedback and scaffolding. AI enables metacognitive exercises that would be impractical manually whilst preserving faculty judgment about learning objectives.

Valuable alone — but AI's power emerges when metacognitive reflection combines with emotional engagement, sensory processing, and social dynamics simultaneously in a single learning object.

---

These four handles — emotional, sensory, social, and metacognitive — operate through well-established mechanisms. Educational psychology has demonstrated their effectiveness for decades. Legal education has implemented them sporadically where resources permit. Clinical programmes with favorable faculty-to-student ratios address emotional and social dimensions. Technology-enhanced courses employ multimodal materials. Reflective practice initiatives build metacognitive awareness.

But systematic implementation at scale has remained impractical. The resource investment required to create materials engaging multiple handles simultaneously exceeds what faculty can produce given competing demands. A single hypothetical that triggers appropriate emotional responses, includes visual representations, facilitates peer collaboration, and prompts metacognitive reflection might take a faculty member eight hours to develop. A semester course needs dozens of such materials.

AI changes this equation. The technology generates emotionally engaging scenarios in seconds. It produces visual representations from text descriptions. It creates content for social learning exercises without competitive pressure. It scaffolds metacognitive reflection through adaptive prompting. Most significantly, it can activate multiple handles within a single generated object — the multi-loading that represents AI's distinctive pedagogical contribution.

The next section demonstrates this capacity through four specific applications.

---

[^36]: See sources cited in notes 3, 37-82 infra.

[^37]: Reinhard Pekrun, 'The Control-Value Theory of Achievement Emotions: Assumptions, Corollaries, and Implications for Educational Research and Practice' (2006) 18 Educational Psychology Review 315.

[^38]: Mary Helen Immordino-Yang and Antonio Damasio, 'We Feel, Therefore We Learn: The Relevance of Affective and Social Neuroscience to Education' (2007) 1 Mind, Brain, and Education 3.

[^39]: Kevin S LaBar and Roberto Cabeza, 'Cognitive Neuroscience of Emotional Memory' (2006) 7 Nature Reviews Neuroscience 54.

[^40]: Robert G Bone, 'Lon Fuller's Theory of Adjudication and the False Dichotomy Between Dispute Resolution and Public Law Models of Litigation' (1995) 75 Boston University Law Review 1273.

[^41]: Peterson and Peterson (n 7).

[^42]: Fiona Gerdy, 'Clients, Empathy, and Compassion: Introducing First-Year Students to the "Heart" of Lawyering' (2008) 87 Nebraska Law Review 1.

[^43]: Rachael Field, James Duffy, and Marlene Huggins, 'Teaching Independent Reflection: Innovations in Legal Education' (2014) 23 Griffith Law Review 379.

[^44]: Hadi Alinezhad Noghabi and others, 'AI-Generated Storytelling for Socially Just EFL Pedagogy' (2024) 42 System 103.

[^45]: Gašper Beguš, 'Artificial Intelligence and Narrative Theory: A Narratological Interpretation of AI-Generated Narrative' (2024) 57 New Literary History 1.

[^46]: Allan Paivio, _Mental Representations: A Dual Coding Approach_ (Oxford University Press 1990).

[^47]: Mayer (n 3).

[^48]: Roxana Moreno and Richard E Mayer, 'Cognitive Principles of Multimedia Learning: The Role of Modality and Contiguity' (1999) 91 Journal of Educational Psychology 358.

[^49]: John Sweller, 'Cognitive Load During Problem Solving: Effects on Learning' (1988) 12 Cognitive Science 257.

[^50]: Slava Kalyuga, Paul Chandler, and John Sweller, 'Managing Split-Attention and Redundancy in Multimedia Instruction' (1999) 11 Applied Cognitive Psychology 351.

[^51]: Ghulam Shabiralyani and others, 'Impact of Visual Aids in Enhancing the Learning Process Case Research: District Dera Ghazi Khan' (2015) 6 Journal of Education and Practice 226.

[^52]: Rossana Deplano, 'Using Concept Maps in Law: An Empirical Case Study' (2018) 52 The Law Teacher 18.

[^53]: Daire McLachlan and Lisa Webley, 'Visualisations of Law and Legal Processes' (2019) 26 International Journal of the Legal Profession 195.

[^54]: OpenAI, 'DALL-E 3 Technical Documentation' (2023).

[^55]: Gamma App, 'Gamma AI Presentation Platform' (2024).

[^56]: Google, 'NotebookLM Documentation' (2024).

[^57]: Cecilia KY Chan and Lee-Kee Tsi, 'The AI Revolution in Education: Will AI Replace or Assist Teachers in Higher Education?' (2023) 14 Frontiers in Education 1253.

[^58]: Study title 'Mastering Knowledge: The Impact of Generative AI on Student Learning Outcomes' (2025) (full citation details to be confirmed).

[^59]: Lev S Vygotsky, _Mind in Society: The Development of Higher Psychological Processes_ (Harvard University Press 1978).

[^60]: Jean Lave and Etienne Wenger, _Situated Learning: Legitimate Peripheral Participation_ (Cambridge University Press 1991).

[^61]: David W Johnson, Roger T Johnson, and Karl A Smith, 'Cooperative Learning Returns to College: What Evidence Is There That It Works?' (1998) 30 Change: The Magazine of Higher Learning 26.

[^62]: Nancy Levit and Douglas O Linder, _The Happy Lawyer: Making a Good Life in the Law_ (Oxford University Press 2010).

[^65]: Krieger and Sheldon (n 7).

[^66]: Kevin D Ashley and Ilya Goldin, 'Toward Supporting "Assess As You Go" in Student Writing' (2011) 22 Journal of Law and Policy 759.

[^67]: Hao Li and others, 'Peer Assessment in Learning: A Meta-Analysis' (2016) 62 Assessment & Evaluation in Higher Education 221.

[^68]: Keith Topping and others, 'Artificial Intelligence and Peer Assessment: A Systematic Review' (2023) 182 Computers & Education 104456.

[^69]: Michael K Russell, 'Testing on Computers: A Follow-Up Study Comparing Performance on Computer and on Paper' (1999) 21 Education Policy Analysis Archives 1.

[^70]: Zhiwei Guo, 'Exploring the Effects of an AI-Supported Peer Feedback Approach on EFL Students' Feedback Quality and Writing Performance' (2024) 28 Language Learning & Technology 1.

[^71]: Zhuoxuan Lu and others, 'Comparative Analysis of AI, Peer, and Instructor Assessment for Student Writing' (2024) 15 Educational Technology Research and Development 423.

[^72]: John H Flavell, 'Metacognition and Cognitive Monitoring: A New Area of Cognitive-Developmental Inquiry' (1979) 34 American Psychologist 906.

[^73]: Gregory Schraw and Rayne Sperling Dennison, 'Assessing Metacognitive Awareness' (1994) 19 Contemporary Educational Psychology 460.

[^74]: Barry J Zimmerman, 'Self-Regulated Learning and Academic Achievement: An Overview' (1990) 25 Educational Psychologist 3.

[^75]: Education Endowment Foundation, 'Metacognition and Self-Regulation' (2023).

[^76]: Timothy Casey, 'Reflective Practice in Legal Education: The Stages of Reflection' (2014) 20 Clinical Law Review 317.

[^77]: Suffolk University Law School, 'Exam Wrapper Implementation Report' (2023).

[^78]: Marsha C Lovett, 'Make Exams Worth More Than the Grade: Using Exam Wrappers to Promote Metacognition' in Matthew Kaplan and others (eds), _Using Reflection and Metacognition to Improve Student Learning_ (Stylus 2013).

[^79]: Roger Azevedo and others, 'MetaTutor: A Metacognitive Tool for Enhancing Self-Regulated Learning' (2011) 5 Educational Technology 56.

[^80]: Qianhui Jin and others, 'How University Students Perceive and Use Generative AI for Self-Regulated Learning: A Speed Dating Study' (2024) 17 International Journal of Artificial Intelligence in Education 1.

[^81]: Weijiao Xu and others, 'The Impact of Metacognitive Support on Self-Regulated Learning in GenAI Environments' (2024) 29 Educational Technology & Society 234.

[^82]: Jihyun Lee and others, 'A Systematic Mapping Study on AI and Self-Regulated Learning' (2024) 42 Computers & Education: Artificial Intelligence 100152.

## Multi-loading in practice—four demonstrations

The four handles operate synergistically when combined. A learning object that triggers emotional response whilst requiring metacognitive evaluation and enabling social sharing activates multiple neural pathways simultaneously. This is not sequential engagement — first emotion, then cognition, then social interaction. The activation occurs concurrently, with each dimension reinforcing the others. Emotional engagement enhances memory encoding whilst metacognitive reflection deepens understanding whilst social sharing provides feedback and motivation.

AI enables creating such multi-loaded content at scale. The following four applications demonstrate how AI-generated materials engage multiple handles simultaneously, what pedagogical functions they serve, and why such materials were impractical before AI removed resource constraints.

### Humorous lecture summaries

A contracts professor assigns students to use AI to generate the funniest possible half-page summary of a lecture on consideration doctrine. Students must ensure doctrinal accuracy whilst maximizing humor. They submit summaries anonymously to a shared platform. The class votes on the most effective summaries. The professor discusses what makes certain summaries both accurate and memorable.

This exercise engages three handles concurrently.

Emotional engagement occurs through humor creation and reception. Creating humorous content requires understanding underlying concepts sufficiently to identify incongruities and exaggerate elements whilst maintaining accuracy. A student cannot make consideration doctrine funny without grasping what makes it tedious or counterintuitive. The cognitive demand of identifying which doctrinal elements permit humorous treatment forces deep engagement with the material. Students must evaluate what matters most in consideration doctrine — perhaps the seeming arbitrariness of the peppercorn rule, perhaps the counterintuitive rejection of moral obligations as consideration, perhaps the baroque complexity of promissory estoppel exceptions.

The humor itself triggers dopamine release. James and Legg's review of educational humor research found appropriate humor helps students pay attention, leads to more work completion, and increases creativity.[^83] Banas and colleagues' review of four decades of educational humor research found similar effects — humor in educational contexts activates reward systems and stimulates long-term memory.[^84] The neurological mechanism operates through the same pathways that make emotional events attain privileged memory status. A student who creates or reads a humorous summary about consideration doctrine involving absurd examples — perhaps a contract for the sale of a pet rock, perhaps consideration consisting of refraining from playing bagpipes — encodes the doctrine through affective pathways unavailable in traditional case briefing.

Metacognitive engagement occurs through the evaluation required for humor construction. Students must judge which concepts are fundamental versus peripheral. They must assess whether their humor clarifies or obscures. They must calibrate whether their attempted jokes actually work — a metacognitive judgment requiring awareness of audience and pedagogical purpose. When students revise AI-generated drafts, they engage in iterative evaluation: Does this version capture the doctrine accurately? Does the humor enhance memorability or merely distract? Would my classmates understand this without the lecture context?

This metacognitive process develops transferable skills. Students learn to evaluate their own understanding by testing whether they can explain concepts in novel ways. They practice the self-assessment necessary for self-regulated learning — monitoring whether they grasp material sufficiently to manipulate it creatively whilst maintaining accuracy. The humor requirement prevents superficial paraphrasing. Students cannot simply restate definitions. They must reconstruct doctrine in ways that reveal deep understanding whilst achieving emotional impact.

Social learning activates when students share summaries and vote on effectiveness. The voting itself constitutes peer assessment, but with reduced stakes because the content is explicitly creative rather than formal academic work. Students develop assessment literacy — recognizing what makes legal explanation both accurate and engaging — through evaluating multiple examples. The anonymity removes fear of judgment whilst preserving the benefits of peer feedback. Students see how classmates approached the same material differently, expanding their conceptual repertoires.

The shared laughter creates community. Legal education's competitive structures isolate students.[^85] An exercise where students collaborate in making doctrine memorable rather than competing for scarce high grades shifts social dynamics. The best summaries become shared resources. Students refer to humorous examples in later discussions, creating inside jokes that signal group membership. The humor humanizes legal education whilst serving pedagogical functions.

Implementation requires minimal faculty time once the exercise is designed. The professor provides the prompt: "Use AI to generate a half-page summary of today's lecture on consideration doctrine. Make it as funny as possible whilst maintaining doctrinal accuracy. Submit anonymously by midnight." Students interact with AI, evaluating and revising outputs. The professor reviews submitted summaries for doctrinal accuracy, selects five finalists, and facilitates the voting and discussion. Total faculty time investment: perhaps 45 minutes for review and one class session for discussion.

Without AI, this exercise would be impractical. Faculty lack time to create multiple humorous examples themselves. Students without AI support would struggle to generate humor that maintains doctrinal accuracy — the cognitive load of simultaneously being funny and correct exceeds many students' capacities, particularly for students whose first language is not English or who lack confidence in creative writing. AI scaffolds the humor generation, enabling students to focus metacognitive effort on evaluation and revision rather than initial creation.

This matters because legal education has long recognized that memorable examples improve learning but has lacked mechanisms to generate them at scale. The exercise produces dozens of examples per class session. Some fail. The best ones enter the professor's teaching materials for future use. Over several semesters, the professor accumulates a library of student-generated, AI-assisted humorous examples covering major doctrines. The resource investment is distributed across students rather than concentrated on faculty. The pedagogical benefit — memorable, emotionally engaging examples that activate metacognitive reflection and social learning — was theoretically available before AI but practically impossible given resource constraints.

### Doctrinally similar, factually varied scenarios

A criminal law professor uses AI to generate five variations of a Fourth Amendment search-and-seizure scenario. The doctrinal elements remain constant: whether a police search constitutes reasonable suspicion for a Terry stop. The factual contexts vary to elicit different emotional responses: an elderly white woman in an affluent neighborhood, a young Black man in a low-income neighborhood, a Middle Eastern person near an airport, a person with visible disabilities, a well-dressed professional in a business district. Students analyze whether the legal standard applies identically across contexts and why their intuitive reactions might differ from the legal analysis.

This exercise engages emotional, sensory, and metacognitive handles simultaneously.

Emotional engagement occurs through empathy and discomfort. Students experience different affective responses to factually varied scenarios despite identical doctrinal structures. The variation forces recognition that identical legal principles apply differently based on social context and implicit biases. A student might feel the search of the elderly white woman seems unreasonable whilst the search of the young Black man seems justified — then confront the discomfort of recognizing this differential response reflects bias rather than legal reasoning. Alinezhad Noghabi and colleagues demonstrated AI-generated content triggers authentic emotional responses including discomfort and vulnerability necessary for socially just pedagogy.[^86]

The emotional authenticity does not require real cases with verified facts. A fabricated scenario describing a Terry stop can trigger genuine empathy if the factual details resonate with students' experiences or cultural awareness. The pedagogical function is perspective-taking — understanding how identical legal doctrines operate differently across social contexts. Whether the scenario describes a real incident or an AI-generated composite is pedagogically irrelevant. What matters is whether the factual variation triggers authentic emotional responses that enable metacognitive reflection on how bias influences legal judgment.

Sensory engagement occurs if the professor pairs text scenarios with visual representations. AI can generate images depicting each scenario — visual representations of the different individuals, different neighborhoods, different circumstances. Mayer's multimedia principle establishes that words and graphics together produce better learning than words alone.[^87] The visual representations activate dual coding pathways whilst reducing cognitive load through distributed processing across visual and verbal channels. A student reading about the elderly woman sees an image depicting an affluent neighborhood, triggering visual memory encoding alongside textual comprehension.

Metacognitive engagement occurs through comparative analysis across scenarios. Students must evaluate their own reasoning processes: Why did I find one search reasonable and another unreasonable when the doctrinal elements are identical? What assumptions did I make about each individual based on demographic characteristics? How do my implicit biases influence legal analysis? This metacognitive reflection develops awareness of reasoning patterns and judgment biases — the foundation for self-regulated learning and professional ethical development.

The exercise also develops pattern recognition. Students see how identical doctrinal structures apply across varied factual contexts. This abstraction skill — recognizing the constant legal elements despite varying facts — represents a core competency in legal reasoning. Simpson identifies pattern recognition and critical thinking as necessary for developing legal reasoning through the FIRAC model applied across wide varieties of assignments.[^88] AI enables generating the wide variety of factually different but doctrinally similar scenarios necessary to build this skill.

Implementation involves designing the initial prompt specifying desired variations and doctrinal constants. The professor prompts: "Generate five Fourth Amendment Terry stop scenarios. Each must involve identical legal elements: reasonable suspicion for stop based on matching general description of suspect from radio call. Vary the following factual elements: race, age, neighborhood affluence, appearance. Maintain identical doctrinal structure." AI generates five scenarios in seconds. The professor reviews for doctrinal accuracy, makes adjustments if necessary, and presents scenarios to students with accompanying questions about differential responses.

The Stanford M&A Negotiation Simulator exemplifies similar applications in legal education.[^89] Built by computer science students interviewing senior M&A partners, the tool uses generative AI to present negotiation scenarios with specific objectives and constraints. Students practice strategic thinking against different personality types. The tool reflects "personalities and thinking of senior lawyers", previewing for young lawyers "experiences of senior partners, walking in their shoes and understanding nuance of those practices in a low-risk environment". Currently used by law firms for new associates, this application demonstrates AI generating varied perspectives that would be impractical to simulate through traditional means.

Israeli law schools documented using Claude, ChatGPT-4, and Gemini Pro 1.5 to generate criminal law case studies with solutions and practice chatbots for interactive learning simulating legal discussions.[^90] Studies of 2,141 students across five courses showed AI enhanced learning but required instructor oversight. The capacity to generate multiple variations of scenarios enables students to encounter diverse factual contexts systematically, building pattern recognition and critical thinking skills.

This matters because legal education has long emphasized that lawyers must understand how legal principles apply across varied contexts. The contextual case method pairs opinions with other perspectives on the same legal questions, exploring complexities that went unaddressed.[^91] By humanizing opinions and encouraging students to "imagine a different legal world", this pedagogical approach benefits from AI's capacity to generate alternative contexts rapidly. Research on perspective-taking in negotiation distinguishes cognitive perspective-taking from emotional empathy, with different skills valuable in different contexts.[^92] AI-generated scenarios enable systematic practice across contexts.

Faculty time investment is front-loaded into prompt design but minimal thereafter. Once the professor develops effective prompts, generating new scenario variations takes seconds. The professor can create fresh examples for each class, preventing students from accessing prior years' materials whilst maintaining doctrinal consistency. The capacity for rapid variation addresses a persistent problem in legal education: how to prevent academic integrity violations when the same hypotheticals circulate for years.

### AI-generated answers for peer evaluation practice

A legal writing professor assigns students to evaluate three legal memoranda addressing the same issue. The memoranda vary in quality: one excellent with clear IRAC structure and effective use of authority, one adequate but with organizational problems, one poor with conclusory analysis and citation errors. Students do not know the memoranda are AI-generated. Working in pairs, students complete evaluation rubrics assessing legal analysis, use of authority, writing clarity, and citation format. The professor then reveals the memoranda were AI-generated, discusses the evaluation rubrics, and assigns peer evaluation of actual student work.

This exercise engages social and metacognitive handles whilst eliminating competitive pressure.

Social learning occurs through collaborative evaluation. Working in pairs, students discuss what makes legal analysis effective. They must articulate criteria for distinguishing excellent from adequate from poor work — a metacognitive process requiring explicit awareness of assessment standards. The collaboration enables legitimate peripheral participation in communities of practice.[^93] Students new to legal writing observe how peers approach evaluation, learning norms and strategies through social interaction. The partnership creates scaffolding — less experienced students learn from more experienced peers, whilst explaining evaluation criteria to partners reinforces the more experienced student's understanding.

The AI-generated content removes social stakes. Students practice evaluation skills without risking peer relationships or experiencing judgment anxiety. They can provide harsh but accurate feedback on poor memoranda without fearing they are insulting classmates. They can disagree with partners about quality assessments without interpersonal consequences. Double-blind protocols in peer assessment prevent identity disclosure between creators and assessors, removing fear of social comparison whilst eliminating interpersonal politics from evaluation.[^94] AI-generated content provides similar benefits whilst enabling practice before consequential peer review.

Metacognitive engagement occurs through developing assessment literacy. Students must make explicit their criteria for quality. What distinguishes clear writing from unclear writing? How much authority is sufficient? When does citation format matter versus when are minor errors acceptable? These evaluative judgments require metacognitive awareness — understanding not just what one thinks is good but why, based on what standards, applied through what reasoning process.

Topping and colleagues' systematic review found AI improves peer assessment across multiple dimensions.[^95] The EvaluMate system powered by ChatGPT facilitates peer review by offering feedback on student reviewers' comments, scaffolding feedback generation. AI provides feedback to reviewers, not just about reviewed work, enabling students to practice evaluation skills iteratively. Guo's study of 124 Chinese undergraduate students found AI-supported peer feedback significantly enhanced feedback quality and writing ability.[^96] The AI chatbot "Eva" provided feedback on student reviewers' comments, creating learning cycles where students developed metacognitive awareness of what constitutes effective feedback.

Lu and colleagues' comparison of AI, peer, and instructor assessment found AI provided higher-quality feedback than peers with more detailed and specific comments.[^97] Students can practice peer evaluation on AI-generated work of varying quality, learning to identify strengths and weaknesses, provide constructive feedback, and calibrate judgments against instructor standards. This practice occurs without risking peer relationships or experiencing judgment anxiety.

Implementation requires the professor to generate AI memoranda of specified quality levels. The prompt specifies: "Generate a legal memorandum analyzing [specific issue]. Make the analysis conclusory with weak use of authority and citation errors." The professor reviews the generated memorandum, adjusts if necessary to ensure it exhibits targeted weaknesses, and repeats for different quality levels. Once generated, the memoranda can be reused across semesters unless the legal issue changes. Total faculty time investment: perhaps two hours to generate and refine three memoranda initially, with no additional time in subsequent semesters.

The exercise prepares students for consequential peer review. After practicing evaluation on AI-generated work, students possess calibrated judgment about quality standards. They have experience articulating constructive feedback. They understand how to use rubrics. The transition to peer review of actual student work involves less anxiety because students have developed competence in low-stakes environments.

This matters because peer assessment improves learning when properly executed but creates social pressures that inhibit effectiveness.[^98] Students worry about being too harsh or too lenient. They fear damaging friendships or creating enemies. They lack confidence in their evaluative judgments. These social and metacognitive barriers prevent effective peer assessment. AI-generated practice materials remove social barriers whilst building metacognitive competence. The result is peer assessment that achieves learning benefits whilst reducing stress and anxiety.

### Emotional hypotheticals with graphics

A torts professor uses AI to generate a negligence hypothetical involving a sympathetic plaintiff — perhaps a child injured on a playground, perhaps an elderly person harmed by inadequate safety measures. The professor prompts AI to create a visual representation: a diagram showing the physical layout of the accident scene, a timeline showing sequence of events, images depicting the harm suffered. Students analyze the negligence elements whilst processing both textual and visual information. The professor then generates variations with less sympathetic plaintiffs to examine how emotional responses influence legal analysis.

This exercise engages emotional and sensory handles simultaneously whilst supporting metacognitive reflection.

Emotional engagement occurs through topic emotions and social emotions triggered by the sympathetic plaintiff. Students care about preventing harm to children or vulnerable elderly individuals. This emotional response activates neural pathways that enhance memory encoding. LaBar and Cabeza demonstrated that emotional events attain privileged status in memory with greater retention advantages.[^99] A student analyzing a negligence case involving a sympathetic plaintiff encodes the doctrinal elements — duty, breach, causation, damages — through affective pathways that strengthen retention.

The emotional content need not involve real cases. A fabricated scenario about a child injured by defective playground equipment triggers genuine sympathy if the factual details resonate emotionally. The pedagogical function is memory encoding and motivational engagement. Whether the child actually exists is pedagogically irrelevant. What matters is whether the scenario triggers emotional responses that activate neural mechanisms supporting learning.

Sensory engagement occurs through visual representations paired with text. Dual coding theory establishes that information processing through verbal and nonverbal channels enhances comprehension and retention.[^100] A diagram showing playground layout enables students to visualize spatial relationships that text alone cannot convey efficiently. A timeline showing sequence of events distributes cognitive load across visual and verbal channels rather than requiring students to construct mental timelines from text alone. An image depicting the harm suffered activates visual memory encoding alongside textual comprehension.

Mayer's contiguity principle requires aligning words to corresponding graphics for maximum effectiveness.[^101] The professor structures presentation so that textual description of the accident scene appears adjacent to the visual diagram. Discussion of temporal sequence coincides with timeline display. This alignment reduces cognitive load by eliminating the need for students to search between separated text and graphics whilst integrating information.

Educational design research found positive emotional design using vivid colors and anthropomorphic features outperformed neutral monochromatic designs on retention and transfer tests.[^102] Making essential elements visually appealing "initiates and guides cognitive processing during learning". AI-generated graphics can incorporate design principles that enhance emotional and cognitive engagement simultaneously — using color to highlight key elements, using visual metaphors to clarify abstract concepts, using spatial arrangement to show relationships.

Trial graphics research demonstrates emotional cues in legal presentations significantly influence perceptions and decision-making.[^103] Strategic emotional triggers including fear, anger, empathy, and surprise capture attention and enhance memory retention. Visual law movements advocate for graphs, icons, tables, and charts supplementing text, focusing on user needs and context, maximizing clarity, and organizing information for both overview and detail. Venn diagrams for overlapping legal categories such as double jeopardy analysis illustrate how visuals reveal essential elements of legal reasoning.

Metacognitive reflection occurs when the professor presents variations with less sympathetic plaintiffs. Students compare their emotional and analytical responses across scenarios. Why did the sympathetic plaintiff case seem like clear negligence whilst the unsympathetic plaintiff case seemed like contributory negligence might apply? How do emotional responses influence application of legal standards? This comparative analysis develops metacognitive awareness of how affect influences judgment — a skill necessary for professional ethical practice.

Implementation involves designing prompts specifying desired emotional content and visual elements. The professor prompts: "Generate a negligence hypothetical involving a child injured on defective playground equipment. Include sympathetic details about the child's age and vulnerability. Create three visual elements: a diagram of the playground layout showing the defective equipment, a timeline of events leading to the injury, an image depicting the type of harm suffered." AI generates text and images in seconds. The professor reviews for doctrinal accuracy and emotional appropriateness, makes adjustments if necessary, and integrates into teaching materials.

DALL-E 3 generates images from text descriptions including diagrams and flowcharts.[^104] Gamma AI creates presentations incorporating AI-generated images through DALL-E 3, Ideogram, and Flux alongside text.[^105] NotebookLM generates audio overviews as podcasts and video overviews with narration, enabling multimodal content creation from single sources.[^106] These tools enable faculty without graphic design skills to create professional-quality visual materials rapidly.

This matters because legal education has understood that visual representations clarify complex doctrine but has lacked resources to create them. Faculty teaching large sections cannot spend hours designing graphics for each hypothetical. AI removes this barrier whilst preserving pedagogical judgment about which concepts benefit from visual representation and what emotional valence serves learning objectives. The combination of emotional engagement and sensory processing creates synergistic effects where affective and visual encoding reinforce each other, producing stronger memory traces than either alone.

---

These four applications demonstrate multi-loading in practice. Each activates multiple pedagogical handles simultaneously. The humorous summaries engage emotion through dopamine release, metacognition through evaluation of humor effectiveness, and social learning through shared voting. The varied scenarios engage emotion through empathy and discomfort, sensory processing through visual representations, and metacognition through comparative analysis. The peer evaluation practice engages social learning through collaborative assessment and metacognition through developing assessment literacy whilst eliminating competitive pressure. The emotional hypotheticals with graphics engage emotion through sympathetic content and sensory processing through dual coding whilst supporting metacognitive reflection on how affect influences judgment.

None of these applications requires perfect doctrinal accuracy in every detail. Fabricated case names, fictional scenarios, and AI-generated graphics serve pedagogical functions effectively regardless of whether they correspond to real cases or real images. What matters is whether they engage multiple handles simultaneously in ways that enhance learning — a question of pedagogical design, not citational precision.

The resource investment is minimal compared to manual creation. Faculty design prompts, evaluate AI outputs for appropriateness, and facilitate exercises. The content generation itself takes seconds. The pedagogical benefit — materials engaging multiple dimensions simultaneously — was theoretically available before AI but practically impossible given time constraints.

The next section examines what competencies faculty need to design such multi-loaded materials effectively.

---

[^83]: James and Legg cited in original article (full citation to be confirmed).

[^84]: John A Banas and others, 'A Review of Humor in Educational Settings: Four Decades of Research' (2011) 20 Communication Education 115.

[^85]: Levit and Linder (n 62).

[^86]: Alinezhad Noghabi and others (n 44).

[^87]: Mayer (n 3).

[^88]: Cite to Simpson to be confirmed from original article.

[^89]: Stanford M&A Negotiation Simulator documentation (2024).

[^90]: Israeli law schools documentation (2024) cited in original article.

[^91]: Contextual case method literature cited in original article.

[^92]: Perspective-taking research cited in original article.

[^93]: Lave and Wenger (n 60).

[^94]: Double-blind protocol research cited in original article.

[^95]: Topping and others (n 68).

[^96]: Guo (n 70).

[^97]: Lu and others (n 71).

[^98]: Li and others (n 67).

[^99]: LaBar and Cabeza (n 39).

[^100]: Paivio (n 46).

[^101]: Mayer (n 3).

[^102]: Educational design research cited in original article.

[^103]: Trial graphics research cited in original article.

[^104]: OpenAI (n 54).

[^105]: Gamma App (n 55).

[^106]: Google (n 56).

## Competency requirements and frameworks

Multi-loading does not occur automatically. Simply using AI tools does not guarantee that generated content engages multiple pedagogical dimensions effectively. A professor can prompt AI to create a hypothetical, receive output in seconds, and present it to students — yet achieve only superficial engagement if the exercise lacks intentional design. The difference between multi-loading and mere tech-use depends on faculty competencies in three areas: pedagogical frameworks guiding intentional design, AI literacy enabling effective prompting and evaluation, and metacognitive awareness of when multi-dimensional engagement serves learning objectives versus when it becomes unnecessary complexity.

Educational frameworks provide structures for multi-loading design. Universal Design for Learning establishes three principles that align with multi-handle pedagogy.[^107] Multiple means of engagement address the affective network — tapping into learners' interests, challenging appropriately, and motivating through emotional responses. Multiple means of representation address the recognition network — providing multiple ways to acquire information through varied sensory modalities. Multiple means of action and expression address the strategic network — offering alternatives for demonstrating learning. UDL aims to develop expert learners who are purposeful, resourceful, and strategic.

These principles map directly onto multi-loading applications. The humorous lecture summary exercise provides multiple means of engagement through emotional humor whilst offering multiple means of expression through creative writing. The varied scenarios provide multiple means of representation through visual and textual information whilst engaging affectively through empathy. The peer evaluation practice provides multiple means of action through collaborative assessment whilst reducing barriers created by competitive anxiety. The emotional hypotheticals with graphics provide multiple means of representation through dual coding whilst engaging through sympathetic content.

UDL guides decisions about which handles to activate for specific learning objectives. A professor designing a contracts exercise must ask: What barriers prevent students from engaging with consideration doctrine? Perhaps abstract concepts need visual representation. Perhaps lack of emotional engagement prevents memory encoding. Perhaps competitive pressure inhibits collaborative discussion. Perhaps students lack metacognitive awareness of their understanding gaps. UDL principles help diagnose barriers and select appropriate interventions.

Technological Pedagogical Content Knowledge provides frameworks for integrating AI into multi-loading design. Mishra and Koehler identified seven knowledge domains: technology knowledge, content knowledge, pedagogical knowledge, and the intersections between them.[^108] TPACK integrates all three knowledge bases — understanding subject matter, knowing effective teaching methods, and recognizing how technology transforms both content and pedagogy. Celik examined Intelligent-TPACK, exploring teachers' professional knowledge to ethically integrate AI-based tools into education.[^109]

TPACK prevents technology-driven rather than pedagogy-driven decisions. A professor should not use AI to generate visual representations because the technology can produce images rapidly. The professor should identify that visual representations would clarify spatial relationships in property doctrine that text alone cannot convey efficiently, then deploy AI to generate appropriate visuals. Technology serves pedagogical goals rather than dictating them.

This distinction matters because AI tools invite misuse through their ease. A professor can generate dozens of hypotheticals in minutes. But quantity does not equal quality. The pedagogical question is whether the hypotheticals engage handles that enhance learning for the specific objectives. TPACK provides decision frameworks: Does this content align with learning goals? Does the technology add pedagogical value beyond efficiency? Have I maintained content accuracy whilst leveraging technological capabilities?

The humorous summary exercise demonstrates TPACK integration. Content knowledge: understanding consideration doctrine sufficiently to evaluate whether student-generated humor maintains accuracy. Pedagogical knowledge: recognizing that humor engages emotional and metacognitive handles whilst reducing the competitive pressure that inhibits creative risk-taking. Technology knowledge: understanding that AI can generate varied humorous examples rapidly whilst requiring human evaluation of appropriateness. The integration: designing prompts that scaffold student creation of content engaging multiple handles, evaluating outputs for doctrinal accuracy, and facilitating discussion that develops metacognitive awareness.

AI literacy extends beyond technical proficiency. Long and Magerko defined AI literacy as abilities to critically evaluate AI, communicate with AI, and utilize AI as tools.[^110] The framework encompasses four aspects: recognizing and understanding AI capabilities and limitations, using and applying AI appropriately, evaluating and creating AI outputs, and understanding AI ethics. Kong, Cheung, and Zhang developed three-dimensional frameworks: cognitive dimensions understanding AI concepts, affective dimensions addressing attitudes toward AI, and sociocultural dimensions considering broader social impacts.[^111]

Digital Promise's 2024 framework articulated three modes of engagement: UNDERSTAND acquiring basic AI knowledge for informed decisions, EVALUATE centering human judgment to critically consider benefits and costs, and USE encompassing interact, create, and problem-solve applications.[^112] UNESCO's 2024 AI Competency Framework for Teachers articulated five aspects at three levels: human-centered mindset, ethics of AI, AI foundations and applications, AI pedagogy, and AI for professional development.[^113]

These frameworks share emphasis on human judgment as the critical competency. AI generates outputs rapidly. Faculty must evaluate whether outputs achieve pedagogical purposes. A professor using AI to generate varied scenarios must assess: Does the factual variation genuinely trigger different emotional responses whilst maintaining doctrinal similarity? Are the differences substantial enough to enable comparative analysis? Do the scenarios resonate with diverse student populations without reinforcing stereotypes? These evaluative judgments require understanding both AI capabilities and pedagogical goals.

The peer evaluation exercise demonstrates AI literacy requirements. The professor must understand that AI can generate legal memoranda of specified quality levels — the technological capability. The professor must evaluate whether AI-generated memoranda exhibit weaknesses students need practice identifying — the pedagogical alignment. The professor must consider whether revealing that memoranda are AI-generated enhances or undermines the exercise — the ethical dimension. The professor must judge whether practicing on AI-generated content genuinely prepares students for peer review or merely creates an illusion of preparation — the critical evaluation.

Faculty development must address these competencies systematically. Mah and Groß studied 122 faculty from German higher education institutions, finding perceived benefits included greater equity in education, personalized learning, enhanced student understanding, and positive influence on learning outcomes.[^114] Perceived challenges centered on lack of AI literacy among students and faculty, ethical considerations, curriculum development needs, and infrastructure requirements. Latent class analysis identified four faculty profiles: Optimistic (33.5%), Critical (27.3%), Critically Reflected (33.9%), and Neutral (5.3%).

The Critically Reflected profile — agreeing with both benefits and challenges — represents the stance appropriate for multi-loading design. Faculty should recognize AI's capacity to generate content engaging multiple handles whilst remaining aware of limitations requiring human oversight. Uncritical optimism risks deploying AI without evaluating pedagogical effectiveness. Categorical criticism prevents recognizing legitimate applications. Critical reflection balances enthusiasm with caution.

Professional development must move beyond tool tutorials. Faculty need practice designing prompts that specify pedagogical properties, not just content topics. A workshop teaching faculty to use ChatGPT provides minimal value if participants learn syntax but not pedagogical design. Effective development teaches faculty to analyze learning objectives, identify which handles would enhance achievement, design prompts specifying desired properties, and evaluate outputs for pedagogical appropriateness.

The varied scenarios exercise illustrates these competencies. A faculty development workshop might present the learning objective: students should understand how identical legal doctrines apply across varied factual contexts whilst recognizing how implicit biases influence legal judgment. Participants practice designing prompts specifying: doctrinal elements that must remain constant, factual elements that should vary, emotional valences that should differ, visual representations that would clarify spatial or temporal relationships. Participants generate scenarios using AI, exchange scenarios with colleagues, evaluate whether scenarios achieve stated objectives, and revise prompts based on feedback.

This active practice develops competencies that passive tool demonstrations cannot. Faculty learn through doing — the same pedagogical principle that guides effective student learning. Workshops emphasizing hands-on prompt design, peer feedback on AI-generated materials, and iterative revision build skills applicable across disciplines and learning objectives.

Usage patterns show faculty interest in such development. Professional development interest appeared strong, with 78.5% interested in teaching and learning with AI tools, 66.4% interested in AI-based tools training, and 48.6% interested in AI for research.[^115] Preferred formats emphasized self-paced online courses. Planned time investment ranged from 5–20 hours. Motivation included 48.8% pursuing curiosity about AI applications.

These preferences suggest development should offer flexible pathways. Faculty with high AI literacy may need only advanced workshops on multi-loading design. Faculty new to AI need foundational understanding of capabilities and limitations before attempting complex applications. Discipline-specific development addresses the reality that contracts professors need different examples than constitutional law professors, even though underlying pedagogical principles remain constant.

The emotional hypotheticals with graphics exercise demonstrates why discipline specificity matters. A contracts professor generating visual representations needs diagrams showing offer-acceptance timelines and consideration flow. A criminal law professor needs diagrams showing elements of crimes and timelines of events establishing mens rea. A property professor needs spatial diagrams showing boundary disputes and easements. The TPACK framework applies across disciplines, but the specific content knowledge differs. Development must address both general principles and discipline-specific applications.

Competency development never ends. AI capabilities evolve rapidly. GPT-4 generates more accurate citations than GPT-3.5, though still with substantial error rates.[^116] Future models may improve further or develop new capabilities. Faculty must maintain awareness of changing capacities whilst preserving core pedagogical judgment. The question is not whether a specific AI version can perform a task. The question is whether using AI to perform that task enhances learning through multi-handle engagement.

The four applications demonstrated in the previous section share common competency requirements. Faculty must design prompts specifying pedagogical properties: emotional valence, visual elements, quality variation, factual diversity. Faculty must evaluate outputs for alignment with learning objectives: Does this humor enhance or distract? Do these visuals clarify or confuse? Does this quality variation enable calibration or mislead? Faculty must facilitate exercises that activate multiple handles: What metacognitive questions will prompt reflection? How will social sharing occur? What emotional responses will be discussed?

These competencies develop through practice and reflection. A professor's first attempt at multi-loading design may produce mixed results. The humorous summaries might fall flat. The varied scenarios might not trigger intended emotional responses. The peer evaluation might not reduce social pressure as hoped. The emotional hypotheticals might overwhelm students with visual information rather than enhancing comprehension. Iterative refinement based on student response and learning outcomes gradually builds expertise.

This is pedagogical development, not technological training. Faculty have developed similar expertise in traditional teaching through years of refining lectures, adjusting hypotheticals, and responding to student feedback. Multi-loading with AI requires similar iterative development. The difference is that AI removes resource constraints that previously prevented experimentation. A professor can generate five scenario variations, test them with students, evaluate which works best, and refine the prompt for future use. The rapid generation enables experimentation that was impractical when creating each variation required hours.

Tools enable. Pedagogical judgment determines whether multi-loading succeeds or becomes superficial tech-use. A hammer enables building houses but does not make someone a carpenter. AI enables multi-loading but does not make someone an effective pedagogue. Faculty need frameworks like UDL and TPACK guiding intentional design, AI literacy enabling effective prompting and critical evaluation, and discipline-specific practice building expertise in their content domains. Professional development must address all three whilst remaining flexible enough to accommodate faculty at different starting points with different learning preferences.

The competency requirements are substantial but not insurmountable. Faculty already possess deep content knowledge and pedagogical expertise from years of teaching. Multi-loading adds technological competency and systematic frameworks for multi-dimensional design. Development programs addressing these needs enable faculty to deploy AI effectively whilst avoiding the superficial tech-adoption that characterizes failed educational technology initiatives.

---

[^107]: David H Rose and Anne Meyer, _Teaching Every Student in the Digital Age: Universal Design for Learning_(Association for Supervision and Curriculum Development 2002).

[^108]: Punya Mishra and Matthew J Koehler, 'Technological Pedagogical Content Knowledge: A Framework for Teacher Knowledge' (2006) 108 Teachers College Record 1017.

[^109]: Ilknur Celik, 'Towards Intelligent-TPACK: An Empirical Study on Teachers' Professional Knowledge to Ethically Integrate Artificial Intelligence-Based Tools into Education' (2023) 150 Computers in Human Behavior 107966.

[^110]: Duri Long and Blakeley H Magerko, 'What Is AI Literacy? Competencies and Design Considerations' (2020) Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems 1.

[^111]: Siu-Cheung Kong, Man-Ling Cheung, and Guo Zhang, 'Evaluating an Artificial Intelligence Literacy Programme for Developing University Students' Conceptual Understanding, Literacy, Empowerment and Ethical Awareness' (2023) 26 Educational Technology & Society 16.

[^112]: Digital Promise, 'AI Literacy Framework' (2024).

[^113]: UNESCO, 'AI Competency Framework for Teachers' (2024).

[^114]: Dana-Kristin Mah and Viktoria Groß, 'Faculty Perspectives on Generative AI in Higher Education: A Latent Class Analysis' (2024) 17 International Journal of Educational Technology in Higher Education 42.

[^115]: Mah and Groß (n 114).

[^116]: Walters and Wilder (n 30).

## Conclusion

Legal education deploys AI one-dimensionally: summarizing cases, generating quizzes, providing automated feedback. These applications save time but miss the technology's distinctive pedagogical capacity. AI can generate content engaging emotional, sensory, social, and metacognitive dimensions simultaneously within single learning objects. This multi-loading addresses resource constraints that have prevented systematic implementation of pedagogical strategies educational psychology validated decades ago.

The argument rests on reconceptualizing AI's role. Faculty resistance to adoption stems partly from accuracy expectations appropriate for legal research but misapplied to pedagogical content. AI hallucinates citations at rates making it unsuitable for brief writing or judicial decisions. These failures matter for research applications. But pedagogical materials serve different functions. Hypotheticals need emotional authenticity and factual variation, not Bluebook precision. Scenarios for empathy development need doctrinal similarity across varied contexts, not verifiable case names. Peer evaluation practice benefits from AI-generated answers of varying quality because students develop assessment skills through identifying flaws.

The accuracy trap operates through category error. Traditional case method materials served dual functions — authoritative legal doctrine and pedagogical hypotheticals simultaneously. This alignment created expectations that all educational content must meet research standards. AI dissolves this conflation. The technology generates pedagogical scenarios engaging multiple learning dimensions without producing authoritative doctrine. This represents the use case where AI's capacities for rapid generation, infinite variation, and multimodal output shine — functions that time constraints prevented faculty from performing manually.

Four pedagogical handles operate through well-established mechanisms. Emotional engagement activates neural pathways enhancing memory encoding and retention. Multiple sensory modalities distribute cognitive load whilst increasing retrieval pathways through dual coding. Social learning leverages communities of practice and legitimate peripheral participation. Metacognitive development builds self-regulated learning capacities transferable across contexts. Educational psychology has demonstrated these dimensions function synergistically. Legal education has implemented them sporadically where resources permit — clinical programs with favorable faculty ratios address emotional and social dimensions, technology-enhanced courses employ multimodal materials, reflective practice initiatives build metacognitive awareness.

AI removes the resource barriers preventing systematic implementation at scale. The four applications demonstrate this capacity concretely. Students using AI to generate humorous lecture summaries engage emotion through dopamine release, metacognition through evaluation required for humor construction, and social learning when sharing with peers. AI generating doctrinally similar but factually varied scenarios enables perspective-taking exercises that trigger empathy whilst building pattern recognition. AI-generated answers for peer evaluation practice develop assessment literacy without competitive pressure. Emotional hypotheticals paired with AI-generated graphics engage dual coding pathways whilst activating affective memory encoding.

Each application activates multiple handles concurrently, not sequentially. The engagement is simultaneous — emotional responses enhancing memory whilst metacognitive reflection deepens understanding whilst social interaction provides feedback. This represents multi-loading's pedagogical advantage. Faculty could theoretically create such materials manually. The resource investment — hours per hypothetical, design skills for visual representations, elaborate scaffolding for peer exercises — prevented systematic implementation. AI generates varied content in seconds, removing time constraints whilst preserving faculty judgment about learning objectives and pedagogical appropriateness.

Implementation requires competencies beyond technical proficiency. Universal Design for Learning and Technological Pedagogical Content Knowledge provide frameworks for intentional design. AI literacy encompasses critical evaluation, effective prompting, and ethical awareness. Faculty development must address these dimensions through hands-on practice designing prompts specifying pedagogical properties, evaluating outputs for alignment with learning objectives, and iterating based on student response. Professional development succeeds when it treats pedagogy as primary and technology as enabling, not when it treats tools as primary and pedagogy as afterthought.

Research gaps constrain evidence-based implementation. Legal education lacks empirical studies measuring learning outcomes from multi-loading applications, longitudinal research tracking skill development over time, and systematic evaluation comparing different integration approaches. The field needs rigorous experimental designs with proper controls, not anecdotal institutional reports. Equity concerns require attention — digital divides create uneven access, algorithmic bias may disadvantage underrepresented students, data privacy affects vulnerable populations disproportionately. Over-reliance risks remain documented: diminished drive and commitment, reduced critical thinking, uncritical acceptance of AI outputs.

These constraints matter. They require institutional support through policies addressing data privacy and ethical AI use, training programs building technological literacy, and resources ensuring equitable access. They demand ongoing assessment of learning outcomes, not adoption for novelty's sake. They necessitate faculty autonomy to reject AI applications that undermine rather than enhance learning.

But constraints do not invalidate the argument. The question is not whether multi-loading improves learning — educational psychology established synergistic effects of multi-dimensional engagement through decades of cognitive science research. The question is not whether AI can generate content engaging multiple handles — the four applications demonstrate this capacity exists now, not in speculative futures. The question is whether legal educators will deploy AI to make systematic multi-loading feasible at the scale necessary to benefit all students, not just those in resource-rich clinical programs or technology-enhanced courses.

AI offers solutions to documented challenges in legal education. Competitive grading structures isolate students — multi-loading creates opportunities for social learning without competitive stakes. Time constraints prevent rich hypothetical development — AI generates varied scenarios rapidly. Limited feedback leaves students comparing themselves to peers rather than learning objectives — AI enables practice that builds skills without social judgment. Emotional suppression in doctrinal courses hinders memory encoding — AI generates content triggering appropriate affective responses.

Implementation depends on institutional commitment and faculty development. Tools exist. Pedagogical frameworks exist. Educational psychology validating multi-dimensional engagement exists. What remains is systematic deployment translating theoretical understanding into practical application. This requires recognizing that AI adoption represents pedagogical evolution, not mere technological convenience. It demands distinguishing applications where accuracy matters from applications where engagement, variation, and rapid generation matter more.

The transformation from one-dimensional to multi-dimensional AI use represents opportunity and obligation. Legal education can continue deploying AI for efficiency — summarizing longer into shorter, automating feedback, generating quiz questions — whilst missing the technology's distinctive contribution. Or legal education can reconceptualize AI as content generator enabling pedagogical strategies that resource constraints prevented for decades. The choice determines whether AI adoption changes teaching at the margins or addresses fundamental challenges limiting legal pedagogy systematically.

The path forward requires faculty to experiment with multi-loading applications, evaluate learning outcomes rigorously, and iterate based on evidence rather than enthusiasm. It requires institutions to provide development opportunities, protect faculty time for pedagogical innovation, and maintain standards ensuring AI enhances rather than replaces human judgment. It requires the field to conduct systematic research establishing which multi-loading approaches work best for which learning objectives with which student populations.

Multi-loading with AI will not solve all problems in legal education. It will not eliminate competitive pressure from curved grading. It will not replace the value of clinical experience or one-on-one mentorship. It will not make struggling students suddenly excel or transform poor teaching into effective pedagogy. But it can address the resource constraint preventing systematic implementation of multi-dimensional engagement at scale. It can enable faculty to create materials that activate emotional, sensory, social, and metacognitive pathways simultaneously — materials that educational psychology tells us improve learning but that time limitations prevented most faculty from producing.

The technology exists. The pedagogical frameworks exist. The research validating multi-dimensional engagement exists. The question is implementation.