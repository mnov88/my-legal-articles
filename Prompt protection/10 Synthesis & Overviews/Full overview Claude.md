# Intellectual Property Protection for AI Prompts under EU Law: A Legal Framework Analysis

**Does EU law currently protect AI prompts - if so, in which ways and under which conditions - and is reform needed?**

The emergence of generative artificial intelligence systems has created a novel category of potentially protectable subject matter: the textual instructions (prompts) that users provide to elicit AI-generated outputs. These prompts range from simple single-sentence requests to complex multi-paragraph specifications incorporating technical parameters, stylistic directions, and contextual examples. As commercial prompt marketplaces have proliferated and prompt engineering has emerged as a recognized skill, a critical legal question arises: does European Union intellectual property law protect these prompts, and if so, under what conditions?

This article provides comprehensive legal analysis of prompt protectability under four EU intellectual property frameworks: copyright law, software and database protection, patent law, and trade secrets. The analysis reveals that while prompts theoretically could receive protection under certain frameworks - particularly trade secrets and, in exceptional cases, copyright - significant doctrinal obstacles exist under each regime. Most fundamentally, prompts face the challenge that they constitute instructions about what to create (ideas) rather than creative expression itself, placing them in tension with the foundational principle that intellectual property law does not protect abstract ideas. The examination of these frameworks reveals not only the current state of EU law but also exposes deeper questions about whether existing IP categories adequately address the economic and innovation dynamics of human-AI interaction.

## Why prompts merit legal protection consideration

Before examining whether prompts receive legal protection, it is essential to establish why protection might be economically and normatively justified. Four primary rationales emerge from the economic and legal literature.

**Investment in skill development and R&D.** Prompt engineering has emerged as a non-intuitive skill requiring substantial investment in training and practice. Academic research by Oppenlaender and colleagues demonstrates empirically that while participants could evaluate prompt quality, they lacked the style-specific vocabulary and technical knowledge necessary for effective prompting, confirming that prompt engineering must be acquired through practice rather than being immediately accessible to any AI user. The investment manifests in multiple forms: time spent on iterative testing (with sources noting significant expenditure on trial-and-error experimentation), acquisition of technical knowledge about model architectures and parameters, and formal training through the growing industry of prompt engineering courses. This human capital investment creates economic value that, under traditional IP theory, might merit protection to incentivize continued skill development and knowledge creation.

**Demonstrated commercial value and competitive advantage.** The rapid emergence of commercial prompt marketplaces provides empirical evidence of economic value. PromptBase, launched in June 2022 as the first major marketplace, reports over 370,000 users and more than 220,000 prompts available for purchase at prices ranging from $1.99 to $4.99, with the platform retaining a 20% commission. Other marketplaces including ChatX (paying 39 CAD per successful prompt), PromptHero (offering millions of AI art images with visible prompts plus educational courses), and PromptScoop (with testimonials claiming $30,000 USD monthly earnings) demonstrate a functioning market for prompt-related services. Beyond direct sales, businesses derive competitive advantage from proprietary prompt libraries that enable consistent brand messaging, efficient content generation, and quality outputs that differentiate their services from competitors. For enterprises using AI-powered services, optimized prompts represent cost savings through reduced token usage and improved first-attempt success rates.

**Creative and intellectual labor.** The creative dimension of prompt engineering has been examined through computational creativity frameworks. Research by Bird evaluating prompts against established creativity theories identifies novelty and value generation in sophisticated prompt construction. While simple prompts offer limited creative choices, complex prompts involve selection of precise vocabulary, sequencing of instructions, strategic use of examples, and calibration of technical parameters - choices that could reflect the personality and creative judgment of the prompt engineer. DLA Piper's legal analysis notes that sophisticated prompts "can be traced back to the creativity and personality of their author," drawing an analogy to other forms of technical writing that receive copyright protection. The intellectual labor extends beyond mere word choice to understanding AI model behaviors, anticipating failure modes, and crafting prompts that navigate the complex semantic space of large language models.

**Information asymmetry and first-mover concerns.** Without IP protection, information asymmetry creates market dynamics that may discourage prompt development. Once a prompt is disclosed - whether through use in generating visible outputs or through marketplace sales - it becomes immediately copyable by competitors. Unlike physical goods or most digital products that require manufacturing capability or technical implementation, prompts are pure information: a string of text that can be copied instantly at zero marginal cost. This creates severe appropriability problems where the first mover invests in developing effective prompts but cannot prevent immediate free-riding once those prompts are revealed. The temporal element matters: prompt development investment occurs upfront, but competitive advantage dissipates upon disclosure. Trade secret protection partially addresses this through secrecy maintenance, but many commercial applications require prompt use in contexts where outputs are visible, potentially enabling reconstruction.

These four rationales establish economic and policy justifications for considering legal protection. However, the normative case for protection must be balanced against countervailing concerns: the risk of restricting access to AI technology through monopolization of basic communication methods, the danger of creating barriers to AI adoption, and the fundamental question of whether prompts represent sufficiently original contributions to merit exclusive rights. The strength of protection arguments varies significantly with prompt complexity - simple instructions like "write a marketing email" present minimal investment and creativity, while sophisticated multi-paragraph prompts with specific technical parameters and carefully crafted examples may cross the threshold justifying protection. With these economic foundations established, the analysis now turns to examining whether and how existing EU legal frameworks accommodate prompt protection.

## Copyright protection for AI prompts under EU law

The question of whether prompts qualify for copyright protection under EU law requires rigorous analysis of the harmonized originality standard as interpreted by the Court of Justice of the European Union, application of the idea-expression dichotomy fundamental to copyright doctrine, and assessment of whether prompts constitute protectable expression or merely unprotectable instructions.

### The harmonized EU originality standard and its requirements

EU copyright law has converged on a unified originality standard applicable to all categories of works. The foundational provision appears in Article 1(3) of the Software Directive 2009/24/EC, which provides that "a computer program shall be protected if it is original in the sense that it is the **author's own intellectual creation**. No other criteria shall be applied to determine its eligibility for protection." The CJEU has extended this standard beyond software to all copyrightable subject matter. In *Infopaq International v Danske Dagblades Forening* (C-5/08), the Court held at paragraph 37 that "**copyright within the meaning of Article 2(a) of Directive 2001/29 is liable to apply only in relation to a subject-matter which is original in the sense that it is its author's own intellectual creation.**" This represents a harmonized standard displacing earlier national variations in originality thresholds.

The CJEU has articulated this standard through several cumulative requirements that any work must satisfy. **First, the work must reflect the author's personality.** As the Court stated in *Painer v Standard Verlags* (C-145/10) at paragraph 88, "an intellectual creation is an author's own if it **reflects the author's personality.**" This personalizing requirement distinguishes copyright from patent or design protection focused on technical or aesthetic function. **Second, the author must have exercised free and creative choices.** The *Painer* judgment continues at paragraph 89 that this occurs "**if the author was able to express his creative abilities in the production of the work by making free and creative choices**." The Court provided concrete examples in the photographic context: "the author can make free and creative choices in several ways and at various points in its production," including selection of background, pose of subject, lighting, angle, and subsequent processing decisions. Each of these choices permits the photographer to stamp the work with a "personal touch."

**Third, where technical considerations, rules, or constraints dictate expression, originality cannot be found.** The CJEU established this limitation in *BSA v Ministerstvo kultury* (C-393/09) at paragraph 50: "**where the expression of those components is dictated by their technical function, the criterion of originality is not met, since the different methods of implementing an idea are so limited that the idea and the expression become indissociable.**" This principle was refined in the context of functional designs in *Brompton Bicycle v Chedech* (C-833/18) at paragraph 24, where the Court held that "**where the realisation of a subject matter has been dictated by technical considerations, rules or other constraints which have left no room for creative freedom, that subject matter cannot be regarded as being original.**" Even where a product's shape is partly necessary to obtain a technical result, copyright may apply if the shape nonetheless permits the author to express creative ability through free choices reflecting personality.

**Fourth, the work must be identifiable with sufficient precision and objectivity.** In *Levola Hengelo v Smilde Foods* (C-310/17), the CJEU refused copyright protection for the taste of a cheese spread, holding at paragraph 40 that "**for there to be a 'work' as referred to in Directive 2001/29, the subject matter protected by copyright must necessarily be expressed in a manner which makes it identifiable with sufficient precision and objectivity**, even though that expression is not necessarily in permanent form." The taste of food failed this requirement because taste sensations are "subjective and variable," depending on individual factors and context, such that "it is not possible in the current state of scientific development to achieve by technical means a precise and objective identification of the taste."

**Fifth, only expression receives protection, never ideas or principles.** Article 1(2) of the Software Directive provides explicitly that "protection in accordance with this Directive shall apply to the expression in any form of a computer program. **Ideas and principles which underlie any element of a computer program, including those which underlie its interfaces, are not protected by copyright** under this Directive." The CJEU emphasized this limitation in *BSA* at paragraph 49: "**only the expression of a computer program is so protected, whereas ideas and principles which underlie any element of that program, including those which underlie its interfaces, are not.**" Furthermore, in *Infopaq* at paragraphs 45-46, the Court held that while "words, considered in isolation, are not as such an intellectual creation of the author who employs them," protection arises only through "the choice, sequence and combination of those words" that expresses creativity in an original manner. Critically, "**words as such do not, therefore, constitute elements covered by the protection.**"

The CJEU consolidated these principles in *Cofemel v G-Star Raw* (C-683/17), confirming at paragraph 29 that "**a subject matter can be classified as a 'work' within the meaning of Directive 2001/29 only if it is an original subject matter in that it is the author's own intellectual creation.**" At paragraph 30, the Court clarified that "the assessment of the originality of a subject matter is therefore primarily based on whether that subject matter **reflects the personality of its author, as an expression of his or her free and creative choices**." Crucially, the Court held that national legislation cannot confer copyright protection based on criteria other than originality - for example, aesthetic effect or applied art status - without violating the harmonized standard.

### Application of the originality test to AI prompts

With the legal test established, the critical question becomes whether AI prompts satisfy these cumulative requirements. The analysis must distinguish between simple prompts and complex prompts, as the originality threshold creates a natural filtering effect.

**For simple prompts - single sentences or basic instructions like "create an image of a cat drinking a cocktail" or "write a professional email requesting a meeting" - copyright protection is almost certainly unavailable.** These prompts fail multiple elements of the originality test. They do not reflect sufficient free and creative choices beyond the obvious and necessary words to convey the intended instruction. Following the *Infopaq* principle that "words as such" do not constitute protectable elements and that protection requires originality through "the choice, sequence and combination of those words," simple prompts lack the requisite selection and arrangement creativity. They fail to reflect the author's personality in the sense articulated in *Painer* - they are functional communications of desired outcomes, not expressions bearing the author's personal touch. Most importantly, they constitute ideas about what to create rather than creative expression. The instruction "cat drinking cocktail" is the idea or concept the user wishes to see realized; it is not the expression itself. Under the idea-expression dichotomy, such instructions fall on the idea side of the divide.

**Complex prompts present a more nuanced case but likely also fail the originality test, albeit for different reasons.** Consider a detailed multi-paragraph prompt specifying artistic style, technical parameters, composition elements, lighting conditions, mood descriptors, and specific examples of desired aesthetic qualities. Such prompts demonstrate greater investment of labor and more elaborate word choice, sequencing, and combination. They might reflect stylistic preferences and technical knowledge specific to the author. However, even complex prompts face three fundamental obstacles.

**First, prompts are instructions about what to create, not the expression itself.** This implicates the core idea-expression dichotomy that pervades EU copyright law. A prompt stating "create an impressionist-style painting of the Eiffel Tower at sunset, with warm orange and pink tones, soft brushstrokes suggesting movement, positioned at right third of composition following rule of thirds, with foreground figures in shadow to create depth" is an elaborate instruction - but it remains an instruction specifying the idea of what the AI should generate. The resulting AI-generated image would be the expression (though it faces separate authorship questions). Protecting the prompt would effectively grant rights over the idea or concept described, not the particular expression of that idea. The CJEU has been emphatic that ideas, including those underlying interfaces and interaction methods, receive no copyright protection.

**Second, prompts are functionally dictated by their purpose: communicating instructions to AI systems.** The *BSA* principle that "where the expression of those components is dictated by their technical function, the criterion of originality is not met" applies with particular force to prompts. A prompt's purpose is to effectively communicate with an AI model to achieve a desired output. This functional purpose constrains expression significantly. While some word choice flexibility exists, the prompt must use language the AI model will process effectively, must specify parameters in ways the system recognizes, and must structure instructions for optimal results. These technical constraints reduce the space for free and creative choices. As the *Brompton Bicycle* decision clarified, even when some creative freedom remains, if "the realisation of a subject matter has been dictated by technical considerations, rules or other constraints which have left no room for creative freedom," originality fails. Many prompt elements - parameter specifications, formatting conventions, strategic keyword placement - are dictated by AI model requirements rather than creative choice.

**Third, prompts raise merger doctrine concerns where limited ways exist to express particular instructions.** When there are only a few ways to convey a specific instruction to an AI system, the expression merges with the idea, and copyright protection is denied to prevent monopolization of the idea itself. For example, instructing an AI to "make the image brighter" or "write in a professional tone" or "use active voice" can be expressed in only limited ways that effectively communicate with AI systems. Protecting such formulations would effectively monopolize the underlying instructions themselves. European copyright doctrine, while not using the term "merger doctrine" explicitly, recognizes this principle through the *BSA* holding that where methods of implementing an idea are so limited that idea and expression become indissociable, no protection attaches.

### Scholarly consensus and national perspectives

Academic commentary on prompt copyrightability has emerged rapidly with substantial consensus that prompts likely fail the originality threshold under EU law. Professor He, writing in GRUR International, argues that "judicial recognition of text-to-image copyrightability at the current stage is dangerous" because "the practice is not in accordance with our traditional understanding of originality and the author-work relationship." He emphasizes that prompts constitute "merely unprotectable ideas" rather than expressions, noting that the U.S. Copyright Office has concluded that "prompts alone do not provide sufficient human control to make users of an AI system the authors of the output."

Professors Gervais and Hugenholtz, leading EU copyright scholars, address the question directly on the Kluwer Copyright Blog: "Can a prompt be protected as a work of authorship? It should, if it is (a) created by one or more humans; (b) not de minimis; and (c) embodies creative choices." However, they identify the critical problem: "The hard question is whether those creative choices - the originality, if any - of the prompt is 'transferable' into the product or output of the AI machine... This gets dangerously close to owning the underlying idea, and thus goes against a fundamental principle of international copyright law." They conclude that "**if the originality of the instructions is not sufficiently reflected in the machine's product, there is no protected work in the output. That should be the default position.**"

Professor Quintais and Professor Hugenholtz, in their comprehensive analysis of AI-assisted output published in the International Review of Intellectual Property and Competition Law, argue that current EU copyright rules are "generally suitable and sufficiently flexible to deal with the challenges posed by AI-assisted output" when properly applied. They emphasize that where subject matter has been dictated by technical considerations leaving no room for creative freedom, originality cannot be found - a principle directly applicable to the functional nature of prompts.

Writing on the Kluwer Copyright Blog, Sampaio addresses whether prompts can be considered "code" protectable under the Software Directive. He notes the critical distinction: "Under copyright for software, compiled code... is protected as a change of format from source code. **This is not the case with prompts. The same prompt to the same model will not deliver the same results.**" Traditional code is deterministic; prompts are not. He further observes that Article 1(2) of the Software Directive excludes ideas and principles underlying interfaces from protection, and concludes that prompts likely fail to qualify as either computer programs or preparatory design work because they are instructions about what to produce rather than code defining how to produce it.

### Potential exceptions for exceptional cases

Notwithstanding the general conclusion that prompts lack copyrightability, two narrow exceptions merit consideration. **First, exceptionally detailed and creative prompts that function as independent literary works might receive protection as such.** Consider a multi-thousand-word prompt that includes elaborate narrative descriptions, original metaphors, poetic language, and sophisticated rhetorical structures that go beyond mere instruction to constitute literary expression in their own right. Such a prompt might be protectable as a literary work separate from any AI output it generates. However, this protection would extend only to the text of the prompt itself as a literary composition, not to any control over AI outputs generated from it or over similar functional prompts. The distinction matters: others could not copy the elaborate textual expression, but they could create functionally equivalent prompts that achieve similar AI outputs without infringing.

**Second, prompts embedded in software as part of larger programs might receive protection as components of the software work.** Where a software application incorporates specific prompts as integral elements of its code - for example, system prompts hardcoded into an AI application that define its behavior - those prompts might be protected as part of the overall software work under the Software Directive. However, again, the protection attaches to the software work as a whole, not to the prompts as independent protectable subject matter.

These exceptions, however, do not disturb the general conclusion that prompts qua prompts - textual instructions provided to AI systems to generate desired outputs - do not meet the EU originality standard for copyright protection. The fundamental obstacles remain insurmountable: prompts are instructions describing ideas about what to create rather than creative expression itself; they are functionally constrained by their communicative purpose; and protecting them would risk monopolizing ideas in violation of core copyright principles.

## Computer programs and databases: specialized copyright regimes

Beyond general copyright protection, EU law provides specialized regimes for computer programs and databases that warrant separate analysis. These regimes employ distinct definitions and requirements that might accommodate prompts even if general copyright protection fails.

### Protection under the Software Directive 2009/24/EC

The Software Directive provides comprehensive protection for computer programs, defining the scope in Article 1(1): "Member States shall protect computer programs, by copyright, as literary works within the meaning of the Berne Convention for the Protection of Literary and Artistic Works. For the purposes of this Directive, **the term 'computer programs' shall include their preparatory design material.**" Critically, Recital 7 elaborates that "the term 'computer program' **shall include programs in any form, including those which are incorporated into hardware. This term also includes preparatory design work leading to the development of a computer program provided that the nature of the preparatory work is such that a computer program can result from it at a later stage.**"

The question becomes whether prompts constitute "computer programs" or "preparatory design material" within these definitions. The CJEU has interpreted the Software Directive's scope through several key decisions that provide guidance.

In *Bezpečnostní softwarová asociace (BSA)* (C-393/09), the Court addressed whether graphical user interfaces qualify as protectable computer programs. The Court held that GUIs are not protected as computer programs because they "do not enable the reproduction of the computer program, but merely constitute one element of that program by way of which users make use of its features." Only the actual source code or object code constituting the program's expression receives protection. This narrow interpretation focuses protection on executable code rather than user-facing elements.

The CJEU further narrowed software protection scope in *SAS Institute v World Programming Ltd* (C-406/10), holding that "the functionality of a computer program, the programming language and the format of data files used in a computer program **do not constitute a form of expression of that program** and, as such, are not protected by copyright in computer programs." The Court emphasized that "to the extent that logic, algorithms and programming languages comprise ideas and principles, those ideas and principles are not protected under this Directive." Only the actual code - the specific source or object code implementation - receives protection.

More recently, in *Sony Computer Entertainment Europe* (C-159/23), the CJEU clarified that even the content of variables stored in RAM during program execution does not constitute an expression of the computer program subject to copyright protection. Modification of data values during program execution does not amount to copyright infringement of the software code.

**Applying this case law to prompts reveals that prompts almost certainly do not qualify as "computer programs."** Prompts are textual instructions provided as input to existing AI programs; they are not themselves source code or object code. They do not define the computational processes executed by the system - the AI model's trained weights and inference algorithms perform the actual computation. Prompts are more analogous to user interface inputs or data provided to programs than to the programs themselves. Under the *BSA* principle, just as GUIs are not protected because they merely enable users to access program features, prompts merely enable users to direct how existing AI programs should be used. They do not "enable the reproduction of the computer program."

Furthermore, under the *SAS* principle, prompts describe functionality - what outputs users want - rather than constituting expression of how the program operates. They are analogous to specifying what function a program should perform, which the CJEU has held does not receive software protection. The natural language formulation of prompts, while directing AI behavior, does not constitute the programming language or algorithmic expression of the AI system itself.

**The preparatory design material category provides a potential alternative argument but ultimately fails.** Recital 7 protects preparatory design work "provided that the nature of the preparatory work is such that a computer program can result from it at a later stage." Academic commentary interprets this as requiring preparatory work to be sufficiently detailed and formalistic that it approaches "quasi-coding" - specifications so precise that a programmer could implement them with minimal additional creative choices. Flow charts, detailed technical specifications, and architecture documents that constrain implementation choices may qualify.

Prompts fail this standard because they do not lead to computer programs resulting from them. A prompt given to an AI system does not generate program code; it generates outputs like text or images. The AI model itself - which already exists as a complete program - processes the prompt, but the prompt does not constitute design work for creating that program. Even if one argues that prompts could inform future AI model development, they lack the technical specificity and formality expected of preparatory design material. Prompts are high-level natural language instructions, not technical specifications that constrain software implementation.

Sampaio's analysis on the Kluwer Copyright Blog emphasizes the determinism distinction: traditional preparatory design material leads deterministically to programs, whereas "the same prompt to the same model will not deliver the same results." This lack of determinism fundamentally distinguishes prompts from preparatory design work, which must be sufficiently specified to enable consistent program implementation.

**The conclusion is clear: prompts do not qualify for protection as computer programs or preparatory design material under the Software Directive.** They are instructions to programs, not programs themselves; they specify desired functionality rather than implementing it; and they lack the technical specificity required for preparatory design work.

### Database protection under Directive 96/9/EC

While individual prompts likely fail software protection, collections of prompts raise distinct questions under the Database Directive 96/9/EC. This Directive establishes two forms of protection: copyright protection for original databases (Article 3) and a sui generis right protecting investment in databases (Article 7). The sui generis right merits particular attention because it protects investment rather than creativity, potentially offering protection where copyright fails.

Article 1(2) defines "database" as "**a collection of independent works, data or other materials arranged in a systematic or methodical way and individually accessible by electronic or other means.**" A collection of prompts clearly satisfies this definition: individual prompts constitute independent textual materials, can be arranged systematically by category or function, and are individually accessible in digital repositories. The definitional threshold presents no obstacle.

The critical question concerns the sui generis right established in Article 7(1): "Member States shall provide for a right for the maker of a database which shows that there has been **qualitatively and/or quantitatively a substantial investment in either the obtaining, verification or presentation of the contents** to prevent extraction and/or re-utilization of the whole or of a substantial part, evaluated qualitatively and/or quantitatively, of the contents of that database." This provision protects database makers who invest substantially in obtaining, verifying, or presenting contents, even when the database lacks originality for copyright purposes.

The CJEU's interpretation of "substantial investment" in the landmark *British Horseracing Board v William Hill* (C-203/02) dramatically narrowed sui generis protection through a critical distinction between investment in creating data versus investment in obtaining existing data. The Court held that "**the resources used to seek out existing independent materials and collect them in the database**" qualifies as protected investment, but "**not the resources used for the creation of materials which make up the contents of a database.**" British Horseracing Board invested £4 million annually in creating horse racing data - determining race dates, creating lists of runners and riders. The Court ruled this was investment in creating data, not obtaining data, and therefore did not qualify for sui generis protection.

The Fixtures Marketing cases (C-46/02, C-338/02, C-444/02) reinforced this distinction. Football leagues invested in creating fixture lists - deciding when matches would occur and which teams would play. The Court held that "resources used for the creation of materials which make up the contents of a database" do not constitute protected investment: "In the context of drawing up a fixture list for the purpose of organising football league fixtures, therefore, **it does not cover the resources used to establish the dates, times and the team pairings for the various matches** in the league." Creating the data falls outside protection; only collecting pre-existing data qualifies.

**This distinction creates a severe problem for prompt collections.** Most prompt engineering involves creating new prompts through iterative testing, trial-and-error refinement, and development of effective formulations. This is investment in creation, not obtaining. Under the *BHB* and *Fixtures* holdings, such creative investment does not qualify for sui generis protection. The labor of developing effective prompts, testing variations, and optimizing formulations - the primary source of value in prompt libraries - constitutes creation of data rather than obtaining existing data.

However, **verification and presentation investments might qualify.** The Database Directive explicitly protects investment in "verification" or "presentation" of contents, not merely obtaining. If a prompt library maker invests substantially in systematically testing prompts across multiple AI systems, quality control verification, effectiveness validation, and reliability assurance, this verification activity could constitute protected investment. In *Football Dataco v Sportradar* (C-173/11), the Court of Appeal held that £600,000 annual investment in collecting live football match data (goals, cards, substitutions) through freelance observers qualified as investment in "obtaining" data because the facts existed independently and the investment was in collecting and verifying these existing facts. Similarly, systematic verification of prompt effectiveness - testing whether prompts produce consistent quality outputs, validating performance metrics, documenting reliability - might qualify as verification investment.

Investment in sophisticated presentation systems could also qualify. If a company develops advanced search and categorization systems, metadata frameworks, recommendation algorithms, or user interfaces requiring substantial technical resources, these presentation investments might receive protection. The key is that the investment must be in presenting existing prompts, not in creating the prompts themselves.

**Quantifying "substantial investment" remains challenging but case law provides guidance.** The £600,000 annual investment in *Football Dataco* was held substantial. Academic commentary suggests "several months of work of a qualified team of researchers" likely suffices. The assessment considers the database maker's size and resources (proportionality), the value of protected information, and industry practices. Documentation of financial expenditure, identifiable human resources (time and personnel), and technical resources deployed strengthens claims of substantiality.

**The practical conclusion for prompt collections is nuanced.** Collections where investment primarily focuses on creating original prompts will not receive sui generis protection under current CJEU interpretation. However, collections where substantial documented investment has been made in systematically collecting prompts created by third parties, in rigorous verification and testing protocols, or in sophisticated presentation systems might qualify. The burden rests on the database maker to prove substantial investment in obtaining, verification, or presentation specifically - not merely in creation.

This creates an unfortunate asymmetry: the most valuable prompt collections, developed through intensive creative engineering and testing to discover effective formulations, receive no sui generis protection because that investment constitutes creation. Less creative collections that aggregate existing prompts from external sources might receive protection. This outcome highlights tensions in the Database Directive's distinction between creation and obtaining that seem ill-suited to knowledge-intensive industries where creation and curation merge.

## Patent protection under the European Patent Convention

Patent protection for prompts raises distinct questions from copyright, focusing on technical character, novelty, and inventive step rather than originality and expression. Analysis requires examination of the European Patent Convention rather than EU directives, as patent law remains governed by the EPC (an international treaty) rather than harmonized EU legislation, though all EU Member States are EPC parties.

### EPC patentability requirements and exclusions

Article 52 EPC establishes the fundamental framework. Article 52(1) provides that "European patents shall be granted for any inventions, in all fields of technology, provided that they are new, involve an inventive step and are susceptible of industrial application." However, Article 52(2) excludes specific categories from patentability, stating that "the following in particular shall not be regarded as inventions" including: "(a) discoveries, scientific theories and mathematical methods; (b) aesthetic creations; (c) schemes, rules and methods for performing mental acts, playing games or doing business, and **programs for computers**; (d) presentations of information."

Critically, Article 52(3) adds: "Paragraph 2 shall exclude the patentability of the subject-matter or activities referred to therein **only to the extent to which a European patent application or European patent relates to such subject-matter or activities as such**." This "as such" qualification has driven EPO practice toward allowing patents for computer-implemented inventions that provide technical effects beyond the excluded subject matter itself.

Prompts face immediate obstacles under Article 52(2). They potentially fall within multiple exclusions: methods for performing mental acts (linguistic formulation of instructions involves mental activity); programs for computers (prompts direct computer operations); presentations of information (prompts structure how information is requested); and arguably mathematical methods (prompts define algorithmic processes through natural language). Each exclusion poses problems for prompt patentability.

### The "technical character" and "further technical effect" requirements

EPO practice has developed a two-stage framework for computer-implemented inventions. At the first stage (patent eligibility), inventions must have "technical character" to qualify as inventions under Article 52(1). At the second stage (inventive step under Article 56), the invention must provide inventive step based on technical contributions to the art.

The landmark EPO Board of Appeal decision in *Computer Program Product/IBM* (T 1173/97) established the "further technical effect" test. The Board held that "a computer program product is not excluded from patentability under Article 52(2) and (3) EPC if, when it is run on a computer, it produces a further technical effect which goes beyond the 'normal' physical interactions between program (software) and computer (hardware)." Mere electrical currents and switching within computer hardware do not suffice; the further technical effect must reside in "further effects deriving from the execution of the instructions." Examples include controlling an anti-lock braking system, controlling processor load balancing, memory allocation improvements, X-ray emission determination, video compression, digital image restoration, and electronic communication encryption.

The Enlarged Board of Appeal in *Programs for Computers* (G 3/08) clarified that technical character requires providing "technical teaching" - instruction on how to solve a technical problem using technical means. The term "technical" remains "not definable" precisely but is understood through case law application. Programming per se may involve technical considerations, but patentability requires "further technical considerations" beyond merely finding an algorithm.

The *Two Identities/COMVIK* decision (T 641/00) established the "COMVIK approach" for assessing inventive step in mixed technical/non-technical inventions. Non-technical features making no contribution to technical character cannot support inventive step. These features are treated as "constraints" or "requirements" in formulating the objective technical problem. Even if non-technical features are novel and inventive in their own domain (e.g., a clever business method), they contribute nothing to patent inventive step.

The Enlarged Board confirmed in *Computer-Implemented Simulations* (G 1/19) that the COMVIK approach applies to all computer-implemented inventions. Importantly, "a computer-implemented simulation of a technical system or process that is claimed as such can, for the purpose of assessing inventive step, solve a technical problem by producing a technical effect going beyond the simulation's implementation on a computer." However, "it is not a sufficient condition that the simulation is based, in whole or in part, on technical principles underlying the simulated system or process."

### EPO Guidelines on AI inventions

The EPO updated its Guidelines in 2024 to address artificial intelligence specifically, treating AI and machine learning as forms of mathematical methods excluded under Article 52(2)(a). The Guidelines establish two "safe harbours" for AI patentability:

**Safe Harbour 1: AI serves a specific technical purpose.** Examples include processing audio, image, or video data; speech recognition; and control systems in technical fields. A claimed example is a neural network controlling fan blade flutter in gas turbine engines. The technical purpose grounds the invention in a technical field rather than abstract mathematics.

**Safe Harbour 2: AI has a specific technical implementation.** This includes new arrangements of computing hardware or effects on internal computer functioning, such as CPU-GPU interaction for machine learning with specific data structures. The implementation must go beyond generic computer use to affect the computing machinery itself.

The 2024 Guidelines also tightened sufficiency of disclosure requirements. Applications must disclose mathematical methods and characteristics of training data affecting technical effects in sufficient detail. Technical effects must be plausible across the entire claimed scope, demonstrated through explanations, mathematical proof, or experimental data. In *Blood Pressure Estimation* (T 0161/18), an application mentioning that training data must cover patients of different ages, sexes, and health conditions but providing no further details was held insufficient - the skilled person could not train the network to achieve the claimed technical effect.

### Application to AI prompts

**Prompts almost certainly cannot be patented under current EPO practice for several fundamental reasons.**

**First, prompts likely constitute excluded subject matter as such.** They are linguistic constructs - text strings communicating intent rather than technical implementations. Prompts fall squarely within "methods for performing mental acts" (linguistic formulation is cognitive activity), "presentations of information" (prompts structure how information is requested), and arguably "computer programs as such" (prompts direct AI operation). The natural language formulation does not disguise their essentially excluded character.

**Second, prompts lack technical character.** The EPO requires "technical teaching" on how to solve a technical problem using technical means. Prompts do not provide such teaching - they specify what outputs are desired, not how to achieve them technically. The prompt doesn't control hardware, doesn't improve computer functioning, and doesn't process technical data in a technical manner. The AI model processes the prompt using its existing trained weights and algorithms, but the model is separate from the prompt. The prompt is input data, not a technical implementation.

**Third, prompts serve cognitive and linguistic purposes, not technical purposes.** Typical prompt purposes include improving AI output quality, relevance, format, or style - these are content quality issues, not technical problems in the EPO sense. A technical problem must relate to a technical field and be solved by technical means producing technical effects. Prompt problems are typically how to get better writing, structure information effectively, reduce ambiguity, or improve comprehension - linguistic and cognitive problems, not technical problems.

**Fourth, under the COMVIK approach, prompt innovations would be treated as non-technical constraints.** Even if one claims a "computer-implemented method using prompts," the novelty and inventiveness resides in the prompt formulation (linguistic/cognitive choices), not in technical implementation. These non-technical features contribute nothing to inventive step. The technical problem becomes "implement this linguistic requirement on a computer," which would be obvious - any competent computer scientist could implement a system that processes the specified prompt. The skilled person (defined as a computer scientist/AI engineer, not a linguist) would find this obvious.

**Fifth, prompts lack the deterministic character typically required.** The same prompt to the same model generates different outputs at different times. This non-determinism contrasts with patentable software inventions where specific code produces predictable technical effects. Patents typically claim predictable, reproducible technical results, which prompts do not provide.

**Potential patentability strategies all face severe obstacles.** One might claim "a method of controlling a technical system using an AI system configured with prompt X," but the prompt itself remains non-technical - merely adding technical context does not render the prompt patentable, just as adding "use a computer" does not make business methods patentable. One might claim "a prompt structured to reduce processing tokens/memory," but this is still linguistic content where reduction is incidental, not a technical implementation solution. The most promising strategy - claiming "an AI system with architecture co-designed to process prompts having structure X" - shifts the invention to the technical architecture rather than the prompt itself, but then the prompt is not the patentable subject matter.

**The legal conclusion is unequivocal: AI prompts, whether claimed alone or as part of computer-implemented methods, do not meet the technical character requirement and would be refused under Article 52 EPC as excluded subject matter, or alternatively would fail inventive step assessment under the COMVIK approach because the innovative prompt features are non-technical.** Patent protection does not offer a viable path for protecting prompt innovations under current EPO practice.

## Trade secrets protection under Directive 2016/943

While copyright and patent protection appear largely unavailable for prompts, trade secrets offer a potentially more accommodating framework. The EU Trade Secrets Directive (EU) 2016/943, implemented across Member States by June 2018, provides harmonized protection based on the TRIPS Agreement Article 39(2).

### The three-part cumulative test

Article 2(1) of the Directive defines "trade secret" as information meeting all three requirements: "(a) it is secret in the sense that it is not, as a body or in the precise configuration and assembly of its components, generally known among or readily accessible to persons within the circles that normally deal with the kind of information in question; (b) it has commercial value because it is secret; (c) it has been subject to reasonable steps under the circumstances, by the person lawfully in control of the information, to keep it secret."

These requirements are cumulative - failure to satisfy any single element defeats protection entirely. Each warrants detailed examination as applied to prompts.

**The secrecy requirement (Article 2(1)(a)).** The test asks whether information is "generally known among or readily accessible to persons within the circles that normally deal with the kind of information in question." This formulation contains several critical specifications. First, "as a body or in the precise configuration and assembly of its components" recognizes that even if individual elements are known, the specific combination might be secret. Second, "generally known" sets a threshold beyond absolute secrecy - some limited disclosure does not destroy protection if information remains generally unknown. Third, "within the circles that normally deal with" defines the relevant community - not the general public, but the specialized industry or professional community.

For prompts, the relevant circles are AI developers, prompt engineers, and businesses using AI commercially. Basic prompt patterns are widely published online - generic instructions, common parameter specifications, and standard formatting conventions are readily accessible. However, sophisticated prompt systems with specific configurations, proprietary combinations of instructions, context frameworks, and optimized formulations might not be generally known within even this specialized community. The determination is inherently fact-specific.

Recital 14 provides important clarification: "The definition of trade secret excludes trivial information and the experience and skills gained by employees in the normal course of their employment." This exclusion directly threatens prompt protection. If prompt engineering skills are considered "experience and skills gained... in the normal course of their employment," individual prompts might be unprotectable as mere applications of that general skill. The distinction between general prompt engineering knowledge (unprotectable experience) and specific prompt formulations (potentially protectable secrets) creates a difficult line-drawing problem.

A critical practical issue concerns whether reverse engineering from outputs destroys secrecy. If effective prompts can be reconstructed by examining AI outputs they produce, the prompts may be "readily accessible" even if not directly disclosed. Modern AI systems can potentially analyze outputs and generate similar prompts achieving comparable results. This reconstruction capability suggests that prompts producing distinctive, visible outputs may fail the secrecy requirement once those outputs are observed.

**Commercial value derived from secrecy (Article 2(1)(b)).** This requirement contains a critical causation element emphasized by the Directive's precise language: information must "have commercial value **because it is secret**." Recital 14 elaborates that information "should have a commercial value, whether actual or potential" and "should be considered to have a commercial value, for example, where its unlawful acquisition, use or disclosure is likely to harm the interests of the person lawfully controlling it."

For prompts, establishing that value derives from secrecy rather than other sources presents challenges. A prompt has value because it produces superior AI outputs, enables cost savings, or provides competitive advantage - but does this value derive from the prompt being secret, or from the prompt being effective? If a competitor could use the same prompt and achieve the same benefits, the value does derive from secrecy (keeping it from competitors maintains advantage). However, if the value comes primarily from the underlying AI model (available to competitors) or from general prompt engineering knowledge (accessible to competitors independently), the causation requirement may fail.

Academic commentary emphasizes this point. As noted in the IIC Journal analysis, "commercial value needs to be derived from the parts of the AI system that satisfy the other two trade secret requirements as well. Article 2(1)(b) of the TSD explicitly stipulates that information must 'have commercial value because it is secret' (emphasis added)... In essence, it is not just the general commercial value of the AI system overall that is decisive here." The value must derive specifically from the secretive prompt, not merely from the AI system generally or from visible outputs.

The ongoing U.S. litigation in *OpenEvidence, Inc. v. Pathway Medical, Inc.* (D. Mass.) illustrates these issues. A healthcare AI startup alleged that a competitor extracted "system prompt data" and "model architecture," claiming trade secret misappropriation. While the outcome remains pending, the case demonstrates that prompts are being asserted as trade secrets in commercial disputes.

**Reasonable steps to maintain secrecy (Article 2(1)(c)).** The Directive requires that information "has been subject to reasonable steps under the circumstances, by the person lawfully in control of the information, to keep it secret." The formulation "reasonable steps under the circumstances" establishes a proportionality test - the required measures depend on the enterprise's size and resources, the secret's value, information's nature, and industry practices. The Directive deliberately avoids defining "reasonable steps" precisely, leaving courts to assess adequacy contextually.

German implementation guidance suggests relevant factors include the infrastructure and size of the enterprise, commercial possibilities connected with the protected secret, and technical accessibility of information. The proportionality principle means small and medium enterprises need not implement the same expensive security measures as large corporations, but the measures must be reasonable given the circumstances.

For prompts, recommended protective measures include: (1) technical access controls (password protection for prompt repositories, restricted access limited to employees with legitimate need, audit logging); (2) contractual measures (non-disclosure agreements with employees and contractors, confidentiality clauses in employment agreements, licenses prohibiting reverse engineering and data scraping); (3) marking and classification (labeling prompts as "Confidential" or "Trade Secret," implementing confidentiality policies, employee training); (4) technical safeguards (segregating prompts from general systems, using enterprise AI tools with data isolation, monitoring for unauthorized access); and (5) documentation (recording R&D investment, documenting development processes, maintaining evidence of protective measures).

The critical challenge for prompts is that unlike source code (which can remain entirely internal), prompts are often entered into third-party AI systems - ChatGPT, Claude, or other external platforms. Using commercial AI services for trade secret prompts risks destroying secrecy unless enterprise deployments with contractual confidentiality protections are employed. Entering proprietary prompts into public AI systems almost certainly fails the "reasonable steps" requirement because control over the information is lost once submitted to external services that may store, analyze, or use prompts for training.

### Practical challenges in maintaining trade secret protection

Beyond satisfying the three-part test, prompts face two severe practical challenges in maintaining trade secret protection during commercial use.

**The disclosure-through-use problem.** Trade secrets require secrecy, but commercial value from AI prompts typically comes from using them to generate outputs - which are often visible. This creates a fundamental tension. Article 3(1)(b) of the Directive explicitly permits lawful acquisition through "observation, study, disassembly or testing of a product or object that has been made available to the public," and Recitals 16-17 protect reverse engineering rights. If AI outputs reveal prompt structures or content, competitors may lawfully reconstruct similar prompts by reverse engineering.

The analogy to software illustrates both possibilities and limitations. Compiled software code (secret) produces visible outputs, and algorithms (secret) produce detectable results. These can be trade secrets if internal workings remain non-obvious from outputs. Similarly, if prompts remain opaque despite visible outputs, secrecy might be maintained. However, if the prompt can be inferred or reconstructed from outputs - particularly given modern AI systems' capability to analyze outputs and generate effective prompts - secrecy is lost.

The feasibility of maintaining secrecy while using prompts commercially depends on use context. Internal use only (prompts used within an organization without external output sharing) provides strongest protection. Business-to-business use with NDAs (prompts shared with specific partners under confidentiality agreements) maintains legal protection under Article 3(2). Black-box commercial services (prompts used to generate services/products where customers see outputs but not prompts) can maintain protection if prompts are not readily reconstructible from outputs. However, public AI platform use (entering trade secret prompts into ChatGPT or similar services) or easily reconstructible prompts (where output quality can be replicated with common prompt patterns) defeat protection.

**The employee mobility tension.** Article 1(3) and Recital 13 of the Directive emphasize that trade secrets protection "should not be understood to offer any ground for restricting the mobility of employees." Employees retain "experience and skills honestly acquired." This creates a critical distinction problem: when do prompts constitute protectable trade secrets versus general prompt engineering skills that employees may take to new employers? An employee who develops prompt engineering expertise while working for Company A cannot be prevented from using that general skill at Company B. But can Company A prevent the employee from using specific prompt formulations developed at Company A? The boundary is unclear and fact-intensive.

### CJEU and national court interpretation

CJEU case law specifically on the Trade Secrets Directive remains limited given the Directive's recent adoption. However, *CK v Dun & Bradstreet* (C-203/22) addressed the balance between GDPR access rights and trade secret protection. The CJEU ruled that when trade secret protection is asserted, controllers must provide allegedly protected information to supervisory authorities or courts for balancing assessment. The decision demonstrates that trade secret protection is not absolute and must be balanced against other rights through proportionality analysis. Trade secret status must be proven, not merely asserted.

National implementations reveal varying approaches. Germany's *Geschäftsgeheimnisgesetz* (2019) took a minimum harmonization approach without exceeding Directive requirements, emphasizing proportionality factors including enterprise size, commercial value of secrets, and technical accessibility. France's *Loi sur le secret des affaires* (Act 2018-670) implemented the three-part test while introducing abuse-of-process protections to prevent misuse of trade secret law to stifle competition (fines up to 20% of damages sought or €60,000 for bad faith claims). The Netherlands implemented through its *Wet bescherming bedrijfsgeheimen* by July 2018, introducing statutory trade secret definitions for the first time and adopting "confidentiality club" procedures for protecting secrets during litigation.

### Conclusion on trade secrets protection

**AI prompts can potentially receive trade secret protection under Directive 2016/943 if all three cumulative requirements are satisfied.** Sophisticated, non-obvious prompt systems with specific configurations may satisfy the secrecy requirement. Commercial value derived from secretive competitive advantages may satisfy the value requirement. Comprehensive technical, contractual, and organizational safeguards may satisfy the reasonable steps requirement.

However, **protection is feasible but fragile.** Simple, trivial prompts clearly fail protection. Prompts readily reconstructible from outputs likely fail secrecy. Prompts entered into public AI systems without protection likely fail reasonable steps. Employee knowledge versus trade secret distinctions create enforcement challenges. Reverse engineering from outputs by sophisticated users may defeat protection. The balancing against transparency requirements (under the AI Act and GDPR) may limit protection scope.

Trade secrets represent the most practically viable IP protection mechanism for prompts currently, but only for genuinely sophisticated prompt systems maintained under rigorous secrecy protocols. The legal framework accommodates protection in principle but imposes demanding requirements that many prompt-based business models will struggle to satisfy in practice.

## Comparative framework analysis and the path forward

Having examined four potential IP frameworks - copyright, software/database protection, patents, and trade secrets - it is now possible to assess comparatively which approach offers the most appropriate protection for prompts, what tradeoffs each entails, and whether reform is needed.

### Comparative assessment of protection frameworks

**Copyright protection** offers strong rights (70 years post-author, exclusive reproduction and adaptation rights, cross-border harmonization) but imposes the fundamental requirement that works be "author's own intellectual creation" reflecting personality through free and creative choices. As demonstrated, prompts face insurmountable obstacles: they are instructions about what to create (ideas) rather than creative expression itself; they are functionally constrained by their communicative purpose; and protection would risk monopolizing ideas in violation of core principles. Copyright applies only in exceptional cases where prompts function as independent literary works, and even then, protection extends only to the textual expression, not to functional equivalents or AI outputs. The copyright framework's fixation on expression versus ideas makes it fundamentally unsuited to protecting instrumental instructions like prompts.

**Software protection** under the specialized regime similarly fails because prompts are not source code, object code, or preparatory design material from which programs result. The CJEU's narrow interpretation limiting protection to executable code expressions excludes user inputs and instructions. Database sui generis protection offers more promise for prompt collections but perversely protects investment in obtaining or verifying existing data while excluding investment in creating data - meaning the most valuable prompt collections developed through creative engineering receive no protection while compilations of others' prompts might. This creates misaligned incentives that fail to reward innovation.

**Patent protection** is categorically unavailable because prompts lack technical character, solve linguistic rather than technical problems, and constitute excluded subject matter (methods for performing mental acts, presentations of information). Under the COMVIK approach, prompt innovations are non-technical features contributing nothing to inventive step. The EPO's rigorous technical effect requirement, appropriate for its purposes, means patents cannot accommodate linguistic or cognitive innovations like prompts regardless of their commercial value.

**Trade secrets protection** is the only framework offering genuinely viable protection, but it is narrow, conditional, and fragile. Protection requires satisfaction of all three cumulative requirements (secrecy, value from secrecy, reasonable steps), each posing challenges. Secrecy must be maintained while using prompts commercially - feasible for internal use or B2B contexts with NDAs but difficult for consumer-facing services. The requirement that value derive from secrecy rather than from the AI model or general knowledge creates causation proof challenges. Reasonable steps requirements demand comprehensive security measures. Most critically, trade secret protection offers no rights against independent development or reverse engineering - competitors who reconstruct effective prompts through their own efforts or by analyzing outputs commit no violation. Protection lasts only while secrecy is maintained, and disclosure (intentional or inadvertent) destroys rights permanently with no residual protection.

### Tradeoffs and implications

Each framework embodies different policy balances between incentivizing creation and ensuring access. **Copyright's requirement of originality and creative expression** serves the policy goal of rewarding human creativity while preserving the public domain of ideas, facts, and functional information. Its inapplicability to prompts reflects that prompts are closer to functional instructions (like product specifications or search queries) than to creative works warranting exclusive rights. Extending copyright to prompts would expand IP protection beyond its traditional boundaries into the realm of utilitarian instruction-giving.

**Patent law's requirement of technical character** reflects the judgment that innovation in non-technical fields - business methods, mental processes, linguistic formulations - should remain freely available for competition. The EPO's insistence on "further technical effect" prevents monopolization of abstract ideas and methods regardless of their novelty or commercial value. This boundary excludes prompts not because they lack value but because patent law deliberately limits its scope to technical innovation. Extending patents to prompts would fundamentally alter the technical character requirement that has defined European patent law.

**Trade secret law's conditional protection** based on secrecy rather than disclosure reflects an opposite policy: information kept secret can be protected, but only as long as secrecy is maintained and only against wrongful acquisition. This allows protection for commercially valuable information (recipes, customer lists, technical know-how) while preserving rights to independent development and reverse engineering. For prompts, this framework is more naturally suited than copyright or patents because it protects valuable information without creating exclusive rights that block others from reaching the same information independently.

**Database sui generis protection** reflects a specific policy choice to protect investment in information aggregation separate from creativity. However, the CJEU's interpretation limiting protection to investment in obtaining (not creating) data creates the perverse outcome that creative prompt development is unprotected while mere aggregation is protected. This interpretive choice, arguably inconsistent with the Directive's recitals emphasizing protection of investment in "obtaining, verification or presentation," has been criticized by scholars but remains binding.

### The question of reform: is new legislation needed?

The analysis reveals a fundamental mismatch between existing IP categories and the characteristics of prompts. **Prompts occupy an uncomfortable middle ground**: more than mere ideas (requiring skill and investment), but less than creative expression (being functional instructions); commercially valuable (demonstrated by active marketplaces), but not traditionally protectable (falling outside existing categories); independently discoverable (multiple prompters can reach similar solutions), but requiring investment to develop (time, testing, expertise).

**Arguments supporting reform** and potential creation of sui generis protection include: (1) market failure - without protection, the appropriability problem discourages investment in prompt development once disclosure occurs; (2) innovation incentives - protecting prompts could encourage development of more sophisticated human-AI interaction methods; (3) international competitiveness - if other jurisdictions protect prompts more robustly, EU businesses may face disadvantages; (4) recognition of investment - prompt engineering requires genuine skill development and R&D deserving reward; (5) existing inadequacy - trade secrets offer only limited protection unsuited to many commercial models.

**Arguments against reform** and for maintaining current law include: (1) risk of monopolization - protecting prompts could restrict access to AI technology by monopolizing communication methods; (2) cumulative innovation - prompt engineering builds incrementally on others' work, and property rights could block this cumulative process; (3) trade secret sufficiency - businesses can protect genuinely valuable prompts through secrecy and contractual measures; (4) difficulty defining scope - where would protection begin and end given the spectrum from simple to complex prompts; (5) alternatives available - first-mover advantages, brand reputation, service quality, and contract law provide protection mechanisms; (6) idea-expression conflation - protecting prompts risks collapsing the idea-expression distinction central to IP law; (7) international fragmentation - EU-specific protection could create conflicts with trading partners.

The scholarly commentary generally counsels against hasty legislative intervention. Professors Quintais and Hugenholtz argue that existing EU copyright rules are "generally suitable and sufficiently flexible to deal with the challenges posed by AI-assisted output" when properly applied. The European Copyright Society has emphasized the need to "balance the interests of human authors and performers; the interests of users and of the wider public... [and] the enhancement of research and innovation." The European Parliament's 2020 Resolution emphasized providing "balanced and innovation-driven protection of intellectual property... to strengthen the international competitiveness of European companies, including against possible abusive litigation tactics."

**The AI Act's approach suggests regulatory restraint.** The Act addresses AI systems comprehensively but does not create new IP rights for prompts or AI outputs. Instead, Recital 106 requires that "providers of general purpose AI models should put in place a policy to comply with Union law on copyright and related rights, in particular to identify and comply with the reservation of rights expressed by rightsholders." This approach relies on existing copyright frameworks rather than inventing new categories. The emphasis on transparency (documenting training data, respecting opt-outs) addresses AI development broadly while leaving specific IP questions to existing frameworks and courts.

### Recommended approach

**In the near term, the appropriate approach is restraint pending judicial clarification and market evolution.** Several considerations support this recommendation:

**First, judicial interpretation of existing frameworks remains incomplete.** The CJEU has not yet addressed whether sophisticated prompts can satisfy the originality threshold, whether prompt collections qualify for database protection under verification investment, or how trade secret protection balances against AI Act transparency requirements. National courts are beginning to see cases involving prompt protection claims. Allowing case law to develop will clarify where existing doctrine settles before legislating.

**Second, the prompt engineering field is rapidly evolving.** Business models, technical practices, and economic dynamics are changing quickly. Legislative intervention now might entrench approaches that become obsolete or might fail to anticipate new developments. Regulatory humility counsels waiting until patterns stabilize.

**Third, alternative protection mechanisms exist.** Businesses can combine multiple strategies: (1) trade secrets for genuinely confidential prompts; (2) contracts imposing confidentiality and use restrictions; (3) technological protection measures restricting access; (4) first-mover advantages and brand reputation; (5) integration of prompts into larger protectable systems (software, databases). These combined approaches may provide adequate protection for most commercial models.

**Fourth, international coordination is essential.** IP protection is increasingly global. The U.S. Copyright Office has taken positions on AI-related issues. China's courts have issued decisions. WIPO has conducted extensive consultations. Unilateral EU action creating prompt-specific protection could create conflicts and fragmentation. Any reform should emerge from international dialogue.

**If reform ultimately proves necessary**, the most appropriate model would be a **limited sui generis right resembling database protection but focused on verification rather than creation**. Such a right might protect documented investment in: (1) systematic testing and verification of prompt effectiveness across multiple AI systems; (2) quality assurance and reliability validation; (3) performance metric documentation; (4) sophisticated presentation and access systems. Protection would extend only to preventing extraction and reutilization of substantial portions of prompt collections, not to preventing independent creation or use of individual prompts. The term should be short (perhaps 5-10 years rather than copyright's 70 years) to balance incentives against access. Most importantly, any protection must preserve rights to independent development, reverse engineering of publicly available outputs, and employee mobility with general skills.

## Conclusion

The question of whether EU law protects AI prompts reveals fundamental tensions between traditional intellectual property categories and novel forms of commercially valuable information emerging from human-AI interaction. The comprehensive legal analysis demonstrates that **prompts receive minimal protection under current EU law**. Copyright protection is unavailable because prompts constitute instructions about what to create (ideas) rather than creative expression, fail to reflect personality through free and creative choices in most cases, and are functionally constrained by their communicative purpose. Software protection fails because prompts are not source code, object code, or preparatory design material from which programs result. Database protection might apply to collections if substantial documented investment in verification or presentation (not creation) is proven, but the CJEU's narrow interpretation excludes most valuable prompt development investment. Patents are categorically unavailable because prompts lack technical character and constitute excluded subject matter.

**Trade secrets protection offers the only genuinely viable framework**, but protection is conditional and fragile. Sophisticated prompt systems maintained under rigorous secrecy with comprehensive protective measures might qualify, but simple prompts, prompts entered into public AI systems, and prompts readily reconstructible from outputs fail protection. The requirement that value derive from secrecy rather than from the underlying AI model creates proof challenges. Most critically, trade secret protection offers no rights against independent development or reverse engineering - competitors who reconstruct prompts through their own efforts commit no violation.

**Whether reform is needed remains uncertain and should await further developments.** The current legal regime reflects deliberate policy choices: copyright's fixation on creative expression versus functional instruction; patent law's limitation to technical innovation; trade secret law's conditioning protection on secrecy maintenance. These boundaries exclude prompts not because they lack value but because existing IP categories embody normative judgments about what types of information warrant exclusive rights.

The emergence of prompt engineering highlights a broader question: as AI systems become ubiquitous and human-AI interaction grows more sophisticated, do traditional IP categories adequately address new forms of valuable information? Prompts exemplify information that requires skill and investment to create, provides commercial advantage, but fits uncomfortably within existing frameworks. The challenge for EU IP law is balancing incentives for prompt development against the imperative to preserve access to AI technology, avoid monopolization of communication methods, and maintain the public domain of ideas and functional information.

For the present, businesses developing valuable prompts should rely on trade secret protection combined with contractual restrictions, using enterprise AI deployments with confidentiality protections rather than public AI services, implementing comprehensive security measures, and documenting investment in verification and testing. Courts should apply existing originality and technical character requirements rigorously rather than diluting standards to accommodate new subject matter. The European Commission should monitor developments but avoid hasty legislative intervention that might create unintended consequences or international conflicts. If reform ultimately proves necessary, it should take the form of a limited sui generis right focused on protecting documented verification investment rather than creative expression, with short protection terms and broad exceptions preserving independent development and employee mobility rights.

The fundamental lesson is that not all valuable information requires or should receive IP protection. Some information - including functional instructions, methods of communication, and practical know-how - may appropriately remain outside property rights regimes, accessible through learning, independent development, and market competition. Prompts may fall within this category. The current legal framework's restrictive approach to prompt protection reflects this judgment and should not be abandoned without compelling evidence that market failure requires intervention.