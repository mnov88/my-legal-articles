
# **H1: The Psychological Architecture and Economic Manifestation of Data Lock-In**

## **Introduction: Deconstructing the "Fear of Loss"**

The first hypothesis (H1) posits that user retention is, in part, a function of a "fear of losing their content," including profiles, personalization, and other user-generated data, across both free and paid services. This analysis will deconstruct this "fear" by examining its precise psychological underpinnings, moving from classical economic theory to the specificities of digital service interaction. It will be demonstrated that the "content" users fear losing is not an abstract collection of data, but a high-value, non-fungible digital asset that functions as an extension of their "self-concept".1 This psychological attachment is then translated into its economic manifestation: a potent, empirically-verified "switching barrier" or "data lock-in" that drives user inertia and retention.

## **The Architecture of the Digital Self: Psychological Ownership and Personalization**

The foundation of the "fear of loss" is not inherent to the digital data itself, but is constructed through user interaction, labor, and personalization. This process creates a profound sense of psychological ownership.

### **The Baseline Endowment Effect and the Digital Goods Paradox**

Classical economic and psychological theory identifies the "endowment effect," a robust phenomenon whereby individuals attach greater value to goods they already own than the value they would place on the same goods if they did not own them.1 Neuroscientific investigations confirm this effect is not merely cognitive, but is grounded in the brain's pleasure and pain networks; purchase intent, for instance, is predictable by examining differential neural activity in the nucleus accumbens (pleasure) and the insular cortex (pain).1 Ownership is not trivial; it fulfills a deep human need for autonomy and serves as a signal of social values and self-concept.1 This identification of the self with objects is defined as "psychological ownership," a significant emotional attachment between the consumer and the product.1  
This classical theory, however, is complicated by research on digital goods. Multiple studies indicate that consumers exhibit a marked preference for physical goods, valuing generic digital goods (such as an e-book or digital textbook) *less* than their physical analogs.1 Consumers are willing to pay less for digital goods and, unlike with utilitarian physical goods, are often not willing to pay more to "purchase" (own) a digital good than to "rent" it.1 This presents a "Digital Goods Paradox": if digital goods are inherently valued less due to their intangibility, why would the *fear of losing them* (H1) be a powerful retention tool?

### **Resolution of the Paradox: Personalization as Value Creation**

The resolution of this paradox lies in the critical distinction between generic, non-personalized digital goods and *personalized digital services*. While the intangibility of a generic e-book may *reduce* psychological ownership, the mechanisms of control and customization in a digital *service* can create a level of psychological ownership that is *greater* than that experienced for comparable physical goods.3  
Digital services, particularly hedonic or experiential platforms like streaming services, enhance user control through personalization, whether manual or algorithmic.3 This "control of the clicks" and the on-demand nature of consumption—where the user dictates the "where, when, and how"—directly and positively impact user attitudes, leading to higher service satisfaction and loyalty.4 The *labor* of personalization—curating playlists, building profiles, uploading photos, customizing settings—transforms the generic, zero-marginal-cost service 5 into a unique, non-fungible asset. This process is a "transference" of positive attributes, forging a deep "self-brand bond".1  
This effect is not theoretical. Empirical research on e-learning platforms demonstrates that psychological ownership has a "greater linear and non-linear effect on engagement" than other factors.6 In the context of digital music, fostering psychological ownership and tailored experiences is a recommended strategy to convert users from freemium to premium subscriptions.7 The "content" that H1 describes—profiles, personalization, user-generated content (UGC)—is therefore a *co-creation* between the user and the platform. It is an investment of the user's self.  
The "fear of loss" is thus not the fear of losing a *file*, which could be downloaded or backed up. It is the fear of losing a *functional, non-fungible digital prosthesis*. The user's intangible labor of personalization is an economic input that converts a generic service into a high-value personal asset. The resulting "profile" is not just data; it is an extension of the self 1, and the "fear" is one of identity loss and the destruction of this user-created capital. This clarifies why the fear is so potent and a strong driver of retention, confirming H1's core mechanism.

## **From Psychological Attachment to Economic Inertia: Data as a Switching Barrier**

This profound psychological attachment directly translates into the behavioral-economic concept of "data lock-in," a primary form of switching barrier that creates economic inertia.

### **The Economic Model: Data Lock-In and Switching Costs**

The psychological "endowment" 1 and the curation of a service 5 are the micro-foundations of the "fear of loss," which, at the macro-level, manifests as a "switching cost".8 This "data lock-in" is a well-documented source of market power 9 that can stifle innovation, prevent entry from new competitors, and reduce consumer choice.9 When consumers are subject to behavioral biases, they become vulnerable to a platform's exploitative behavior, which uses this market power to extract profit.11

### **Empirical Verification of "Fear of Data Loss"**

The hypothesis that this fear drives retention is not speculative; it is an empirically-verified phenomenon. "Fear of data loss" is cited *explicitly* in multiple studies across different service sectors as a primary switching barrier:

* **Telecommunications:** In the context of mobile service providers, users demonstrate a significant "reluctance to change".12 Even when a technical solution exists, such as mobile number portability (MNP), it remains underutilized due to factors *explicitly* including "fear of data loss" and "inconvenience".12  
* **Health Technology:** In the adoption of mobile health applications, "fear of data loss or erroneous data input" is identified as a significant barrier to user retention and acceptance, particularly among target groups like older users.13  
* **E-Commerce:** In developing economies, "Fear of data loss/Risk of security breaches" was identified as one of the "most prominent psychological barriers" for e-shopping adoption.15

Furthermore, the "content" in H1 often refers to User-Generated Content (UGC). Research on switching barriers confirms that user contributions 16 are a primary source of "constraint-based switching barriers".16 The *relationship quality* built within a platform's community—the "self-brand bonds" 1—is another dedication-based barrier, all of which would be destroyed upon switching.16

### **Application to "Free" and "Paid" Service Models**

H1 correctly posits that this mechanism applies to both free and paid services, though the strategic corporate motive for its use diverges.

* **Paid/Subscription Models:** The link is direct. In subscription models, once a consumer has access to and is receiving "curated products," they "are less likely to want to give those up".5 The endowment effect 5 and psychological ownership 7 are used to foster loyalty, secure future subscription revenue, and "encourage a shift from freemium to premium".7  
* **Freemium/Zero-Price Models:** The dynamic is even more critical in "zero-price markets".19 In a free model, the user's data and attention are the product being sold to advertisers.11 Here, data lock-in 9 is not merely a *retention* tool; it is the core mechanism of *value extraction*.

The psychological *mechanism* of H1—the endowment effect fostering psychological ownership via personalization—is identical in both free and paid services. However, the *strategic motive* for its exploitation differs. In a paid service, lock-in secures future revenue from the *user*. In a free service, the "fear of loss" acts as an invisible fence, preventing the *product* (the user) from leaving the *factory*. This "data lock-in" ensures a stable, extractable user base 11, which is the asset a platform leverages. This exploitation of the H1-identified fear is the subject of the following report.

# **H2: Corporate Exploitation and the "Inactivity Wall" as a Coercive Dark Pattern**

## **Introduction: Defining the Exploitative Hypothesis**

The second hypothesis (H2) posits that *Companies actively exploit this, using data deletion threats as a dark pattern*. This report will analyze this hypothesis by using the "inactive account deletion" policies of major technology platforms as a central case study. This analysis will first deconstruct the public-facing "security" rationale for these policies. It will then demonstrate that this rationale, while technically valid, is often a pretext for a *disproportionate remedy* (total data deletion). This remedy is not a simple security measure but a strategic, coercive "dark pattern" designed to weaponize the "fear of loss" (established in H1) to force user re-engagement.

## **Deconstructing the Public Rationale: Inactive Account Policies**

Major digital platforms, which rely on user-generated content and personalization (the H1 assets), have instituted policies that threaten the deletion of these assets upon periods of user inactivity.

### **The Policies and Their Stated Justification**

A review of platform terms reveals a common "delete-on-inactivity" policy:

* **Google:** As of December 2023, Google began implementing a policy to delete personal accounts that have been inactive for at least two years. This deletion is total, removing all associated content, including emails, documents, and photos.20  
* **Microsoft:** The Microsoft Account Activity Policy similarly states that accounts not accessed in the last two years will be automatically deleted, with no mechanism for recovery.22  
* **X (formerly Twitter):** The platform, as X, announced it would purge accounts that have had no activity for "several years".20

The dominant public rationale for these policies is **cybersecurity**. Google, for example, states that security is "at the heart" of its policy.20 The argument, which is valid, is that inactive accounts pose a significant security risk.20 These accounts are "at least 10 times less likely to have 2-step verification" set up, often rely on old or compromised passwords, and receive fewer user security checks.20 They are, therefore, vulnerable to being compromised for identity theft, spam, or phishing scams.20

### **The Disconnect: User Impact and Disproportionate Remedy**

These deletion announcements trigger the exact psychological vulnerability identified in H1. The X/Twitter announcement "sparked discussion about our ownership of our 'digital lives'".20 It caused significant user concern, particularly over the loss of accounts belonging to deceased loved ones—a clear manifestation of the deep, emotional, "self-concept" value 1 invested in these profiles.20  
This emotional impact reveals the central argument of H2: the "security" rationale, while plausible, serves as a pretext for a disproportionate and strategically-chosen *remedy*. The *problem* stated by platforms is *account vulnerability*.20 However, the *remedy* chosen is not a proportionate security fix (e.g., forcing a password reset on next login, mandating 2-step verification, or *freezing* the account's public-facing status while preserving the user's data). Instead, the chosen remedy is the most extreme one: *total, irreversible data deletion*.21  
This disproportionality reveals the policy's true, unstated objective. Total deletion is the only remedy that simultaneously (a) "solves" the security issue and (b) leverages the "fear of loss" (H1) to *coerce user re-engagement*. The *threat* of deletion, communicated via periodic warning emails 21, is the *actual* tool. The platform's goal is not, in fact, to delete the account—which represents a lost user—but to *prevent* the deletion by forcing the user to log in. This *coerced login* provides the platform with a fresh "active user" data point, revitalizing a "stale" asset. The policy is therefore not a security policy; it is a *retention policy* disguised as a security measure, confirming the "active exploitation" posited by H2.

## **Weaponizing the Default: Data Deletion as a Coercive Dark Pattern**

This coercive retention strategy is a form of "deceptive design," or "dark pattern," specifically engineered to exploit consumer behavioral biases.

### **Defining "Dark Patterns" in the EU Context**

Regulators, particularly the European Data Protection Board (EDPB), have defined "deceptive design patterns" as interfaces that "influence users into making unintended, unwilling, and potentially harmful decisions".25 These patterns are *exploitative* 11 and aim to "hinder the users' ability to effectively protect their personal data and make conscious choices".25 A key example provided by regulators is when "rejecting" a choice (like cookies) is made "harder than accepting them".26 Such a design undermines the principle of "freely given consent" 26 by creating a scenario where the user is nudged or forced into a decision that is "against the users’ best interests" 25 but extracts profit for the platform.11

### **The "Inactivity Wall": A Novel Coercive Pattern**

The "inactive account deletion threat" is a novel, and arguably more coercive, form of dark pattern that can be termed an **"Inactivity Wall."** Its function is analogous to the "Cookie Wall" identified by the EDPB.27

* A **"Cookie Wall"** denies the user *access* to a website or service unless they "consent" to tracking.27 This is not a "freely given" choice.  
* An **"Inactivity Wall"** denies the user *continued existence* of their *personal assets* (the H1 "digital self") unless they "consent" to *re-engagement* (an equally un-free choice).

The "Inactivity Wall" fits the EDPB definition of a dark pattern perfectly. It presents the user with a coerced, "unwilling" choice: (A) Suffer the significant, painful, and emotional loss 1 of their "digital self," or (B) Take an action they had *not* chosen to take (hence the "inactivity")—logging back into the service.  
This pattern is arguably *more* coercive than a standard cookie wall. A cookie wall typically blocks access to generic content. The inactivity wall *threatens to destroy* the user's unique, non-fungible, psychologically-owned asset.1 This is a direct form of "Emotional Steering," a category of dark pattern identified by the EDPB 25, which "appealing to their emotions" to affect their choice.  
This coerced re-engagement (the login) is the "profit" 11 the platform seeks, particularly in the "zero-price" model.19 It is a data point that proves the user is "active," which inflates the platform's user metrics (e.g., Monthly Active Users), which in turn is the currency used to support advertising revenue. Therefore, the threat of data deletion is not a peripheral administrative policy; it is a deliberate, exploitative, and active "dark pattern," as H2 contends.

# **H3: The GDPR's Doctrinal Gap and the Interoperability Solution**

## **Introduction: The Legal Hypothesis of the Regulatory Gap**

The third hypothesis (H3) states that this coercive practice *is not per se illegal under the GDPR (there is no obligation to process someone’s data)*. This report will first confirm the literal correctness of this legal premise, demonstrating how the GDPR's own principles can be (mis)used to justify deletion. It will then identify the precise nature of the regulatory failure: the *act* of deletion is legal, but the *threat* of deletion constitutes "unfair" processing. This analysis will then pivot to the GDPR's *intended* solution for data lock-in—the Right to Data Portability (Article 20)—and demonstrate its structural and doctrinal failure. Finally, it will posit that this gap is only now being addressed, not by the GDPR, but by the EU's new *ex-ante* competition-focused regulations: the Digital Markets Act (DMA) and the EU Data Act.

## **The Legality of Deletion: Reconciling Storage Limitation and User Control**

H3 is, in a narrow and literal sense, legally correct. The General Data Protection Regulation (GDPR) contains no general "obligation to continue processing" a user's data against a controller's will.28 Such an obligation only arises in specific, narrow circumstances, such as a "legal obligation to continue processing" data in a certain way.29  
In fact, the GDPR's "storage limitation" principle (Art. 5(1)(e)) mandates the opposite: data must be "kept in a form which permits identification of data subjects for no longer than is necessary." A company's legal filings may even note that the GDPR *requires* them "to delete data when we no longer have an overriding business need to retain such data".31 From a controller's perspective, an "inactive" account, for which the user is no longer providing engagement (the "business need" in a "free" model), is a prime candidate for deletion *under the GDPR's own logic*. Therefore, the *act* of deletion is not *per se* illegal, confirming H3's premise.  
This, however, reveals the subtle nature of the regulatory gap. The legal problem is *not* the *act* of deletion. The legal violation is the *coercive threat* of deletion, which constitutes *unfair processing* under GDPR Article 5(1)(a). This Article states that all processing must be "lawful, *fair* and transparent."  
As established in H2, the "Inactivity Wall" is a "dark pattern" 25 that "exploits" 11 a known psychological vulnerability (the H1 "fear of loss") to "coerce" an "unwilling" action (the H2 "re-engagement"). This practice is definitionally *unfair*. The regulatory gap is that this "fairness" principle is abstract and has not been specifically applied by regulators to this "Inactivity Wall" pattern. This allows companies to *claim* compliance (by focusing on the legality of the *deletion act*) while engaging in *unfair processing* (the *coercive threat*).

## **The Failure of Portability: The "Paradox" of GDPR Article 20**

This regulatory gap is compounded by the fact that the GDPR's primary intended solution for data lock-in—the Right to Data Portability (Art. 20)—is structurally and doctrinally incapable of solving the problem.

### **The Intended Goal and Procedural Loopholes of Article 20**

Article 20 was designed to be the antidote to the H1 problem. Its explicit goal was to "facilitate switching" 8, "avoid consumer lock-in" 32, and "lower switching costs".34 It provides a right for the data subject "to receive the personal data concerning him or her, which he or she has provided to a controller, in a structured, commonly used and machine-readable format" and to "transmit those data to another controller".34  
However, the right is procedurally weak. First, it is gutted by the "technical feasibility" loophole. Article 20(2) only requires a direct controller-to-controller transfer "where technically feasible".36 As critics have noted, this allows controllers to simply "contend that such a transfer is technically infeasible".32 Recital 68 of the GDPR reinforces this loophole, clarifying that Article 20 *does not* impose an "obligation for the controllers to adopt or maintain processing systems which are technically compatible".36

### **The Doctrinal Failure: The "Paradox of Data Portability"**

The more fundamental flaw in Article 20 is not procedural but doctrinal. The right is a victim of the "paradox of data portability".33 This paradox states that the data users are *most likely* to port (and which Art. 20 covers) are the *least essential* to digital market competition, while the data most essential to competition are those users are *least likely* to port (and which Art. 20 *does not* cover).33  
Article 20 is limited to data "which he or she has *provided* to a controller".34 This generally includes "provided" data like photos, emails, and contact lists. However, the *actual source* of the H1 lock-in is rarely this simple data. It is the *inferred* data, the *derived* data, the personalization algorithms, the code-based features, and, most importantly, the *network effects*—the community and relationships 16—that the user has built.33  
Article 20 is "incapable of solving lock-in effects created by non-data-based features" like network effects.33 It is doctrinally misaligned. It treats a *systemic, market-level* problem (data lock-in) as an *individual-rights* problem. It gives the user a "right" to download a.zip file of their photos from a social network. It does *not* give them a right to *transfer* their *network of friends* or their *curated profile's interaction history* to a new service.  
Therefore, porting the data *does not* solve the "fear of loss." The user *still* loses the *actual* asset they value: the functional, embedded "digital self." Article 20 is a "paper tiger" against the H1 problem. It *appears* to be a solution but is structurally incapable of mitigating the actual switching costs, confirming the existence of the major regulatory gap hypothesized in H3.

## **Beyond Portability: The Digital Markets Act (DMA) and EU Data Act**

The manifest failure of Article 20 to address market-level data lock-in is the primary impetus for the EU's new regulatory paradigm, which moves from *data protection* to *market regulation*. The Digital Markets Act (DMA) and the EU Data Act are designed to fix the precise gaps the GDPR left open.

### **The New Regulatory Paradigm: Scope and Rights**

These new regulations attack the lock-in problem by changing both the *scope* of the data and the *nature* of the right.

1. **The EU Data Act (Expanding Scope):** The Data Act directly targets business models that "depend heavily on... a 'data lock-in' effect".37 It does this by radically expanding the *scope* of portable data. While the GDPR focuses on "personal data" 37, the Data Act grants access and portability rights for *all* data, including **"non-personal data and industrial data"**.37 It also grants these rights not just to *individuals* (like the GDPR) but to *legal entities* (businesses) as well.37  
2. **The Digital Markets Act (Changing the Right):** The DMA, targeting dominant "gatekeeper" platforms, moves beyond *portability* entirely.33 It does not offer a one-time "right to receive" data; it imposes an *ex-ante* obligation of **"mandatory interoperability"**.38 This requires gatekeepers to build systems that *allow* third-party services to communicate and exchange data in real-time.

### **Table 1: Comparative Analysis of EU Regulatory Frameworks for Data Lock-In**

| Framework | Primary Goal | Scope of Data | Right Granted | Key Limitation (re: Lock-in) | Effectiveness vs. Lock-in (H1) |
| :---- | :---- | :---- | :---- | :---- | :---- |
| **GDPR (Art. 20\)** | Protect individual rights; data protection. | "Personal data" *provided by* the data subject.34 | **Data Portability:** Right to *receive* data in a machine-readable format.34 | "Technical feasibility" loophole.32 Excludes inferred/derived data & network effects.33 | **Very Low.** Fails "portability paradox".33 Cannot transfer the *functional value* of the "digital self." |
| **EU Data Act** | Unlock economic potential; data sharing. | *All* data (personal, non-personal, industrial) generated by connected products.37 | **Data Access & Portability:** Right for *users and businesses* to access and move data.37 | Complements GDPR; focus is primarily on IoT/industrial data, not all social platform data. | **Medium.** Solves the *scope* problem (non-personal data) but not necessarily the *network* problem. |
| **Digital Markets Act (DMA)** | Ensure market fairness; *ex-ante* competition. | "Gatekeeper" platform data. | **Mandatory Interoperability:** *Obligation* for gatekeepers to enable real-time data exchange.38 | Only applies to designated "gatekeepers".39 | **High.** Directly targets lock-in by *eliminating* switching costs. Allows users to leave *without* data loss. |

Interoperability, not portability, is the only coherent regulatory solution to the problems identified in H1 and H2. It *disarms* the "deletion threat" by *de-valuing* the platform's *exclusivity* over the user's data. The coercive power of the "Inactivity Wall" (H2) stems from the fact that the platform has an exclusive monopoly on the functional value of the user's "digital self" (H1). Interoperability 38 breaks this monopoly. If a user can switch to a *new* service that can interoperate with (i.e., read from and post to) the *old* service, the user *can leave the platform without losing their network or data*. The switching cost (H1) evaporates. When the "fear of loss" is neutralized, the "deletion threat" (H2) loses all its coercive power. This new regulatory framework, therefore, is the true antidote to the entire coercive lock-in cycle.

# **Data as Digital Handcuffs: Coercive Retention in the Platform Economy and the Limits of EU Regulation**

## **Abstract**

This paper argues that "inactive account deletion" policies 20 are not benign security measures but a form of coercive "dark pattern" 26 designed to *compel* user retention. This tactic actively exploits the "psychological ownership" 3 that users develop over their personalized "digital selves" (Hypothesis 1), weaponizing their "fear of data loss" 12 to force re-engagement (Hypothesis 2). It is argued that this practice constitutes *unfair* processing under Article 5(1)(a) of the General Data Protection Regulation (GDPR). This analysis then demonstrates that the GDPR's intended remedy, the "right to data portability" (Article 20), is structurally incapable of solving this "data lock-in" due to the "portability paradox" 33 (Hypothesis 3). The paper concludes that only the *ex-ante* interoperability mandates of the Digital Markets Act (DMA) 38 can neutralize this coercive practice by disarming the "fear of loss" that enables it.

## **1\. Introduction: The Deletion Threat**

The digital platform economy is characterized by a central puzzle: why do dominant platforms like Google 20 and X (formerly Twitter) 20 periodically threaten to delete the accounts and data of *inactive* users? These announcements invariably spark widespread user anxiety, particularly concerning the loss of personal archives and the digital legacies of the deceased.20 The public justification for these policies is uniformly one of *cybersecurity* 20; platforms argue that dormant accounts are a significant security risk.20 This paper tests the hypotheses that this security rationale is a *pretext* (H2) for a *coercive retention strategy* (H1) and that this exploitation is permitted by a *doctrinal gap* in EU data protection law (H3).

## **2\. The Psychology and Economics of the "Digital Self" (H1)**

Hypothesis 1 posits that users are retained by a "fear of losing their content." This "content" is not a simple, fungible asset. While baseline research shows that generic "digital goods" are valued *less* than their physical counterparts 1, this "digital goods paradox" is resolved by *personalization*. The mechanisms of "control" 4 and *customization* 3 in a digital service enable users to invest their own labor—curating, clicking, and creating—into the platform. This labor transforms the generic service into an extension of the user's "self-concept" 1, creating a "psychological ownership" 6 that can be *greater* than that for physical goods.3  
This high-value, co-created "digital self" is the asset users fear losing. This "fear of data loss" is not theoretical; it is an empirically-verified *switching barrier* cited by consumers as a primary reason for *not* changing providers in sectors from mobile telecommunications 12 to health applications.13 This psychological attachment is the economic "data lock-in" 9 that platforms rely on for retention, whether to secure subscription revenue 5 or to maintain a stable user base for advertisers in "zero-price markets".11

## **3\. The "Inactivity Wall": A Coercive Dark Pattern (H2)**

Hypothesis 2 argues that companies *actively exploit* this fear. The "inactive account deletion" policy is the primary vector of this exploitation. The "security" rationale 20 functions as a pretext for a *disproportionate remedy*. The *problem* is account vulnerability, but the *chosen remedy* is total, irreversible data deletion.21 This choice is strategic: it is the only remedy that weaponizes the H1 "fear of loss."  
The *threat* of deletion, sent via warning emails 24, is a *coercive "dark pattern"*. As defined by the European Data Protection Board (EDPB), dark patterns influence users into "unintended, unwilling" decisions 25 and undermine "freely given" choice.26 This practice can be termed an **"Inactivity Wall"**: it functions just like a "Cookie Wall" 27, which denies *access* for consent, but is more coercive. The "Inactivity Wall" threatens the *destruction of the user's personal asset* (H1) to force an *unwilling action* (re-engagement). This "coerced login" is the "profit" 11 platforms seek, as it converts a "stale" user into an "active" one, validating H2.

## **4\. The GDPR's Doctrinal Failure (H3)**

Hypothesis 3 posits a *regulatory gap* in the GDPR. This gap is twofold. First, H3 is *literally* correct: the *act* of deletion is not *per se* illegal. The GDPR contains no "obligation to continue processing" 28 and, in fact, the "storage limitation" principle 31 may *require* deletion of data for which there is no "business need." The *true* violation is that the *threat* (the H2 dark pattern) constitutes *unfair processing* under GDPR Art. 5(1)(a). The gap is that this "fairness" principle is unenforced in this context.  
Second, the GDPR's *intended* solution for lock-in, the Right to Data Portability (Art. 20), is a doctrinal failure. It was *designed* to "avoid consumer lock-in" 32, but it fails due to:

1. **Procedural Loopholes:** The "technical feasibility" clause 36 and the lack of an interoperability mandate 32 render it impotent.  
2. **The "Portability Paradox":** The right is structurally misaligned.33 It grants a right to "provided" data 34 (e.g., photos), but the *actual* lock-in (H1) stems from *network effects* and *inferred/derived data*, which are not portable.33 A user can download their files, but not their *functional "digital self"*. Art. 20 fails to neutralize the "fear of loss."

## **5\. A New Regulatory Paradigm: From Portability to Interoperability**

The failure of Art. 20 (H3) necessitated a new regulatory class. The EU Data Act expands the *scope* of portability beyond "personal data" to *all* data, targeting "data lock-in" models.37 More importantly, the Digital Markets Act (DMA) changes the *right* itself, imposing *mandatory interoperability* on gatekeepers.38  
Interoperability, not portability, is the *only* coherent regulatory solution. It *disarms* the H1 "fear" by making the H2 "threat" impotent. If a user's data and network are interoperable with a rival service, the platform's monopoly on the *functional value* of that data is broken. The switching cost evaporates. When the "fear of loss" is neutralized, the "Inactivity Wall" loses all its coercive power.

## **6\. Conclusion and Policy Recommendations**

This analysis confirms all three hypotheses. The "fear of data loss" (H1) is a potent retention tool rooted in the psychological ownership of a co-created "digital self." Platforms actively exploit this fear using "Inactivity Wall" dark patterns (H2), a coercive practice that operates in a regulatory gap (H3) created by the doctrinal failure of the GDPR's right to portability.  
Based on this, two recommendations are forwarded:

1. **For Data Protection Authorities:** The European Data Protection Board (EDPB) must issue formal guidance clarifying that "Inactivity Walls"—the use of data deletion threats to coerce re-engagement—are a "deceptive design pattern" 25 and a *per se* violation of the "fairness" principle under GDPR Article 5(1)(a).  
2. **For Competition Authorities:** National Competition Authorities and the European Commission must aggressively enforce the interoperability mandates of the Digital Markets Act 38 as the only *structural, long-term* remedy that can neutralize this specific, exploitative, and anti-competitive form of consumer lock-in.

#### **Works cited**

1. Defining the Phygital Marketing Advantage \- MDPI, accessed November 9, 2025, [https://www.mdpi.com/0718-1876/16/6/130](https://www.mdpi.com/0718-1876/16/6/130)  
2. Wish list thinking: The quasi‐endowment effect's impact on online wish lists outcomes | Request PDF \- ResearchGate, accessed November 9, 2025, [https://www.researchgate.net/publication/345263760\_Wish\_list\_thinking\_The\_quasi-endowment\_effect's\_impact\_on\_online\_wish\_lists\_outcomes](https://www.researchgate.net/publication/345263760_Wish_list_thinking_The_quasi-endowment_effect's_impact_on_online_wish_lists_outcomes)  
3. Evolution of Consumption: A Psychological Ownership Framework \- Wharton Faculty Platform \- University of Pennsylvania, accessed November 9, 2025, [https://faculty.wharton.upenn.edu/wp-content/uploads/2016/11/evolution-of-consumption.pdf](https://faculty.wharton.upenn.edu/wp-content/uploads/2016/11/evolution-of-consumption.pdf)  
4. Kisfürjesi Nóra The Role of Attachment in the Switching Dynamics of Liquid Consumption, accessed November 9, 2025, [https://phd.lib.uni-corvinus.hu/1428/1/Kisfurjesi\_Nora\_den.pdf](https://phd.lib.uni-corvinus.hu/1428/1/Kisfurjesi_Nora_den.pdf)  
5. Digital Business Models and Platforms, accessed November 9, 2025, [https://www.rug.nl/gdbc/white-paper-digital-business-models-and-platforms.pdf](https://www.rug.nl/gdbc/white-paper-digital-business-models-and-platforms.pdf)  
6. Nonlinear moderating effects of individual social engagement in freemium strategies on digital content platforms \- ResearchGate, accessed November 9, 2025, [https://www.researchgate.net/publication/386570308\_Nonlinear\_moderating\_effects\_of\_individual\_social\_engagement\_in\_freemium\_strategies\_on\_digital\_content\_platforms](https://www.researchgate.net/publication/386570308_Nonlinear_moderating_effects_of_individual_social_engagement_in_freemium_strategies_on_digital_content_platforms)  
7. Women are more likely to buy unknown brands than men: The effects of gender and known versus unknown brands on purchase intentions | Request PDF \- ResearchGate, accessed November 9, 2025, [https://www.researchgate.net/publication/343976708\_Women\_are\_more\_likely\_to\_buy\_unknown\_brands\_than\_men\_The\_effects\_of\_gender\_and\_known\_versus\_unknown\_brands\_on\_purchase\_intentions](https://www.researchgate.net/publication/343976708_Women_are_more_likely_to_buy_unknown_brands_than_men_The_effects_of_gender_and_known_versus_unknown_brands_on_purchase_intentions)  
8. Privacy Considerations under EU Competition Law \- Research@CBS, accessed November 9, 2025, [https://research-api.cbs.dk/ws/portalfiles/portal/62184058/877760\_Thesis\_14\_May\_2020.pdf](https://research-api.cbs.dk/ws/portalfiles/portal/62184058/877760_Thesis_14_May_2020.pdf)  
9. Stigler Committee on Digital Platforms Final Report | Public Knowledge, accessed November 9, 2025, [https://publicknowledge.org/wp-content/uploads/2021/11/Stigler-Committee-on-Digital-Platforms-Final-Report.pdf](https://publicknowledge.org/wp-content/uploads/2021/11/Stigler-Committee-on-Digital-Platforms-Final-Report.pdf)  
10. Restrictions On Privacy and Exploitation In The Digital Economy: A Market Failure Perspective | Journal of Competition Law & Economics | Oxford Academic, accessed November 9, 2025, [https://academic.oup.com/jcle/article/17/4/765/6248466?rss=1](https://academic.oup.com/jcle/article/17/4/765/6248466?rss=1)  
11. Committee for the Study of Digital Platforms Market Structure and Antitrust Subcommittee \- Research Centers \- Chicago Booth, accessed November 9, 2025, [https://research.chicagobooth.edu/-/media/research/stigler/pdfs/market-structure---report-as-of-15-may-2019.pd](https://research.chicagobooth.edu/-/media/research/stigler/pdfs/market-structure---report-as-of-15-may-2019.pd)  
12. Switch or Stay: Unraveling the Loyalty Puzzle in Nepal's Telecom Industry, accessed November 9, 2025, [https://www.nepjol.info/index.php/djis/article/download/84587/64526/241792](https://www.nepjol.info/index.php/djis/article/download/84587/64526/241792)  
13. The Use of Mobile Applications among Adults with Type 1 and Type 2 Diabetes: Results from the Second MILES \- Australia (MILES-2) Study | Request PDF \- ResearchGate, accessed November 9, 2025, [https://www.researchgate.net/publication/320389860\_The\_Use\_of\_Mobile\_Applications\_among\_Adults\_with\_Type\_1\_and\_Type\_2\_Diabetes\_Results\_from\_the\_Second\_MILES\_-\_Australia\_MILES-2\_Study](https://www.researchgate.net/publication/320389860_The_Use_of_Mobile_Applications_among_Adults_with_Type_1_and_Type_2_Diabetes_Results_from_the_Second_MILES_-_Australia_MILES-2_Study)  
14. Combining Motivating Strategies with Design Concepts for Mobile Apps to Increase Usability for the Elderly and Alzheimer Patients | Request PDF \- ResearchGate, accessed November 9, 2025, [https://www.researchgate.net/publication/342828261\_Combining\_Motivating\_Strategies\_with\_Design\_Concepts\_for\_Mobile\_Apps\_to\_Increase\_Usability\_for\_the\_Elderly\_and\_Alzheimer\_Patients](https://www.researchgate.net/publication/342828261_Combining_Motivating_Strategies_with_Design_Concepts_for_Mobile_Apps_to_Increase_Usability_for_the_Elderly_and_Alzheimer_Patients)  
15. (PDF) Does e-shopping service quality enhance customers' e-shopping adoption? An extended perspective of unified theory of acceptance and use of technology \- ResearchGate, accessed November 9, 2025, [https://www.researchgate.net/publication/358881083\_Does\_e-shopping\_service\_quality\_enhance\_customers'\_e-shopping\_adoption\_An\_extended\_perspective\_of\_unified\_theory\_of\_acceptance\_and\_use\_of\_technology](https://www.researchgate.net/publication/358881083_Does_e-shopping_service_quality_enhance_customers'_e-shopping_adoption_An_extended_perspective_of_unified_theory_of_acceptance_and_use_of_technology)  
16. Good for all, good for me: the influences of dedication- and constraint-based switching barriers on user-generated contributions \- ResearchGate, accessed November 9, 2025, [https://www.researchgate.net/publication/381428808\_Good\_for\_all\_good\_for\_me\_the\_influences\_of\_dedication-\_and\_constraint-based\_switching\_barriers\_on\_user-generated\_contributions](https://www.researchgate.net/publication/381428808_Good_for_all_good_for_me_the_influences_of_dedication-_and_constraint-based_switching_barriers_on_user-generated_contributions)  
17. Measuring Switching Costs and the Determinants of Customer Retention in Internet-Enabled Businesses: A Study of the Online Brokerage Industry | Information Systems Research \- PubsOnLine, accessed November 9, 2025, [https://pubsonline.informs.org/doi/10.1287/isre.13.3.255.78](https://pubsonline.informs.org/doi/10.1287/isre.13.3.255.78)  
18. The Effects of Firm Generated Content in Social Media on Customer Behavior: An Empirical Examination \- Marketing Science Institute, accessed November 9, 2025, [https://www.msi.org/wp-content/uploads/2020/06/MSI\_Report\_16-111.pdf](https://www.msi.org/wp-content/uploads/2020/06/MSI_Report_16-111.pdf)  
19. 1 Request for Information on Merger Enforcement Public Comments of 23 State Attorneys General April 21, 2022 The Attorneys Gener, accessed November 9, 2025, [https://www.naag.org/wp-content/uploads/2022/08/Public-Comments-of-23-State-Attorneys-General-.pdf](https://www.naag.org/wp-content/uploads/2022/08/Public-Comments-of-23-State-Attorneys-General-.pdf)  
20. Google is deleting inactive accounts to build cyber resilience | World ..., accessed November 9, 2025, [https://www.weforum.org/stories/2023/12/cyber-resilience-inactive-accounts/](https://www.weforum.org/stories/2023/12/cyber-resilience-inactive-accounts/)  
21. How to Keep Your Google Account Active and Avoid Data Deletion \- Pep Talk Radio, accessed November 9, 2025, [https://www.peptalkradio.com/how-to-keep-your-google-account-active-and-avoid-data-deletion/](https://www.peptalkradio.com/how-to-keep-your-google-account-active-and-avoid-data-deletion/)  
22. Msn maill deleted \- Microsoft Q\&A, accessed November 9, 2025, [https://learn.microsoft.com/en-us/answers/questions/4668931/msn-maill-deleted](https://learn.microsoft.com/en-us/answers/questions/4668931/msn-maill-deleted)  
23. (PDF) The Law of Digital Resurrection \- ResearchGate, accessed November 9, 2025, [https://www.researchgate.net/publication/392220047\_The\_Law\_of\_Digital\_Resurrection](https://www.researchgate.net/publication/392220047_The_Law_of_Digital_Resurrection)  
24. Does Google delete inactive accounts in 2020? \- Quora, accessed November 9, 2025, [https://www.quora.com/Does-Google-delete-inactive-accounts-in-2020](https://www.quora.com/Does-Google-delete-inactive-accounts-in-2020)  
25. Guidelines 03/2022 on Deceptive design patterns in social media ..., accessed November 9, 2025, [https://www.edpb.europa.eu/system/files/2023-02/edpb\_03-2022\_guidelines\_on\_deceptive\_design\_patterns\_in\_social\_media\_platform\_interfaces\_v2\_en\_0.pdf](https://www.edpb.europa.eu/system/files/2023-02/edpb_03-2022_guidelines_on_deceptive_design_patterns_in_social_media_platform_interfaces_v2_en_0.pdf)  
26. The new era of cookie walls and user consent: CNIL's €475M enforcement action \- Analytics Platform \- Matomo, accessed November 9, 2025, [https://matomo.org/blog/2025/09/cookie-regulation-cnil/](https://matomo.org/blog/2025/09/cookie-regulation-cnil/)  
27. Dark Patterns \- 10 Examples of Manipulative Consent Requests \- Wide Angle Analytics, accessed November 9, 2025, [https://wideangle.co/blog/dark-patterns-examples-of-manipulative-consent-requests](https://wideangle.co/blog/dark-patterns-examples-of-manipulative-consent-requests)  
28. Data Protection and Privacy Policy \- Been There, accessed November 9, 2025, [https://beenthereapp.com/privacy-policy/](https://beenthereapp.com/privacy-policy/)  
29. Privacy Policy \- Cambridge Road Estate, accessed November 9, 2025, [https://www.cambridgeroadestate.com/privacy-policy](https://www.cambridgeroadestate.com/privacy-policy)  
30. GDPR Policy \- Robin Stephenson \- Notary Public, accessed November 9, 2025, [https://www.uknotarypublic.co.uk/gdpr-policy](https://www.uknotarypublic.co.uk/gdpr-policy)  
31. 20-F \- SEC.gov, accessed November 9, 2025, [https://www.sec.gov/Archives/edgar/data/1833835/000095017024033944/psfe-20231231.htm](https://www.sec.gov/Archives/edgar/data/1833835/000095017024033944/psfe-20231231.htm)  
32. View of The right to data portability in the GDPR and EU competition ..., accessed November 9, 2025, [https://ejlt.org/index.php/ejlt/article/view/546/726](https://ejlt.org/index.php/ejlt/article/view/546/726)  
33. THE PARADOX OF DATA PORTABILITY AND LOCK-IN EFFECTS ..., accessed November 9, 2025, [https://jolt.law.harvard.edu/assets/articlePDFs/v36/Zhang-The-Paradox-of-Data-Portability-and-Lock-In-Effects.pdf](https://jolt.law.harvard.edu/assets/articlePDFs/v36/Zhang-The-Paradox-of-Data-Portability-and-Lock-In-Effects.pdf)  
34. Compatibility Choices, Switching Costs and Data Portability \- Toulouse School of Economics, accessed November 9, 2025, [https://www.tse-fr.eu/sites/default/files/TSE/documents/doc/by/jeon/compatibility\_choices\_01\_2022.pdf](https://www.tse-fr.eu/sites/default/files/TSE/documents/doc/by/jeon/compatibility_choices_01_2022.pdf)  
35. Data Portability between Online Services: An Empirical Analysis on the Effectiveness of GDPR Art. 20 \- ResearchGate, accessed November 9, 2025, [https://www.researchgate.net/publication/351070025\_Data\_Portability\_between\_Online\_Services\_An\_Empirical\_Analysis\_on\_the\_Effectiveness\_of\_GDPR\_Art\_20](https://www.researchgate.net/publication/351070025_Data_Portability_between_Online_Services_An_Empirical_Analysis_on_the_Effectiveness_of_GDPR_Art_20)  
36. Data portability among online platforms \- Internet Policy Review, accessed November 9, 2025, [https://policyreview.info/articles/analysis/data-portability-among-online-platforms](https://policyreview.info/articles/analysis/data-portability-among-online-platforms)  
37. EU Data Act Compliance: A Complete Guide for Executives, accessed November 9, 2025, [https://appinventiv.com/blog/eu-data-act-compliance-checklist/](https://appinventiv.com/blog/eu-data-act-compliance-checklist/)  
38. The Great Interoperability Convergence: 2023 Year in Review ..., accessed November 9, 2025, [https://www.eff.org/deeplinks/2023/12/great-interoperability-convergence-2023-year-review](https://www.eff.org/deeplinks/2023/12/great-interoperability-convergence-2023-year-review)  
39. THE PRESENT AND FUTURE OF DATA PORTABILITY, accessed November 9, 2025, [https://dtinit.org/assets/DTI-Data-Portability-Compendium.pdf](https://dtinit.org/assets/DTI-Data-Portability-Compendium.pdf)  
40. Digital Competition and Data Regula- tion in the EU: Analysing the Inter- play between the DMA and the GDPR. \- Lund University Publications, accessed November 9, 2025, [https://lup.lub.lu.se/student-papers/record/9159815/file/9159822.pdf](https://lup.lub.lu.se/student-papers/record/9159815/file/9159822.pdf)